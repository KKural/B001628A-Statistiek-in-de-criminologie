---
title: "Correlation & Regression — Microcourse (MCQ format)"
output: word_document
---

# Correlation and Regression — Basics to Interpretation

Note: This file reformats questions from `Complete_Course_Questions.Rmd` to match the MCQ style used in `All quesion/basisbegrippen_statistiek.Rmd`. For items that normally require visuals, the phrasing is conceptual.

## OVERVIEW (Expanded course — 72 questions)

### Module 1: Correlation Basics (24 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q1 | What is correlation? | Remember |
| Q2 | What is regression? | Remember |
| Q3 | Variable types for correlation | Understand |
| Q4 | Correlation vs causation basics | Understand |
| Q5 | What is a z-score? | Remember |
| Q6 | Interpreting correlation values | Understand |
| Q7 | Key measures in correlation | Remember |
| Q8 | Direction of relationships | Understand |
| Q9 | Why standardize? | Understand |
| Q10 | Center in z‑scores | Remember |
| Q11 | Anscombe's Quartet | Understand |
| Q12 | Correlation ≠ Causation | Analyze |
| Q13 | Monotone vs. linear | Apply |
| Q14 | Units don't change r | Remember |
| Q15 | Z‑scores compare axes | Understand |
| Q16 | Subgroups vs. overall r | Analyze |
| Q17 | Quadrants and sign | Understand |
| Q18 | Direction and strength | Apply |
| Q19 | Outlier impact | Analyze |
| Q20 | Covariance vs correlation | Understand |
| Q21 | Weak positive | Apply |
| Q22 | Describe the pattern | Understand |
| Q23 | Meaning of z = +1.2 | Remember |
| Q24 | Aggregation pitfall | Analyze |

### Module 2: Correlation Calculations (18 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q25 | Compute means | Apply |
| Q18 | Calculate deviations | Apply |
| Q19 | Sum of squares | Apply |
| Q20 | Sample variances | Apply |
| Q21 | Covariance calculation | Apply |
| Q22 | Pearson r (standardized cov) | Apply |
| Q23 | Pearson r (z‑scores) | Understand |
| Q24 | Interpret r magnitude | Analyze |
| Q25 | Compute R² | Apply |
| Q26 | Spearman from ranks | Apply |
| Q27 | Handling ties in ranks | Understand |
| Q28 | Cramér's V calculation | Apply |
| Q29 | Point‑biserial correlation | Apply |
| Q30 | Choose correlation measure | Analyze |
| Q31 | Outlier sensitivity | Analyze |
| Q32 | When to use Spearman | Evaluate |
| Q33 | Correlation vs covariance | Understand |
| Q34 | Interpretation practice | Apply |

### Module 3: Regression Basics (10 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q35 | OLS principle | Understand |
| Q36 | Line passes through means | Remember |
| Q37 | Slope interpretation | Understand |
| Q38 | Intercept meaning | Understand |
| Q39 | Residuals concept | Understand |
| Q40 | Why squared errors | Understand |
| Q41 | R² interpretation | Understand |
| Q42 | Extrapolation risks | Analyze |
| Q43 | Correlation vs regression | Understand |
| Q44 | Causality caution | Analyze |

### Module 4: Regression Calculations (12 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q45 | Calculate slope | Apply |
| Q46 | Calculate intercept | Apply |
| Q47 | Make predictions | Apply |
| Q48 | Calculate residuals | Apply |
| Q49 | R² from correlation | Apply |
| Q50 | Standardized slope | Apply |
| Q51 | Unit effects on regression | Understand |
| Q52 | Read statistical output | Apply |
| Q53 | Outlier effects | Analyze |
| Q54 | Intercept interpretation | Analyze |
| Q55 | Model assumptions | Understand |
| Q56 | Prediction vs explanation | Understand |

### Module 5: Partial Correlation (8 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q57 | When to use partial correlation | Understand |
| Q58 | Partial correlation formula | Remember |
| Q59 | Calculate partial correlation | Apply |
| Q60 | Spurious vs suppression | Analyze |
| Q61 | Control vs interaction | Understand |
| Q62 | Interpret partial correlation | Analyze |
| Q63 | Statistical reporting | Apply |
| Q64 | Scale invariance | Understand |ression — Microcourse (MCQ format)"
output: word_document
---

# Correlation and Regression — Basics to Interpretation

Note: This file reformats questions from `Complete_Course_Questions.Rmd` to match the MCQ style used in `All quesion/basisbegrippen_statistiek.Rmd`. For items that normally require visuals, the phrasing is conceptual.

## OVERVIEW (Module 1 — selection, 16 questions)

| Question | Title | Level |
|----------|-------|-------|
| Q1 | Why standardize? | Understand |
| Q2 | Center in z‑scores | Remember |
| Q3 | Anscombe’s Quartet | Understand |
| Q4 | Correlation ≠ Causation | Analyze |
| Q5 | Monotone vs. linear | Apply |
| Q6 | Units don’t change r | Remember |
| Q7 | Z‑scores compare axes | Understand |
| Q8 | Subgroups vs. overall r | Analyze |
| Q9 | Quadrants and sign | Understand |
| Q10 | Direction and strength | Apply |
| Q11 | Outlier impact | Analyze |
| Q12 | Covariance vs correlation | Understand |
| Q13 | Weak positive | Apply |
| Q14 | Describe the pattern | Understand |
| Q15 | Meaning of z = +1.2 | Remember |
| Q16 | Aggregation pitfall | Analyze |

---

### Question Q1 (Remember)
**What is correlation?**

> **Hint:** Think about the relationship between two variables.

1) A measure of how much one variable causes another  
"1" = "❌ Incorrect. Correlation does not establish causation."
2) A statistical measure of the strength and direction of relationship between two variables  
"2" = "✅ Correct! Correlation quantifies linear association between variables."
3) The difference between two variables  
"3" = "❌ Incorrect. That would be a simple difference, not correlation."
4) A method to predict future values  
"4" = "❌ Incorrect. That's prediction; correlation measures association."

---

### Question Q2 (Remember)
**What is regression?**

> **Hint:** Think about predicting one variable from another.

1) The same thing as correlation  
"1" = "❌ Incorrect. Regression and correlation are related but different."
2) A statistical method to predict one variable from another using a linear equation  
"2" = "✅ Correct! Regression creates prediction equations like Y = a + bX."
3) A way to calculate averages  
"3" = "❌ Incorrect. Regression involves prediction, not just averaging."
4) A method only used for categorical variables  
"4" = "❌ Incorrect. Regression typically uses continuous variables."

---

### Question Q3 (Understand)
**For which types of variables can you calculate Pearson correlation?**

> **Hint:** Consider the measurement level requirements.

1) Only categorical variables  
"1" = "❌ Incorrect. Pearson correlation requires numeric variables."
2) Both variables must be continuous (interval or ratio level)  
"2" = "✅ Correct! Pearson correlation requires numeric, continuous variables."
3) One categorical and one continuous variable  
"3" = "❌ Incorrect. This would use point-biserial correlation."
4) Any type of variables  
"4" = "❌ Incorrect. Different correlation types exist for different variable types."

---

### Question Q4 (Understand)
**Why doesn't correlation prove causation?**

> **Hint:** Think about alternative explanations for associations.

1) Correlation is always too weak to prove anything  
"1" = "❌ Incorrect. Even strong correlations don't prove causation."
2) Third variables, reverse causation, or coincidence might explain the relationship  
"2" = "✅ Correct! Many alternative explanations exist for statistical associations."
3) Only experiments can show any relationships  
"3" = "❌ Incorrect. Correlation shows association; causation requires more evidence."
4) Correlation is the same as causation  
"4" = "❌ Incorrect. This is the misconception we want to avoid."

---

### Question Q5 (Remember)
**What is a z-score?**

> **Hint:** Think about standardizing scores relative to the mean and spread.

1) The raw score minus the mean  
"1" = "❌ Incorrect. That's a deviation, not a z-score."
2) A score that shows how many standard deviations a value is from the mean  
"2" = "✅ Correct! z = (X - μ)/σ standardizes scores."
3) The percentage above the mean  
"3" = "❌ Incorrect. Z-scores use standard deviation units, not percentages."
4) The square of the original score  
"4" = "❌ Incorrect. Z-scores involve standardization, not squaring."

---

### Question Q6 (Understand)
**How do you interpret a correlation of r = 0.75?**

> **Hint:** Consider both direction and strength.

1) Weak positive relationship  
"1" = "❌ Incorrect. 0.75 is stronger than weak."
2) Strong positive relationship  
"2" = "✅ Correct! Values around 0.7-0.8 indicate strong positive association."
3) Perfect negative relationship  
"3" = "❌ Incorrect. The value is positive, not negative or perfect."
4) No relationship  
"4" = "❌ Incorrect. 0.75 shows a clear relationship."

---

### Question Q7 (Remember)
**What are the key measures in correlation analysis?**

> **Hint:** Think about the main statistics that describe correlation.

1) Only the correlation coefficient (r)  
"1" = "❌ Incorrect. There are additional important measures."
2) Correlation coefficient (r), coefficient of determination (R²), and sample size (n)  
"2" = "✅ Correct! These provide complete information about the relationship."
3) Only the mean and standard deviation  
"3" = "❌ Incorrect. These don't describe the relationship between variables."
4) The slope and intercept  
"4" = "❌ Incorrect. These are regression parameters, not correlation measures."

---

### Question Q8 (Understand)
**What does the direction of a correlation tell you?**

> **Hint:** Think about positive vs. negative relationships.

1) How strong the relationship is  
"1" = "❌ Incorrect. Direction is about sign, not strength."
2) Whether variables increase together (positive) or one increases as the other decreases (negative)  
"2" = "✅ Correct! Direction shows whether variables move in the same or opposite directions."
3) Whether the relationship is causal  
"3" = "❌ Incorrect. Direction doesn't indicate causation."
4) How many observations are in the dataset  
"4" = "❌ Incorrect. Direction doesn't relate to sample size."

---

### Question Q9 (Understand)
**Why is standardizing (using z‑scores) useful when comparing two variables?**

> **Hint:** Consider unit effects on covariance and correlation as a unit‑free measure.

1) The relationship fundamentally changes when units change  
"1" = "❌ Incorrect. Units don’t change the underlying relationship; only covariance’s magnitude."
2) The relationship stays the same, but covariance isn’t comparable across units  
"2" = "✅ Correct! Correlation (r) is standardized and unit‑free; covariance isn’t."
3) Covariance is always better than correlation  
"3" = "❌ Incorrect. Covariance is scale‑dependent; correlation is scale‑invariant."
4) You should never standardize variables  
"4" = "❌ Incorrect. Standardizing is useful to put variables on the same scale."

---

### Question Q2 (Remember)
**Where is the ‘center of gravity’ in a standardized (z‑score) scatterplot?**

> **Hint:** Z‑scores center variables at their means.

1) (0, 0) — intersection of mean lines  
"1" = "✅ Correct! In z‑scores, the bivariate center is (0,0)."
2) (1, 1) — one standard deviation point  
"2" = "❌ Incorrect. That’s one SD above both means, not the center."
3) The densest part of the cloud  
"3" = "❌ Incorrect. The mode isn’t necessarily the mean‑center."
4) The most frequent observed point  
"4" = "❌ Incorrect. That’s the mode, not the mean‑based center in z‑space."

---

### Question Q3 (Understand)
**What is the main lesson of Anscombe’s Quartet?**

> **Hint:** Four datasets can share identical summaries yet have very different shapes.

1) Correlation tells the whole story  
"1" = "❌ Incorrect. Identical r can arise from very different patterns."
2) Always plot your data first  
"2" = "✅ Correct! Visualization avoids being misled by summaries alone."
3) Graphs are less reliable than statistics  
"3" = "❌ Incorrect. Plots complement statistics; both matter."
4) Linear relationships are the most common  
"4" = "❌ Incorrect. The quartet shows diverse structures with the same r."

---

### Question Q4 (Analyze)
**Headline: “Ice cream sales and drownings are strongly correlated.” What’s a plausible explanation?**

> **Hint:** Think of a third variable (confounder) driving both.

1) Ice cream causes drownings  
"1" = "❌ Incorrect. Correlation ≠ causation."
2) Drownings cause higher ice cream sales  
"2" = "❌ Incorrect. Reverse causality isn’t plausible here."
3) Temperature/season increases both  
"3" = "✅ Correct! Warm weather raises ice cream sales and swimming activity."
4) There is no relationship at all  
"4" = "❌ Incorrect. There is an association, just not causal."

---

### Question Q5 (Apply)
**The relationship is curved but monotonically increasing. Which correlation should you choose?**

> **Hint:** Distinguish “linear” from “monotone”.

1) Pearson correlation  
"1" = "❌ Incorrect. Pearson measures linear association and may underestimate strength."
2) Spearman correlation  
"2" = "✅ Correct! Spearman captures monotone relationships via ranks."
3) Both are equally appropriate  
"3" = "❌ Incorrect. Spearman fits better here."
4) Neither  
"4" = "❌ Incorrect. Spearman is suitable for monotone, non‑linear patterns."

---

### Question Q6 (Remember)
**You switch X from meters to centimeters. What happens to r(X,Y)?**

> **Hint:** Correlation is scale‑invariant; covariance isn’t.

1) r becomes 100× larger  
"1" = "❌ Incorrect. Units don’t affect r."
2) r becomes 100× smaller  
"2" = "❌ Incorrect. Units don’t affect r."
3) r stays exactly the same  
"3" = "✅ Correct! r is unit‑free and invariant to linear rescaling."
4) r becomes negative  
"4" = "❌ Incorrect. The sign doesn’t flip due to units."

---

### Question Q7 (Understand)
**Why do z‑scores make axes more comparable in a scatterplot?**

> **Hint:** Consider “same scale” and “standard deviations”.

1) They put both variables into SD units  
"1" = "✅ Correct! Standardizing places both on the same scale."
2) They always increase the correlation  
"2" = "❌ Incorrect. Standardizing doesn’t change r."
3) They remove all outliers  
"3" = "❌ Incorrect. They may help detect outliers, not remove them."
4) They make covariance unit‑free  
"4" = "❌ Incorrect. Correlation is unit‑free; covariance remains scale‑dependent."

---

### Question Q8 (Analyze)
**A scatterplot colors points by ‘neighborhood type’. How is the overall correlation r typically computed?**

> **Hint:** Compare subgroup calculations versus full sample.

1) Using only the largest subgroup  
"1" = "❌ Incorrect. That ignores many cases."
2) As the average of subgroup correlations  
"2" = "❌ Incorrect. A simple mean of subgroup r’s isn’t standard."
3) Using all points together, ignoring colors  
"3" = "✅ Correct! By default r is computed on the full dataset."
4) As a weighted average of subgroup r’s  
"4" = "❌ Incorrect. Not the default definition of r."

---

### Question Q9 (Understand)
**Which quadrants dominate under a positive association (in z‑scores)?**

> **Hint:** Consider the signs of z(X) and z(Y).

1) Mostly quadrants I & III  
"1" = "✅ Correct! Positive: both above or both below their means."
2) Mostly quadrants II & IV  
"2" = "❌ Incorrect. That indicates negative association."
3) Evenly spread across all quadrants  
"3" = "❌ Incorrect. Suggests little/no linear relationship."
4) Only quadrant I  
"4" = "❌ Incorrect. Quadrant III also occurs in positive association."

---

### Question Q10 (Apply)
**A straight trend line slopes upward; points cluster tightly. Which description fits best?**

> **Hint:** Combine direction (sign) with strength (spread).

1) Strong positive  
"1" = "✅ Correct! Upward line + tight cluster → strong positive."
2) Moderate positive  
"2" = "❌ Incorrect. Description suggests stronger than moderate."
3) Weak negative  
"3" = "❌ Incorrect. Direction is positive, not negative."
4) No linear pattern  
"4" = "❌ Incorrect. The pattern is clearly linear."

---

### Question Q11 (Analyze)
**In a positive trend, which outlier position most reduces r?**

> **Hint:** Think of points that break the linear pattern.

1) Far bottom‑left (low X, very low Y)  
"1" = "❌ Incorrect. That aligns with the positive trend."
2) Far bottom‑right (high X, low Y)  
"2" = "✅ Correct! Pulls the cloud off the line and lowers r."
3) Far top‑right (high X, high Y)  
"3" = "❌ Incorrect. Often increases a positive r."
4) A point exactly on the line  
"4" = "❌ Incorrect. Minimal impact on r."

---

### Question Q12 (Understand)
**Which statement about covariance and correlation is true?**

> **Hint:** Watch for units and ranges.

1) Covariance is unit‑free and bounded −1 to +1  
"1" = "❌ Incorrect. That's correlation, not covariance."
2) Correlation is unit‑free and always between −1 and +1  
"2" = "✅ Correct! That's why r is comparable across variables."
3) Both are unbounded  
"3" = "❌ Incorrect. Only covariance is unbounded."
4) Both depend on measurement scale  
"4" = "❌ Incorrect. Only covariance is scale‑dependent."

---

### Question Q13 (Apply)
**Which r value best matches 'weak positive'?**

> **Hint:** Use common interpretation guidelines.

1) r = 0.12  
"1" = "✅ Correct! Often interpreted as weak positive."
2) r = 0.56  
"2" = "❌ Incorrect. Closer to moderate."
3) r = −0.72  
"3" = "❌ Incorrect. Strong negative, not weak positive."
4) r = 0.93  
"4" = "❌ Incorrect. Very strong positive."

---

### Question Q14 (Understand)
**"As X increases, Y tends to …" — choose the best completion for a slightly increasing pattern.**

> **Hint:** Use the standard sentence for a weak upward trend.

1) … decrease, strongly  
"1" = "❌ Incorrect. Wrong direction."
2) … increase, weakly  
"2" = "✅ Correct! Weakly increasing relationship."
3) … increase, very strongly  
"3" = "❌ Incorrect. 'Very strong' doesn't fit a slight increase."
4) … stay the same  
"4" = "❌ Incorrect. That implies no linear relationship."

---

### Question Q15 (Remember)
**What does z = +1.2 mean in plain words?**

> **Hint:** Relate to the mean and standard deviation.

1) 1.2 units above the mean  
"1" = "❌ Incorrect. They are SD units, not raw units."
2) 1.2 standard deviations above the mean  
"2" = "✅ Correct! That's the definition of a positive z."
3) 1.2% above the mean  
"3" = "❌ Incorrect. Not a percentage."
4) 0.12 standard deviations above the mean  
"4" = "❌ Incorrect. Wrong magnitude."

---

### Question Q16 (Analyze)
**Subgroup colors on the plot: what's a risk of looking only at overall r?**

> **Hint:** Think Simpson's paradox and heterogeneity across groups.

1) Subgroup patterns can mask or reverse the overall pattern  
"1" = "✅ Correct! Aggregation can mislead; inspect subgroups."
2) r always changes when you add colors  
"2" = "❌ Incorrect. r's calculation ignores colors."
3) r can never be misleading  
"3" = "❌ Incorrect. r without context can mislead."
4) Subgroups automatically increase r  
"4" = "❌ Incorrect. No such general rule."

---

# Module 2: Correlation Calculations (18 questions)

### Question Q25 (Apply)
**Given this dataset, calculate the mean of Test1 scores:**

Test1 scores: 72, 85, 90, 78, 82, 88, 75, 92

> **Hint:** Add all values and divide by the number of observations.

1) 80.25  
"1" = "❌ Incorrect. Check your arithmetic."
2) 82.75  
"2" = "✅ Correct! Mean = 662/8 = 82.75"
3) 83.50  
"3" = "❌ Incorrect. Double‑check your calculation."
4) 85.00  
"4" = "❌ Incorrect. This is not the correct mean."

---

### Question Q18 (Apply)
**What does the deviation (X − X̄) represent?**

> **Hint:** Think about what we're measuring relative to the center.

1) How far each score is from zero  
"1" = "❌ Incorrect. Deviations are from the mean, not zero."
2) How far each score is from the mean  
"2" = "✅ Correct! Deviations measure distance from the center."
3) The squared distance from the mean  
"3" = "❌ Incorrect. That would be (X − X̄)²."
4) The absolute value of the score  
"4" = "❌ Incorrect. This ignores the mean as reference point."

---

### Question Q19 (Apply)
**In correlation calculations, what is SSxy (sum of cross‑products)?**

> **Hint:** Consider how X and Y deviations combine.

1) Σ(X − X̄)²  
"1" = "❌ Incorrect. That's SSx (sum of squares for X)."
2) Σ(Y − Ȳ)²  
"2" = "❌ Incorrect. That's SSy (sum of squares for Y)."
3) Σ(X − X̄)(Y − Ȳ)  
"3" = "✅ Correct! Cross‑products measure how X and Y deviate together."
4) Σ(X + Y)  
"4" = "❌ Incorrect. This ignores deviations and their relationship."

---

### Question Q20 (Apply)
**For sample variance, why do we divide by (n−1) instead of n?**

> **Hint:** Think about bias correction in sample statistics.

1) It's easier to calculate  
"1" = "❌ Incorrect. Calculation difficulty isn't the reason."
2) It corrects for sample bias (Bessel's correction)  
"2" = "✅ Correct! Using n−1 gives an unbiased estimate of population variance."
3) It makes the variance larger  
"3" = "❌ Incorrect. While true, this isn't the primary reason."
4) It's required by statistical software  
"4" = "❌ Incorrect. The mathematical reasoning comes first."

---

### Question Q21 (Apply)
**How do you calculate sample covariance from sum of cross‑products?**

> **Hint:** Similar to variance calculation with deviations.

1) Cov = SSxy / n  
"1" = "❌ Incorrect. Use n−1 for sample covariance."
2) Cov = SSxy / (n−1)  
"2" = "✅ Correct! Sample covariance uses Bessel's correction."
3) Cov = SSxy × (n−1)  
"3" = "❌ Incorrect. You divide, not multiply."
4) Cov = √(SSxy / n)  
"4" = "❌ Incorrect. This involves a square root, which isn't needed."

---

### Question Q22 (Apply)
**Which formula correctly calculates Pearson correlation?**

> **Hint:** Correlation is standardized covariance.

1) r = Cov(X,Y)  
"1" = "❌ Incorrect. This is just covariance, not standardized."
2) r = Cov(X,Y) / (Sx × Sy)  
"2" = "✅ Correct! Correlation is covariance divided by the product of standard deviations."
3) r = Sx / Sy  
"3" = "❌ Incorrect. This is a ratio of standard deviations."
4) r = SSxy / (SSx + SSy)  
"4" = "❌ Incorrect. This formula doesn't properly standardize."

---

### Question Q23 (Understand)
**The conceptual formula r = average(zx × zy) shows that correlation is:**

> **Hint:** Think about what z‑scores represent.

1) The average product of raw scores  
"1" = "❌ Incorrect. Z‑scores are standardized, not raw scores."
2) The average product of standardized scores  
"2" = "✅ Correct! This shows correlation as the average of standardized cross‑products."
3) The sum of all deviations  
"3" = "❌ Incorrect. This doesn't involve products or averaging."
4) The ratio of means  
"4" = "❌ Incorrect. Correlation doesn't directly involve means this way."

---

### Question Q24 (Analyze)
**A correlation of r = 0.65 is best described as:**

> **Hint:** Use common interpretation guidelines.

1) Very weak  
"1" = "❌ Incorrect. 0.65 is well above weak thresholds."
2) Moderate  
"2" = "✅ Correct! Values around 0.6‑0.7 are typically moderate‑to‑strong."
3) Perfect  
"3" = "❌ Incorrect. Perfect correlation is r = ±1.0."
4) Negative  
"4" = "❌ Incorrect. The value is positive."

---

### Question Q25 (Apply)
**If r = 0.80, what is R² and its interpretation?**

> **Hint:** R² = r² for simple correlation.

1) R² = 0.80; 80% of variance explained  
"1" = "❌ Incorrect. You need to square the correlation."
2) R² = 0.64; 64% of variance explained  
"2" = "✅ Correct! R² = (0.80)² = 0.64"
3) R² = 0.40; 40% of variance explained  
"3" = "❌ Incorrect. Check your squaring calculation."
4) R² = 1.60; 160% of variance explained  
"4" = "❌ Incorrect. R² cannot exceed 1.0."

---

### Question Q26 (Apply)
**When calculating Spearman correlation, you first:**

> **Hint:** Spearman works with ranks, not raw values.

1) Calculate means and deviations  
"1" = "❌ Incorrect. Spearman doesn't use raw score means."
2) Rank both variables separately  
"2" = "✅ Correct! Convert data to ranks, then apply Pearson formula to ranks."
3) Remove all outliers  
"3" = "❌ Incorrect. Ranking handles outliers automatically."
4) Standardize to z‑scores  
"4" = "❌ Incorrect. Spearman uses ranks, not z‑scores."

---

### Question Q27 (Understand)
**How do you handle tied values when ranking for Spearman correlation?**

> **Hint:** Equal values need equal treatment.

1) Ignore tied values  
"1" = "❌ Incorrect. Ties must be handled systematically."
2) Assign them consecutive ranks  
"2" = "❌ Incorrect. This treats equal values unequally."
3) Use the average of the ranks they would occupy  
"3" = "✅ Correct! This ensures fair treatment of equal values."
4) Always round down to the lower rank  
"4" = "❌ Incorrect. This introduces bias."

---

### Question Q28 (Apply)
**Cramér's V is used to measure association between:**

> **Hint:** Consider what types of variables this applies to.

1) Two continuous variables  
"1" = "❌ Incorrect. Use Pearson correlation for continuous variables."
2) Two categorical variables  
"2" = "✅ Correct! Cramér's V measures association in contingency tables."
3) One continuous and one binary variable  
"3" = "❌ Incorrect. Use point‑biserial correlation for this."
4) Ranked variables only  
"4" = "❌ Incorrect. Use Spearman for ranked variables."

---

### Question Q29 (Apply)
**Point‑biserial correlation is appropriate when:**

> **Hint:** Think about the combination of variable types.

1) Both variables are continuous  
"1" = "❌ Incorrect. Use regular Pearson correlation."
2) One variable is continuous, one is binary (0/1)  
"2" = "✅ Correct! Point‑biserial handles continuous vs. binary variables."
3) Both variables are categorical  
"3" = "❌ Incorrect. Use chi‑square or Cramér's V."
4) Both variables are ranked  
"4" = "❌ Incorrect. Use Spearman correlation."

---

### Question Q30 (Analyze)
**Match the correlation type to the scenario: Education level (High school/Bachelor/Master/PhD) vs. Income (dollars)**

> **Hint:** Consider the nature of each variable.

1) Pearson correlation  
"1" = "❌ Incorrect. Education is ordinal, not truly continuous."
2) Spearman correlation  
"2" = "✅ Correct! One ordinal variable (education) makes Spearman appropriate."
3) Point‑biserial correlation  
"3" = "❌ Incorrect. Neither variable is binary."
4) Cramér's V  
"4" = "❌ Incorrect. Income is continuous, not categorical."

---

### Question Q31 (Analyze)
**An outlier in the bottom‑right corner of a positive trend will:**

> **Hint:** Consider how this point contradicts the overall pattern.

1) Increase the correlation  
"1" = "❌ Incorrect. This outlier goes against the positive trend."
2) Decrease the correlation  
"2" = "✅ Correct! High X with low Y contradicts positive association."
3) Have no effect on correlation  
"3" = "❌ Incorrect. Outliers typically affect correlation."
4) Make the correlation negative  
"4" = "❌ Incorrect. One outlier rarely reverses the overall sign."

---

### Question Q32 (Evaluate)
**When should you choose Spearman over Pearson correlation?**

> **Hint:** Consider data characteristics that favor rank‑based methods.

1) When you want the strongest possible correlation  
"1" = "❌ Incorrect. Choose based on data properties, not desired strength."
2) When the relationship is monotonic but not linear  
"2" = "✅ Correct! Spearman captures monotonic relationships better."
3) When both variables are normally distributed  
"3" = "❌ Incorrect. Normal distribution favors Pearson."
4) When the sample size is very large  
"4" = "❌ Incorrect. Sample size alone doesn't determine the choice."

---

### Question Q33 (Understand)
**The key advantage of correlation over covariance is:**

> **Hint:** Think about comparability across different variable pairs.

1) Correlation is easier to calculate  
"1" = "❌ Incorrect. Calculation complexity is similar."
2) Correlation is unit‑free and bounded (‑1 to +1)  
"2" = "✅ Correct! This makes correlation comparable across studies."
3) Correlation is always positive  
"3" = "❌ Incorrect. Correlation can be negative."
4) Correlation requires smaller sample sizes  
"4" = "❌ Incorrect. Sample size requirements are similar."

---

### Question Q34 (Apply)
**Complete this interpretation: "As study hours increase, test scores tend to..."**

Given: r = 0.45 between study hours and test scores

> **Hint:** Describe direction and strength appropriately.

1) decrease moderately  
"1" = "❌ Incorrect. Wrong direction for positive r."
2) increase moderately  
"2" = "✅ Correct! Positive correlation with moderate strength."
3) increase strongly  
"3" = "❌ Incorrect. 0.45 is moderate, not strong."
4) remain constant  
"4" = "❌ Incorrect. This would imply r ≈ 0."

---

# Module 3: Regression Basics (10 questions)

### Question Q35 (Understand)
**What does the "least squares" principle minimize in regression?**

> **Hint:** Think about the type of distances OLS optimizes.

1) Horizontal distances from points to line  
"1" = "❌ Incorrect. OLS minimizes vertical distances."
2) Sum of squared vertical distances from points to line  
"2" = "✅ Correct! OLS minimizes Σ(Y − Ŷ)²"
3) Total number of prediction errors  
"3" = "❌ Incorrect. We focus on error magnitude, not count."
4) The slope of the regression line  
"4" = "❌ Incorrect. The slope is determined by minimizing errors."

---

### Question Q36 (Remember)
**A fundamental property of regression lines is that they:**

> **Hint:** Think about where the line must pass through.

1) Always have positive slopes  
"1" = "❌ Incorrect. Slopes can be negative."
2) Pass through the point (X̄, Ȳ)  
"2" = "✅ Correct! The regression line always passes through the bivariate mean."
3) Have zero intercept  
"3" = "❌ Incorrect. Intercepts can be any value."
4) Minimize horizontal distances  
"4" = "❌ Incorrect. They minimize vertical distances."

---

### Question Q37 (Understand)
**If the regression slope b = 2.5, this means:**

> **Hint:** Think about how Y changes when X increases.

1) For every 1‑unit increase in X, Y increases by 2.5 units  
"1" = "✅ Correct! The slope represents change in Y per unit change in X."
2) For every 2.5‑unit increase in X, Y increases by 1 unit  
"2" = "❌ Incorrect. This reverses the slope interpretation."
3) The correlation is 2.5  
"3" = "❌ Incorrect. Correlation is bounded between ‑1 and +1."
4) Y is always 2.5 times larger than X  
"4" = "❌ Incorrect. This confuses slope with a multiplicative relationship."

---

### Question Q38 (Understand)
**The y‑intercept represents:**

> **Hint:** Consider what happens when X = 0.

1) The average value of Y  
"1" = "❌ Incorrect. That would be Ȳ, not the intercept."
2) The predicted value of Y when X = 0  
"2" = "✅ Correct! The intercept is Ŷ when X = 0."
3) The slope of the regression line  
"3" = "❌ Incorrect. That's a different parameter (b)."
4) The correlation coefficient  
"4" = "❌ Incorrect. That's r, not the intercept."

---

### Question Q39 (Understand)
**Residuals in regression analysis represent:**

> **Hint:** Think about the difference between observed and predicted values.

1) The actual Y values  
"1" = "❌ Incorrect. Residuals are not the raw Y values."
2) The predicted Y values  
"2" = "❌ Incorrect. Residuals are not the predictions themselves."
3) The differences between observed and predicted Y values  
"3" = "✅ Correct! Residuals = Y − Ŷ (prediction errors)."
4) The X values used for prediction  
"4" = "❌ Incorrect. Residuals don't represent X values."

---

### Question Q40 (Understand)
**Why does OLS use squared residuals instead of absolute residuals?**

> **Hint:** Consider mathematical and practical advantages.

1) Squared values are easier to interpret  
"1" = "❌ Incorrect. Squaring doesn't improve interpretation."
2) It penalizes large errors more heavily and ensures mathematical tractability  
"2" = "✅ Correct! Squaring emphasizes large errors and enables calculus solutions."
3) It always produces positive slopes  
"3" = "❌ Incorrect. Squaring doesn't determine slope sign."
4) It makes calculation faster  
"4" = "❌ Incorrect. Computational speed isn't the primary reason."

---

### Question Q41 (Understand)
**R² in regression represents:**

> **Hint:** Think about explained vs. total variation.

1) The correlation coefficient  
"1" = "❌ Incorrect. That's r, not R²."
2) The proportion of Y's variance explained by X  
"2" = "✅ Correct! R² = explained variance / total variance."
3) The slope of the regression line  
"3" = "❌ Incorrect. That's b, not R²."
4) The number of observations  
"4" = "❌ Incorrect. That's n, not R²."

---

### Question Q42 (Analyze)
**Extrapolation in regression is risky because:**

> **Hint:** Consider what happens outside the observed data range.

1) The calculations become more complex  
"1" = "❌ Incorrect. Mathematical complexity isn't the main risk."
2) The relationship may not continue linearly beyond observed X values  
"2" = "✅ Correct! Patterns may change outside the observed range."
3) R² automatically decreases  
"3" = "❌ Incorrect. R² is based on the original data."
4) The software cannot compute predictions  
"4" = "❌ Incorrect. Software can extrapolate, but it may be unreliable."

---

### Question Q43 (Understand)
**The key difference between correlation and regression is:**

> **Hint:** Think about symmetry and prediction direction.

1) Correlation measures strength; regression measures direction  
"1" = "❌ Incorrect. Both can measure direction."
2) Correlation is symmetric; regression predicts Y from X specifically  
"2" = "✅ Correct! Correlation treats X and Y equally; regression is asymmetric."
3) Correlation uses all data; regression uses samples  
"3" = "❌ Incorrect. Both use available data similarly."
4) There is no meaningful difference  
"4" = "❌ Incorrect. The asymmetry is a crucial distinction."

---

### Question Q44 (Analyze)
**A strong regression R² doesn't prove causation because:**

> **Hint:** Think about alternative explanations for statistical associations.

1) R² only measures correlation  
"1" = "❌ Partially correct but incomplete."
2) Confounding variables, reverse causation, or spurious relationships may exist  
"2" = "✅ Correct! Statistical association ≠ causal relationship."
3) The sample size might be too small  
"3" = "❌ Incorrect. Sample size doesn't determine causality."
4) Only experimental data can show causation  
"4" = "❌ Too strong; observational studies can provide causal evidence with proper design."

---

# Module 4: Regression Calculations (12 questions)

### Question Q45 (Apply)
**The regression slope is calculated as:**

> **Hint:** Think about the relationship between covariance and variance.

1) b = Var(X) / Cov(X,Y)  
"1" = "❌ Incorrect. This reverses the ratio."
2) b = Cov(X,Y) / Var(X)  
"2" = "✅ Correct! Slope = covariance divided by X variance."
3) b = Cov(X,Y) / Var(Y)  
"3" = "❌ Incorrect. Use Var(X) in the denominator."
4) b = Var(Y) / Var(X)  
"4" = "❌ Incorrect. This ignores covariance."

---

### Question Q46 (Apply)
**If b = 1.5 and the means are X̄ = 10, Ȳ = 25, what is the intercept?**

> **Hint:** Use the formula a = Ȳ − b·X̄

1) a = 10.0  
"1" = "❌ Incorrect. Check your calculation."
2) a = 10.5  
"2" = "✅ Correct! a = 25 − 1.5(10) = 25 − 15 = 10"
3) a = 15.0  
"3" = "❌ Incorrect. Double‑check the arithmetic."
4) a = 25.0  
"4" = "❌ Incorrect. This ignores the slope adjustment."

---

### Question Q47 (Apply)
**Using Ŷ = 10 + 1.5X, predict Y when X = 8:**

> **Hint:** Substitute X = 8 into the regression equation.

1) Ŷ = 18  
"1" = "❌ Incorrect. Check your multiplication."
2) Ŷ = 22  
"2" = "✅ Correct! Ŷ = 10 + 1.5(8) = 10 + 12 = 22"
3) Ŷ = 25  
"3" = "❌ Incorrect. Verify your calculation."
4) Ŷ = 28  
"4" = "❌ Incorrect. Double‑check the arithmetic."

---

### Question Q48 (Apply)
**If Y = 20 and Ŷ = 22, what is the residual?**

> **Hint:** Residual = observed − predicted

1) e = +2  
"1" = "❌ Incorrect. Check the order of subtraction."
2) e = −2  
"2" = "✅ Correct! e = Y − Ŷ = 20 − 22 = −2"
3) e = 0  
"3" = "❌ Incorrect. The observed and predicted values differ."
4) e = 42  
"4" = "❌ Incorrect. This adds instead of subtracting."

---

### Question Q49 (Apply)
**In simple regression, R² equals:**

> **Hint:** Think about the relationship between correlation and R².

1) r  
"1" = "❌ Incorrect. Need to square the correlation."
2) r²  
"2" = "✅ Correct! For simple regression, R² = r²"
3) 2r  
"3" = "❌ Incorrect. This doubles instead of squaring."
4) √r  
"4" = "❌ Incorrect. This takes the square root instead of squaring."

---

### Question Q50 (Apply)
**The standardized regression coefficient β equals:**

> **Hint:** Think about the relationship between β and correlation.

1) β = r × (Sx/Sy)  
"1" = "❌ Incorrect. This reverses the standard deviation ratio."
2) β = r × (Sy/Sx)  
"2" = "❌ Incorrect. For standardized coefficients, β = r."
3) β = r (when both variables are standardized)  
"3" = "✅ Correct! When X and Y are z‑scored, β = r."
4) β = b × r  
"4" = "❌ Incorrect. This isn't the correct relationship."

---

### Question Q51 (Understand)
**When you change X from meters to centimeters:**

> **Hint:** Consider scale invariance properties.

1) Both r and R² change  
"1" = "❌ Incorrect. These are scale‑invariant."
2) Only the slope (b) changes  
"2" = "✅ Correct! r and R² stay the same; slope adjusts for units."
3) Only r changes  
"3" = "❌ Incorrect. r is scale‑invariant."
4) Nothing changes  
"4" = "❌ Incorrect. The slope will change with units."

---

### Question Q52 (Apply)
**In this regression output, what is the intercept?**

```
                  B      Beta     t      p
(Constant)     15.8              2.45   .025
Test_Score      0.92    .73     4.21   .001
```

> **Hint:** Look for the constant term in the B column.

1) 0.92  
"1" = "❌ Incorrect. That's the slope."
2) 15.8  
"2" = "✅ Correct! The constant (intercept) is 15.8."
3) 0.73  
"3" = "❌ Incorrect. That's the standardized coefficient."
4) 4.21  
"4" = "❌ Incorrect. That's the t‑statistic."

---

### Question Q53 (Analyze)
**An outlier far above the regression line will:**

> **Hint:** Consider the effect on the line's position and fit.

1) Always decrease R²  
"1" = "✅ Correct! Outliers typically reduce the proportion of explained variance."
2) Always increase R²  
"2" = "❌ Incorrect. Outliers usually worsen fit."
3) Have no effect on the regression  
"3" = "❌ Incorrect. Outliers influence both slope and fit."
4) Only affect the intercept  
"4" = "❌ Incorrect. Outliers can affect multiple parameters."

---

### Question Q54 (Analyze)
**When is the intercept not meaningful?**

> **Hint:** Consider when X = 0 makes no practical sense.

1) When the slope is negative  
"1" = "❌ Incorrect. Negative slopes don't affect intercept meaning."
2) When X = 0 is outside the observed range or impossible  
"2" = "✅ Correct! E.g., predicting income from years of education when 0 years is meaningless."
3) When R² is low  
"3" = "❌ Incorrect. Model fit doesn't determine intercept interpretation."
4) When the sample size is small  
"4" = "❌ Incorrect. Sample size doesn't affect interpretation."

---

### Question Q55 (Understand)
**Which is NOT a key assumption of linear regression?**

> **Hint:** Think about standard regression assumptions.

1) Linear relationship between X and Y  
"1" = "❌ Incorrect. Linearity is a key assumption."
2) Constant variance of residuals (homoscedasticity)  
"2" = "❌ Incorrect. This is also a key assumption."
3) Perfect correlation (r = 1.0)  
"3" = "✅ Correct! Perfect correlation is not required or expected."
4) Independence of observations  
"4" = "❌ Incorrect. Independence is indeed assumed."

---

### Question Q56 (Understand)
**What's the difference between prediction and explanation in regression?**

> **Hint:** Consider the goals and implications of each approach.

1) Prediction focuses on accuracy; explanation focuses on understanding mechanisms  
"1" = "✅ Correct! Prediction emphasizes forecasting; explanation emphasizes causality."
2) Prediction uses different formulas than explanation  
"2" = "❌ Incorrect. The mathematical formulas are the same."
3) Prediction requires larger samples than explanation  
"3" = "❌ Incorrect. Sample size requirements are similar."
4) There is no difference  
"4" = "❌ Incorrect. The goals and interpretations differ significantly."

---

# Module 5: Partial Correlation (8 questions)

### Question Q57 (Understand)
**Partial correlation is most useful when you want to:**

> **Hint:** Think about controlling for third variables.

1) Increase the strength of correlation  
"1" = "❌ Incorrect. The goal isn't to artificially strengthen relationships."
2) Examine the relationship between X and Y after controlling for Z  
"2" = "✅ Correct! Partial correlation shows the 'net' relationship after removing Z's influence."
3) Convert correlation to causation  
"3" = "❌ Incorrect. Statistical control doesn't establish causation."
4) Handle missing data  
"4" = "❌ Incorrect. Partial correlation doesn't address missing data."

---

### Question Q58 (Remember)
**The formula for partial correlation rXY·Z is:**

> **Hint:** Recall the standard formula involving zero‑order correlations.

1) (rXY + rXZ × rYZ) / √[(1−rXZ²)(1−rYZ²)]  
"1" = "❌ Incorrect. Should subtract, not add in numerator."
2) (rXY − rXZ × rYZ) / √[(1−rXZ²)(1−rYZ²)]  
"2" = "✅ Correct! This is the standard partial correlation formula."
3) (rXY × rXZ) / rYZ  
"3" = "❌ Incorrect. This doesn't match the proper formula structure."
4) rXY / (rXZ + rYZ)  
"4" = "❌ Incorrect. This isn't the correct partial correlation formula."

---

### Question Q59 (Apply)
**Given rXY = 0.60, rXZ = 0.40, rYZ = 0.30, calculate rXY·Z:**

> **Hint:** Apply the partial correlation formula step by step.

1) 0.45  
"1" = "❌ Incorrect. Check your calculation."
2) 0.52  
"2" = "✅ Correct! rXY·Z = (0.60 − 0.40×0.30) / √[(1−0.16)(1−0.09)] = 0.48/0.92 ≈ 0.52"
3) 0.60  
"3" = "❌ Incorrect. This ignores the control variable."
4) 0.70  
"4" = "❌ Incorrect. Double‑check your arithmetic."

---

### Question Q60 (Analyze)
**If rXY = 0.20 but rXY·Z = 0.45, this suggests:**

> **Hint:** Compare zero‑order and partial correlations.

1) Spurious correlation (Z was inflating the relationship)  
"1" = "❌ Incorrect. The relationship got stronger, not weaker."
2) Suppression (Z was hiding the true relationship)  
"2" = "✅ Correct! Controlling for Z revealed a stronger underlying relationship."
3) No change in the relationship  
"3" = "❌ Incorrect. The correlation increased substantially."
4) Measurement error  
"4" = "❌ Incorrect. This pattern doesn't indicate measurement error."

---

### Question Q61 (Understand)
**Partial correlation is different from interaction/moderation because:**

> **Hint:** Think about controlling for vs. examining conditional effects.

1) Partial correlation is harder to calculate  
"1" = "❌ Incorrect. Calculation difficulty isn't the key difference."
2) Partial correlation controls for Z; moderation examines how the X‑Y relationship depends on Z  
"2" = "✅ Correct! Partial correlation removes Z's influence; moderation studies Z's conditional effects."
3) Partial correlation requires larger samples  
"3" = "❌ Incorrect. Sample size requirements are similar."
4) There is no difference  
"4" = "❌ Incorrect. These are conceptually distinct approaches."

---

### Question Q62 (Analyze)
**You find rXY = 0.70 and rXY·Z = 0.20. In a criminology context, this suggests:**

> **Hint:** Think about spurious relationships and confounding.

1) The relationship between X and Y is mostly genuine  
"1" = "❌ Incorrect. The large drop suggests the opposite."
2) Variable Z accounts for most of the apparent X‑Y relationship  
"2" = "✅ Correct! The dramatic reduction suggests Z was a confounder."
3) Z has no effect on the X‑Y relationship  
"3" = "❌ Incorrect. Z clearly has a major effect."
4) The measurement of Z is unreliable  
"4" = "❌ Incorrect. This pattern doesn't indicate measurement problems."

---

### Question Q63 (Apply)
**In APA‑style reporting, how would you report: B = 2.5, SE = 0.8, β = 0.45, t = 3.12, p = .003?**

> **Hint:** Include key statistics and avoid causal language.

1) "X causes Y to increase by 2.5 units (p = .003)"  
"1" = "❌ Incorrect. Avoid causal language in correlational analysis."
2) "Higher X predicted higher Y (B = 2.5, SE = 0.8, β = .45, t = 3.12, p = .003)"  
"2" = "✅ Correct! Includes key statistics with appropriate predictive language."
3) "X and Y are perfectly correlated (B = 2.5)"  
"3" = "❌ Incorrect. This overstates the relationship and omits key statistics."
4) "The relationship is significant (p = .003)"  
"4" = "❌ Incorrect. Too minimal; should include effect size information."

---

### Question Q64 (Understand)
**When you convert X from centimeters to meters, what happens to r and R²?**

> **Hint:** Consider scale invariance in correlation and explained variance.

1) Both r and R² change proportionally  
"1" = "❌ Incorrect. These measures are scale‑invariant."
2) Only r changes; R² stays the same  
"2" = "❌ Incorrect. Both are scale‑invariant."
3) Both r and R² remain exactly the same  
"3" = "✅ Correct! Correlation and R² are unaffected by linear transformations."
4) Only R² changes; r stays the same  
"4" = "❌ Incorrect. Both are scale‑invariant."

### Question Q10 (Apply)
**A straight trend line slopes upward; points cluster tightly. Which description fits best?**

> **Hint:** Combine direction (sign) with strength (spread).

1) Strong positive  
"1" = "✅ Correct! Upward line + tight cluster → strong positive."
2) Moderate positive  
"2" = "❌ Incorrect. Description suggests stronger than moderate."
3) Weak negative  
"3" = "❌ Incorrect. Direction is positive, not negative."
4) No linear pattern  
"4" = "❌ Incorrect. The pattern is clearly linear."

---

### Question Q11 (Analyze)
**In a positive trend, which outlier position most reduces r?**

> **Hint:** Think of points that break the linear pattern.

1) Far bottom‑left (low X, very low Y)  
"1" = "❌ Incorrect. That aligns with the positive trend."
2) Far bottom‑right (high X, low Y)  
"2" = "✅ Correct! Pulls the cloud off the line and lowers r."
3) Far top‑right (high X, high Y)  
"3" = "❌ Incorrect. Often increases a positive r."
4) A point exactly on the line  
"4" = "❌ Incorrect. Minimal impact on r."

---

### Question Q12 (Understand)
**Which statement about covariance and correlation is true?**

> **Hint:** Watch for units and ranges.

1) Covariance is unit‑free and bounded −1 to +1  
"1" = "❌ Incorrect. That’s correlation, not covariance."
2) Correlation is unit‑free and always between −1 and +1  
"2" = "✅ Correct! That’s why r is comparable across variables."
3) Both are unbounded  
"3" = "❌ Incorrect. Only covariance is unbounded."
4) Both depend on measurement scale  
"4" = "❌ Incorrect. Only covariance is scale‑dependent."

---

### Question Q13 (Apply)
**Which r value best matches ‘weak positive’?**

> **Hint:** Use common interpretation guidelines.

1) r = 0.12  
"1" = "✅ Correct! Often interpreted as weak positive."
2) r = 0.56  
"2" = "❌ Incorrect. Closer to moderate."
3) r = −0.72  
"3" = "❌ Incorrect. Strong negative, not weak positive."
4) r = 0.93  
"4" = "❌ Incorrect. Very strong positive."

---

### Question Q14 (Understand)
**“As X increases, Y tends to …” — choose the best completion for a slightly increasing pattern.**

> **Hint:** Use the standard sentence for a weak upward trend.

1) … decrease, strongly  
"1" = "❌ Incorrect. Wrong direction."
2) … increase, weakly  
"2" = "✅ Correct! Weakly increasing relationship."
3) … increase, very strongly  
"3" = "❌ Incorrect. ‘Very strong’ doesn’t fit a slight increase."
4) … stay the same  
"4" = "❌ Incorrect. That implies no linear relationship."

---

### Question Q15 (Remember)
**What does z = +1.2 mean in plain words?**

> **Hint:** Relate to the mean and standard deviation.

1) 1.2 units above the mean  
"1" = "❌ Incorrect. They are SD units, not raw units."
2) 1.2 standard deviations above the mean  
"2" = "✅ Correct! That’s the definition of a positive z."
3) 1.2% above the mean  
"3" = "❌ Incorrect. Not a percentage."
4) 0.12 standard deviations above the mean  
"4" = "❌ Incorrect. Wrong magnitude."

---

### Question Q16 (Analyze)
**Subgroup colors on the plot: what’s a risk of looking only at overall r?**

> **Hint:** Think Simpson’s paradox and heterogeneity across groups.

1) Subgroup patterns can mask or reverse the overall pattern  
"1" = "✅ Correct! Aggregation can mislead; inspect subgroups."
2) r always changes when you add colors  
"2" = "❌ Incorrect. r’s calculation ignores colors."
3) r can never be misleading  
"3" = "❌ Incorrect. r without context can mislead."
4) Subgroups automatically increase r  
"4" = "❌ Incorrect. No such general rule."

