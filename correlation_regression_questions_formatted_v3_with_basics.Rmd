---
title: "Correlation & Regression — Enhanced Microcourse with Visuals (MCQ format)"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(flextable)
library(dplyr)
```

# Correlation and Regression — Enhanced with Visual Learning

This comprehensive assessment covers correlation and regression analysis concepts essential for criminology statistics. The file includes 80 carefully structured questions across five modules, with visual examples, practical applications, and detailed feedback for optimal learning.

## Visual Learning Guide

### Understanding Correlation Patterns Through Scatterplots

```{r correlation-patterns, echo=TRUE, fig.width=12, fig.height=8}
# Generate example data for different correlation patterns
set.seed(123)
n <- 50

# Strong positive correlation (r ≈ 0.85)
x1 <- rnorm(n, 50, 10)
y1 <- 0.85 * scale(x1)[,1] * 8 + rnorm(n, 60, 3)

# Strong negative correlation (r ≈ -0.75)
x2 <- rnorm(n, 50, 10)
y2 <- -0.75 * scale(x2)[,1] * 8 + rnorm(n, 60, 4)

# Weak correlation (r ≈ 0.15)
x3 <- rnorm(n, 50, 10)
y3 <- 0.15 * scale(x3)[,1] * 8 + rnorm(n, 60, 8)

# No correlation (r ≈ 0)
x4 <- rnorm(n, 50, 10)
y4 <- rnorm(n, 60, 8)

# Create combined dataset
data_patterns <- data.frame(
  x = c(x1, x2, x3, x4),
  y = c(y1, y2, y3, y4),
  pattern = rep(c("Strong Positive (r ≈ +0.85)", "Strong Negative (r ≈ -0.75)", 
                  "Weak Positive (r ≈ +0.15)", "No Correlation (r ≈ 0)"), each = n)
)

# Create the visualization
ggplot(data_patterns, aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 2, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1) +
  facet_wrap(~pattern, ncol = 2, scales = "free") +
  labs(
    title = "Understanding Correlation Patterns in Criminology Data",
    subtitle = "How data points cluster around the trend line indicates correlation strength",
    x = "Predictor Variable (e.g., socioeconomic status)",
    y = "Outcome Variable (e.g., crime rate)",
    caption = "Note: Shaded area shows confidence interval around regression line"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11),
    strip.text = element_text(size = 10, face = "bold"),
    axis.title = element_text(size = 10),
    plot.caption = element_text(size = 9, style = "italic")
  )
```

**Key Interpretation Points:**
- **Strong Positive**: Points cluster tightly around upward-sloping line
- **Strong Negative**: Points cluster tightly around downward-sloping line  
- **Weak Correlation**: Points scattered widely around trend line
- **No Correlation**: No discernible linear pattern, flat or chaotic arrangement

### Regression Line Components

```{r regression-components, echo=TRUE, fig.width=10, fig.height=6}
# Create example regression data
set.seed(456)
x_reg <- seq(10, 50, length.out = 30)
y_reg <- 15 + 0.8 * x_reg + rnorm(30, 0, 4)

# Calculate regression line
model <- lm(y_reg ~ x_reg)
intercept <- coef(model)[1]
slope <- coef(model)[2]

# Create regression visualization
ggplot(data.frame(x = x_reg, y = y_reg), aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7, color = "darkblue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1.5) +
  # Highlight intercept
  geom_point(aes(x = 0, y = intercept), color = "green", size = 4, shape = 17) +
  # Add annotations
  annotate("text", x = 5, y = intercept + 3, 
           label = paste("Y-intercept =", round(intercept, 1)), 
           color = "green", size = 4, fontface = "bold") +
  annotate("text", x = 35, y = 25, 
           label = paste("Slope =", round(slope, 2)), 
           color = "red", size = 4, fontface = "bold") +
  # Add residual examples
  geom_segment(aes(x = x_reg[5], y = y_reg[5], 
                   xend = x_reg[5], yend = predict(model)[5]), 
               color = "orange", linewidth = 1, linetype = "dashed") +
  annotate("text", x = x_reg[5] + 2, y = (y_reg[5] + predict(model)[5])/2, 
           label = "Residual", color = "orange", size = 3, fontface = "bold") +
  labs(
    title = "Anatomy of a Regression Line",
    subtitle = "Understanding slope, intercept, and residuals in criminology regression",
    x = "Predictor Variable (X)",
    y = "Outcome Variable (Y)",
    caption = "Green triangle = Y-intercept | Red line = Regression line | Orange dashed = Residual (error)"
  ) +
  xlim(0, 55) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11),
    axis.title = element_text(size = 10),
    plot.caption = element_text(size = 9, style = "italic")
  )
```

**Component Explanations:**
- **Y-intercept**: Value of Y when X = 0 (may not be meaningful in all contexts)
- **Slope**: Change in Y for each 1-unit increase in X
- **Residuals**: Vertical distance between observed points and predicted line
- **R²**: Proportion of variance in Y explained by X (closer to 1.0 = better fit)

### Understanding Standard Error in Regression

**Standard Error (SE)** measures the precision of our regression estimates:

- **SE of slope**: How much the slope might vary across different samples
- **Smaller SE**: More precise estimate, narrow confidence intervals
- **Larger SE**: Less precise estimate, wide confidence intervals
- **95% CI**: Slope ± (1.96 × SE) gives the range we're 95% confident contains the true population slope

In criminology: A small SE for the relationship between unemployment and crime suggests this relationship is precisely estimated and likely reliable across different communities.

## APA-Style Regression Results Table

```{r apa-table, echo=TRUE}
# Create example regression results for criminology research
regression_results <- data.frame(
  Predictor = c("(Intercept)", "Unemployment Rate", "Population Density", "Education Level"),
  B = c(45.23, 2.14, 0.003, -1.87),
  SE = c(8.91, 0.45, 0.001, 0.62),
  t = c(5.08, 4.76, 3.00, -3.02),
  p = c("< .001", "< .001", ".003", ".003"),
  CI_Lower = c(27.75, 1.26, 0.001, -3.08),
  CI_Upper = c(62.71, 3.02, 0.005, -0.66)
)

# Create APA-style table using flextable
apa_table <- flextable(regression_results) %>%
  set_header_labels(
    Predictor = "Predictor",
    B = "B",
    SE = "SE", 
    t = "t",
    p = "p",
    CI_Lower = "95% CI Lower",
    CI_Upper = "95% CI Upper"
  ) %>%
  add_header_lines("Table 1. Regression Analysis Predicting Crime Rate per 1,000 Residents") %>%
  align(align = "center", part = "all") %>%
  align(j = 1, align = "left", part = "body") %>%
  fontsize(size = 10, part = "all") %>%
  fontsize(size = 12, part = "header") %>%
  bold(part = "header") %>%
  autofit() %>%
  add_footer_lines(c(
    "Note. N = 150 cities. R² = .67, F(3, 146) = 98.45, p < .001.",
    "B = unstandardized regression coefficient; SE = standard error; CI = confidence interval.",
    "All continuous predictors were centered before analysis."
  )) %>%
  fontsize(size = 9, part = "footer") %>%
  italic(part = "footer")

apa_table
```

## Interpretation Guide for Criminology Research

### Effect Size Guidelines (Cohen's Conventions)
- **Small correlation**: r = .10 (1% of variance explained)
- **Medium correlation**: r = .30 (9% of variance explained)  
- **Large correlation**: r = .50 (25% of variance explained)

### Practical Significance vs Statistical Significance
- **Statistical significance**: p < .05 (relationship unlikely due to chance)
- **Practical significance**: Effect size large enough to matter in real-world applications
- **Example**: r = .15, p < .001 in large sample may be statistically significant but practically small

### Common Interpretation Pitfalls
1. **Correlation ≠ Causation**: High correlation doesn't prove one variable causes another
2. **Third variables**: Alternative explanations may account for observed relationships
3. **Restriction of range**: Limited variability can artificially reduce correlations
4. **Outliers**: Extreme scores can inflate or deflate correlation coefficients
5. **Non-linear relationships**: Correlation assumes linear associations

Note: This file reformats questions from `Complete_Course_Questions.Rmd` to match the MCQ style used in `All quesion/basisbegrippen_statistiek.Rmd`. For items that normally require visuals, the phrasing is conceptual.

## OVERVIEW (Expanded course with fundamentals — 89 questions)

### Module 1: Correlation Basics (34 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q1 | What is correlation? | Remember |
| Q2 | What is regression? | Remember |
| Q3 | Variable types for correlation | Understand |
| Q4 | Correlation vs causation basics | Understand |
| Q5 | What is a z-score? | Remember |
| Q6 | Interpreting correlation values | Understand |
| Q7 | Key measures in correlation | Remember |
| Q8 | Direction of relationships | Understand |
| Q9 | What does correlation tell us? | Understand |
| Q10 | Correlation vs regression differences | Apply |
| Q11 | Regression slope meaning | Understand |
| Q12 | Regression intercept meaning | Remember |
| Q13 | R² interpretation | Understand |
| Q14 | Why square residuals? | Analyze |
| Q15 | Correlation-regression connection | Understand |
| Q16 | Zero correlation and slope | Apply |
| Q17 | Correlation and causation | Evaluate |
| Q18 | Why standardize? | Understand |
| Q19 | Center in z‑scores | Remember |
| Q20 | Anscombe's Quartet | Understand |
| Q21 | Correlation ≠ Causation | Analyze |
| Q22 | Monotone vs. linear | Apply |
| Q23 | Units don't change r | Remember |
| Q24 | Z‑scores compare axes | Understand |
| Q25 | Subgroups vs. overall r | Analyze |
| Q26 | Quadrants and sign | Understand |
| Q27 | Direction and strength | Apply |
| Q28 | Outlier impact | Analyze |
| Q29 | Covariance vs correlation | Understand |
| Q30 | Weak positive | Apply |
| Q31 | Describe the pattern | Understand |
| Q32 | Meaning of z = +1.2 | Remember |
| Q33 | Aggregation pitfall | Analyze |
| Q34 | Bridge to calculations | Apply |

### Module 2: Correlation Calculations (18 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q35 | Compute means | Apply |
| Q36 | Calculate deviations | Apply |
| Q37 | Sum of squares | Apply |
| Q38 | Sample variances | Apply |
| Q39 | Covariance calculation | Apply |
| Q40 | Pearson r (standardized cov) | Apply |
| Q41 | Pearson r (z‑scores) | Understand |
| Q42 | Interpret r magnitude | Analyze |
| Q43 | Compute R² | Apply |
| Q44 | Spearman from ranks | Apply |
| Q45 | Handling ties in ranks | Understand |
| Q46 | Cramér's V calculation | Apply |
| Q47 | Point‑biserial correlation | Apply |
| Q48 | Choose correlation measure | Analyze |
| Q49 | Outlier sensitivity | Analyze |
| Q50 | When to use Spearman | Evaluate |
| Q51 | Correlation vs covariance | Understand |
| Q52 | Interpretation practice | Apply |

### Module 3: From Correlation to Regression (7 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q53 | Visual correlation patterns | Understand |
| Q54 | Correlation strength to prediction | Apply |
| Q55 | From r to regression line | Apply |
| Q56 | Prediction accuracy and R² | Analyze |
| Q57 | Slope interpretation practice | Apply |
| Q58 | Residual patterns | Understand |
| Q59 | When regression is appropriate | Evaluate |

### Module 4: Regression Basics (10 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q60 | OLS principle | Understand |
| Q61 | Line passes through means | Remember |
| Q62 | Slope interpretation | Understand |
| Q63 | Intercept meaning | Understand |
| Q64 | Residuals concept | Understand |
| Q65 | Why squared errors | Understand |
| Q66 | R² interpretation | Understand |
| Q67 | Extrapolation risks | Analyze |
| Q68 | Correlation vs regression | Understand |
| Q69 | Causality caution | Analyze |

### Module 5: Regression Calculations (12 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q70 | Calculate slope | Apply |
| Q71 | Calculate intercept | Apply |
| Q72 | Make predictions | Apply |
| Q73 | Calculate residuals | Apply |
| Q74 | R² from correlation | Apply |
| Q75 | Standardized slope | Apply |
| Q76 | Unit effects on regression | Understand |
| Q77 | Read statistical output | Apply |
| Q78 | Outlier effects | Analyze |
| Q79 | Intercept interpretation | Analyze |
| Q80 | Model assumptions | Understand |
| Q81 | Prediction vs explanation | Understand |

### Module 6: Partial Correlation (8 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q82 | When to use partial correlation | Understand |
| Q83 | Partial correlation formula | Remember |
| Q84 | Calculate partial correlation | Apply |
| Q85 | Spurious vs suppression | Analyze |
| Q86 | Control vs interaction | Understand |
| Q87 | Interpret partial correlation | Analyze |
| Q88 | Statistical reporting | Apply |
| Q89 | Scale invariance | Understand |

---

# Module 1: Correlation Basics (34 questions)

---
title: "Exercise II"
output: word_document
---

# Basisbegrippen in de Correlation and regression

## 📋 OVERZICHTSTABEL - VRAGEN VOLGENS BLOOM'S TAXONOMIE

### REMEMBER LEVEL (7 vragen - 17%)
| Vraagnummer | Vraag Titel | Leerintentie |
|-------------|-------------|--------------|
| Q1 | What is correlation? | Definitie van correlatie herinneren |
| Q2 | What is regression? | Definitie van regressie herinneren |
| Q5 | What is a z-score? | Z-score definitie herinneren |
| Q7 | Key measures in correlation | Belangrijke correlatiematen herinneren |
| Q12 | Regression intercept meaning | Betekenis van intercept herinneren |
| Q19 | Center in z-scores | Centrum van gestandaardiseerde verdeling herinneren |
| Q23 | Units don't change r | Invariantie van correlatie voor eenheden herinneren |

### UNDERSTAND LEVEL (16 vragen - 38%)
| Vraagnummer | Vraag Titel | Leerintentie |
|-------------|-------------|--------------|
| Q3 | Variable types for correlation | Variabeletypes voor correlatie begrijpen |
| Q4 | Correlation vs causation basics | Verschil correlatie-causatie begrijpen |
| Q6 | Interpreting correlation values | Correlatie-interpretatie begrijpen |
| Q8 | Direction of relationships | Richting van verbanden begrijpen |
| Q9 | What does correlation tell us? | Wat correlatie betekent begrijpen |
| Q11 | Regression slope meaning | Betekenis van regressiehelling begrijpen |
| Q13 | R² interpretation | R-kwadraat interpretatie begrijpen |
| Q15 | Correlation-regression connection | Verband correlatie-regressie begrijpen |
| Q18 | Why standardize? | Redenen voor standaardisatie begrijpen |
| Q20 | Anscombe's Quartet | Belang van visualisatie begrijpen |
| Q24 | Z-scores compare axes | Vergelijking via z-scores begrijpen |
| Q26 | Quadrants and sign | Kwadranten en tekenrichting begrijpen |
| Q29 | Covariance vs correlation | Verschil covariantie-correlatie begrijpen |
| Q31 | Describe the pattern | Patroonbeschrijving begrijpen |
| Q32 | Meaning of z = +1.2 | Interpretatie specifieke z-score begrijpen |
| Q34 | Bridge to calculations | Overgang naar berekeningen begrijpen |

### APPLY LEVEL (5 vragen - 12%)
| Vraagnummer | Vraag Titel | Leerintentie |
|-------------|-------------|--------------|
| Q10 | Correlation vs regression differences | Verschillen praktisch toepassen |
| Q16 | Zero correlation and slope | Nul-correlatie gevolgen toepassen |
| Q22 | Monotone vs. linear | Monotoon versus lineair toepassen |
| Q27 | Direction and strength | Richting en sterkte bepalen |
| Q30 | Weak positive | Zwak positieve correlatie herkennen |

### ANALYZE LEVEL (5 vragen - 12%)
| Vraagnummer | Vraag Titel | Leerintentie |
|-------------|-------------|--------------|
| Q14 | Why square residuals? | Reden voor kwadrateren analyseren |
| Q21 | Correlation ≠ Causation | Correlatie-causatie mythe analyseren |
| Q25 | Subgroups vs. overall r | Subgroep versus totaal analyseren |
| Q28 | Outlier impact | Impact van uitbijters analyseren |
| Q33 | Aggregation pitfall | Aggregatievalkuil analyseren |

### EVALUATE LEVEL (5 vragen - 12%)
| Vraagnummer | Vraag Titel | Leerintentie |
|-------------|-------------|--------------|
| Q35 | Evaluate conflicting study results | Tegenstellende onderzoeksresultaten evalueren |
| Q36 | Critique visualization design | Visualisatie-ontwerp kritisch beoordelen |
| Q37 | Assess statistical claims | Statistische claims beoordelen |
| Q38 | Judge research methodology | Onderzoeksmethodologie beoordelen |
| Q39 | Evaluate model assumptions | Modelveronderstellingen evalueren |

### CREATE LEVEL (4 vragen - 10%)
| Vraagnummer | Vraag Titel | Leerintentie |
|-------------|-------------|--------------|
| Q40 | Design a correlation study | Correlatiestudie ontwerpen |
| Q41 | Create research hypothesis | Onderzoekshypothese formuleren |
| Q42 | Construct interpretation | Interpretatie construeren |
| Q43 | Design visualization | Visualisatie ontwerpen |

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(ggplot2)
library(flextable)
library(dplyr)
```

# Correlation and Regression — Enhanced with Visual Learning

This comprehensive assessment covers correlation and regression analysis concepts essential for criminology statistics. The file includes 80 carefully structured questions across five modules, with visual examples, practical applications, and detailed feedback for optimal learning.

## Visual Learning Guide

### Understanding Correlation Patterns Through Scatterplots

```{r correlation-patterns, echo=TRUE, fig.width=12, fig.height=8}
# Generate example data for different correlation patterns
set.seed(123)
n <- 50

# Strong positive correlation (r ≈ 0.85)
x1 <- rnorm(n, 50, 10)
y1 <- 0.85 * scale(x1)[,1] * 8 + rnorm(n, 60, 3)

# Strong negative correlation (r ≈ -0.75)
x2 <- rnorm(n, 50, 10)
y2 <- -0.75 * scale(x2)[,1] * 8 + rnorm(n, 60, 4)

# Weak correlation (r ≈ 0.15)
x3 <- rnorm(n, 50, 10)
y3 <- 0.15 * scale(x3)[,1] * 8 + rnorm(n, 60, 8)

# No correlation (r ≈ 0)
x4 <- rnorm(n, 50, 10)
y4 <- rnorm(n, 60, 8)

# Create combined dataset
data_patterns <- data.frame(
  x = c(x1, x2, x3, x4),
  y = c(y1, y2, y3, y4),
  pattern = rep(c("Strong Positive (r ≈ +0.85)", "Strong Negative (r ≈ -0.75)", 
                  "Weak Positive (r ≈ +0.15)", "No Correlation (r ≈ 0)"), each = n)
)

# Create the visualization
ggplot(data_patterns, aes(x = x, y = y)) +
  geom_point(alpha = 0.7, size = 2, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1) +
  facet_wrap(~pattern, ncol = 2, scales = "free") +
  labs(
    title = "Understanding Correlation Patterns in Criminology Data",
    subtitle = "How data points cluster around the trend line indicates correlation strength",
    x = "Predictor Variable (e.g., socioeconomic status)",
    y = "Outcome Variable (e.g., crime rate)",
    caption = "Note: Shaded area shows confidence interval around regression line"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11),
    strip.text = element_text(size = 10, face = "bold"),
    axis.title = element_text(size = 10),
    plot.caption = element_text(size = 9, style = "italic")
  )
```

**Key Interpretation Points:**
- **Strong Positive**: Points cluster tightly around upward-sloping line
- **Strong Negative**: Points cluster tightly around downward-sloping line  
- **Weak Correlation**: Points scattered widely around trend line
- **No Correlation**: No discernible linear pattern, flat or chaotic arrangement

### Regression Line Components

```{r regression-components, echo=TRUE, fig.width=10, fig.height=6}
# Create example regression data
set.seed(456)
x_reg <- seq(10, 50, length.out = 30)
y_reg <- 15 + 0.8 * x_reg + rnorm(30, 0, 4)

# Calculate regression line
model <- lm(y_reg ~ x_reg)
intercept <- coef(model)[1]
slope <- coef(model)[2]

# Create regression visualization
ggplot(data.frame(x = x_reg, y = y_reg), aes(x = x, y = y)) +
  geom_point(size = 3, alpha = 0.7, color = "darkblue") +
  geom_smooth(method = "lm", se = FALSE, color = "red", linewidth = 1.5) +
  # Highlight intercept
  geom_point(aes(x = 0, y = intercept), color = "green", size = 4, shape = 17) +
  # Add annotations
  annotate("text", x = 5, y = intercept + 3, 
           label = paste("Y-intercept =", round(intercept, 1)), 
           color = "green", size = 4, fontface = "bold") +
  annotate("text", x = 35, y = 25, 
           label = paste("Slope =", round(slope, 2)), 
           color = "red", size = 4, fontface = "bold") +
  # Add residual examples
  geom_segment(aes(x = x_reg[5], y = y_reg[5], 
                   xend = x_reg[5], yend = predict(model)[5]), 
               color = "orange", linewidth = 1, linetype = "dashed") +
  annotate("text", x = x_reg[5] + 2, y = (y_reg[5] + predict(model)[5])/2, 
           label = "Residual", color = "orange", size = 3, fontface = "bold") +
  labs(
    title = "Anatomy of a Regression Line",
    subtitle = "Understanding slope, intercept, and residuals in criminology regression",
    x = "Predictor Variable (X)",
    y = "Outcome Variable (Y)",
    caption = "Green triangle = Y-intercept | Red line = Regression line | Orange dashed = Residual (error)"
  ) +
  xlim(0, 55) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11),
    axis.title = element_text(size = 10),
    plot.caption = element_text(size = 9, style = "italic")
  )
```

**Component Explanations:**
- **Y-intercept**: Value of Y when X = 0 (may not be meaningful in all contexts)
- **Slope**: Change in Y for each 1-unit increase in X
- **Residuals**: Vertical distance between observed points and predicted line
- **R²**: Proportion of variance in Y explained by X (closer to 1.0 = better fit)

### Understanding Standard Error in Regression

**Standard Error (SE)** measures the precision of our regression estimates:

- **SE of slope**: How much the slope might vary across different samples
- **Smaller SE**: More precise estimate, narrow confidence intervals
- **Larger SE**: Less precise estimate, wide confidence intervals
- **95% CI**: Slope ± (1.96 × SE) gives the range we're 95% confident contains the true population slope

In criminology: A small SE for the relationship between unemployment and crime suggests this relationship is precisely estimated and likely reliable across different communities.

## APA-Style Regression Results Table

```{r apa-table, echo=TRUE}
# Create example regression results for criminology research
regression_results <- data.frame(
  Predictor = c("(Intercept)", "Unemployment Rate", "Population Density", "Education Level"),
  B = c(45.23, 2.14, 0.003, -1.87),
  SE = c(8.91, 0.45, 0.001, 0.62),
  t = c(5.08, 4.76, 3.00, -3.02),
  p = c("< .001", "< .001", ".003", ".003"),
  CI_Lower = c(27.75, 1.26, 0.001, -3.08),
  CI_Upper = c(62.71, 3.02, 0.005, -0.66)
)

# Create APA-style table using flextable
apa_table <- flextable(regression_results) %>%
  set_header_labels(
    Predictor = "Predictor",
    B = "B",
    SE = "SE", 
    t = "t",
    p = "p",
    CI_Lower = "95% CI Lower",
    CI_Upper = "95% CI Upper"
  ) %>%
  add_header_lines("Table 1. Regression Analysis Predicting Crime Rate per 1,000 Residents") %>%
  align(align = "center", part = "all") %>%
  align(j = 1, align = "left", part = "body") %>%
  fontsize(size = 10, part = "all") %>%
  fontsize(size = 12, part = "header") %>%
  bold(part = "header") %>%
  autofit() %>%
  add_footer_lines(c(
    "Note. N = 150 cities. R² = .67, F(3, 146) = 98.45, p < .001.",
    "B = unstandardized regression coefficient; SE = standard error; CI = confidence interval.",
    "All continuous predictors were centered before analysis."
  )) %>%
  fontsize(size = 9, part = "footer") %>%
  italic(part = "footer")

apa_table
```

## Interpretation Guide for Criminology Research

### Effect Size Guidelines (Cohen's Conventions)
- **Small correlation**: r = .10 (1% of variance explained)
- **Medium correlation**: r = .30 (9% of variance explained)  
- **Large correlation**: r = .50 (25% of variance explained)

### Practical Significance vs Statistical Significance
- **Statistical significance**: p < .05 (relationship unlikely due to chance)
- **Practical significance**: Effect size large enough to matter in real-world applications
- **Example**: r = .15, p < .001 in large sample may be statistically significant but practically small

### Common Interpretation Pitfalls
1. **Correlation ≠ Causation**: High correlation doesn't prove one variable causes another
2. **Third variables**: Alternative explanations may account for observed relationships
3. **Restriction of range**: Limited variability can artificially reduce correlations
4. **Outliers**: Extreme scores can inflate or deflate correlation coefficients
5. **Non-linear relationships**: Correlation assumes linear associations

Note: This file reformats questions from `Complete_Course_Questions.Rmd` to match the MCQ style used in `All quesion/basisbegrippen_statistiek.Rmd`. For items that normally require visuals, the phrasing is conceptual.


### Module 1: Correlation Basics (42 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q1 | What is correlation? | Remember |
| Q2 | What is regression? | Remember |
| Q3 | Variable types for correlation | Understand |
| Q4 | Correlation vs causation basics | Understand |
| Q5 | What is a z-score? | Remember |
| Q6 | Interpreting correlation values | Understand |
| Q7 | Key measures in correlation | Remember |
| Q8 | Direction of relationships | Understand |
| Q9 | What does correlation tell us? | Understand |
| Q10 | Correlation vs regression differences | Apply |
| Q11 | Regression slope meaning | Understand |
| Q12 | Regression intercept meaning | Remember |
| Q13 | R² interpretation | Understand |
| Q14 | Why square residuals? | Analyze |
| Q15 | Correlation-regression connection | Understand |
| Q16 | Zero correlation and slope | Apply |
| Q17 | Correlation and causation | Evaluate |
| Q18 | Why standardize? | Understand |
| Q19 | Center in z‑scores | Remember |
| Q20 | Anscombe's Quartet | Understand |
| Q21 | Correlation ≠ Causation | Analyze |
| Q22 | Monotone vs. linear | Apply |
| Q23 | Units don't change r | Remember |
| Q24 | Z‑scores compare axes | Understand |
| Q25 | Subgroups vs. overall r | Analyze |
| Q26 | Quadrants and sign | Understand |
| Q27 | Direction and strength | Apply |
| Q28 | Outlier impact | Analyze |
| Q29 | Covariance vs correlation | Understand |
| Q30 | Weak positive | Apply |
| Q31 | Describe the pattern | Understand |
| Q32 | Meaning of z = +1.2 | Remember |
| Q33 | Aggregation pitfall | Analyze |
| Q35 | Evaluate conflicting study results | Evaluate |
| Q36 | Critique visualization design | Evaluate |
| Q37 | Assess statistical claims | Evaluate |
| Q38 | Judge research methodology | Evaluate |
| Q39 | Evaluate model assumptions | Evaluate |
| Q40 | Design a correlation study | Create |
| Q41 | Create research hypothesis | Create |
| Q42 | Construct interpretation | Create |
| Q43 | Design visualization | Create |


---

# Module 1: Correlation Basics (34 questions)

## REMEMBER LEVEL (7 vragen)

### Vraag Q1 (Remember)
**What is correlation?**

> **Hint:** Think about how two criminological variables move together — for example, unemployment and crime rate — not about cause and effect.

A measure of how much one variable causes another
"1" = "❌ Incorrect. This is a common misconception in criminological research. Correlation shows that two variables change together, but it does not prove that one causes the other. For instance, neighborhoods with high unemployment often have higher crime rates, but this may result from a third factor such as poverty, social disorganization, or weak informal control."

A statistical measure of the strength and direction of the relationship between two variables
"2" = "✅ Correct! Correlation quantifies how strongly and in what direction two quantitative variables are related. A positive correlation (e.g., r = +0.68 between unemployment and property crime) means higher unemployment is associated with higher crime, while a negative correlation (e.g., r = –0.55 between police visibility and disorder) means that as one increases, the other decreases."

The difference between two variables
"3" = "❌ Incorrect. Taking a difference (Y – X) only measures a gap, not whether the variables vary together. For example, the difference between theft and assault rates says nothing about whether these crimes rise or fall together. Correlation examines co-variation — how much both variables deviate from their means in the same or opposite direction."

A method to predict future values
"4" = "❌ Incorrect. That’s regression analysis, not correlation. Regression allows criminologists to predict, for example, the expected crime rate for a given unemployment level. Correlation only summarizes how two variables are related at one point in time — it cannot make predictions or prove causation."

---

### Vraag Q2 (Remember)
**What is regression?**

> **Hint:** Think about predicting crime outcomes from known factors — for example, predicting recidivism rates from employment status or predicting neighborhood crime from socioeconomic indicators.

1) The same thing as correlation  
"1" = "❌ Incorrect. While correlation and regression are mathematically related, they serve different purposes in criminological research. Correlation tells us that two variables move together (e.g., poverty and crime rates are correlated), but regression allows us to make specific predictions (e.g., 'For every 1% increase in unemployment, we predict property crime will increase by 2.3 incidents per 1,000 residents'). Correlation is symmetric (X relates to Y the same way Y relates to X), while regression is directional (we predict Y from X)."
2) A statistical method to predict one variable from another using a linear equation  
"2" = "✅ Correct! Regression creates prediction equations like Y = a + bX that allow criminologists to forecast outcomes. For example, a regression equation might predict recidivism probability from factors like age at first arrest, number of prior convictions, and employment status. The equation gives us the expected value of the outcome variable (Y) for any given value of the predictor variable (X), making it invaluable for risk assessment and policy planning."
3) A way to calculate averages  
"3" = "❌ Incorrect. While regression uses means in its calculations, its primary purpose is prediction, not averaging. If we only wanted averages, we wouldn't need the complexity of regression analysis. Regression tells us how the average of Y changes as X changes — for example, how the average number of arrests changes as neighborhood poverty levels increase. Simple averaging would lose this crucial relationship information."
4) A method only used for categorical variables  
"4" = "❌ Incorrect. Regression typically uses continuous variables as predictors and outcomes. In criminology, we often regress continuous outcomes (crime rates, sentence length, number of prior arrests) on continuous predictors (age, income, education years). While there are specialized regression techniques for categorical outcomes (like logistic regression for guilty/not guilty), basic linear regression works with quantitative variables."

---

### Vraag Q5 (Remember)
**What is a z-score?**

> **Hint:** Think about comparing crime statistics across different jurisdictions or time periods — how do we know if a crime rate is unusually high or low relative to the typical pattern?

1) The raw score minus the mean  
"1" = "❌ Incorrect. This gives you a deviation score, which tells you how far above or below the mean a value is, but doesn't account for the variability in your data. For example, if the mean crime rate is 50 per 1,000 and a city has 60 per 1,000, the deviation is +10. But we can't judge if this is 'a lot' without knowing whether crime rates typically vary by ±2 or ±20 around the mean. The z-score standardizes this by dividing by the standard deviation."
2) A score that shows how many standard deviations a value is from the mean  
"2" = "✅ Correct! Z-scores standardize values using the formula z = (X - μ)/σ, allowing meaningful comparisons across different variables or time periods. For example, if a city's violent crime rate has z = +2.1, this means it's 2.1 standard deviations above the average for all cities — an unusually high rate. Z-scores let us compare 'how unusual' different crime types are: a burglary rate with z = +1.5 and an assault rate with z = +0.8 both indicate above-average crime, but burglary is more extremely elevated."
3) The percentage above the mean  
"3" = "❌ Incorrect. Z-scores are expressed in standard deviation units, not percentages. However, z-scores can be converted to percentiles using the normal distribution. For instance, z = +1.0 corresponds to about the 84th percentile (meaning 84% of values fall below this point), but the z-score itself isn't a percentage. In criminology, this distinction matters when interpreting risk assessments or comparing crime statistics across jurisdictions."
4) The square of the original score  
"4" = "❌ Incorrect. Squaring a score would dramatically change its scale and lose information about whether the original value was above or below the mean. Z-scores preserve the relative position while standardizing the scale. If we squared crime rates, a city with 100 crimes per 1,000 would become 10,000 — completely changing the meaning and making comparisons impossible."

---

### Vraag Q7 (Remember)
**What are the key measures in correlation analysis?**

> **Hint:** When studying the relationship between two crime-related variables, what statistics do you need to fully understand and report the association?

1) Only the correlation coefficient (r)  
"1" = "❌ Incorrect. While r is the primary measure, reporting only r provides incomplete information for criminological research. You also need to know how much variance is explained (R²) and whether your sample size (n) is large enough to trust the result. For example, r = 0.40 between police presence and crime reduction might seem meaningful, but if n = 8 cities, the result is unreliable. Professional criminological research requires reporting all three statistics."
2) Correlation coefficient (r), coefficient of determination (R²), and sample size (n)  
"2" = "✅ Correct! These three provide complete information about the relationship. The correlation coefficient (r) tells you the strength and direction (-1 to +1), R² tells you the percentage of variance explained (r² × 100%), and sample size (n) indicates reliability. For example: 'Police visibility and disorder showed a moderate negative correlation (r = -0.45, R² = 0.20, n = 150 neighborhoods), indicating that 20% of the variation in disorder can be explained by police presence levels.' This gives readers all the information needed to evaluate the finding."
3) Only the mean and standard deviation  
"3" = "❌ Incorrect. Means and standard deviations describe individual variables but don't capture the relationship between two variables. You could have identical means and standard deviations for unemployment and crime rates across two different studies, but completely different correlations (r = +0.80 vs. r = -0.20). Correlation analysis specifically examines how variables co-vary, which requires different statistics than basic descriptive measures."
4) The slope and intercept  
"4" = "❌ Incorrect. Slope and intercept are regression parameters, not correlation measures. While regression and correlation are related (slope = r × sy/sx), they serve different purposes. Correlation summarizes the strength of association; regression provides prediction equations. In criminology, you might report correlation when studying whether two crime types tend to occur together, but regression when predicting future crime rates from demographic factors."

---

### Vraag Q12 (Remember)
**What does the intercept (a) represent in regression?**

> **Hint:** In a regression predicting crime rates from unemployment, what would the intercept tell you about crime when unemployment = 0%?

1) The predicted value of Y when X = 0  
"1" = "✅ Correct! The intercept is the predicted Y-value when X equals zero. However, in criminological research, be careful about interpreting this literally — often X = 0 isn't realistic or meaningful. For example, in a regression predicting crime rate from unemployment percentage, the intercept represents predicted crime when unemployment = 0%, which may not reflect any real community. The intercept is mathematically necessary for the equation but may not have practical meaning. Always consider whether X = 0 is within the range of your data and makes sense in your research context."
2) The strength of the correlation  
"2" = "❌ Incorrect. The intercept is a parameter of the regression equation, not a measure of relationship strength. Correlation strength is measured by r (or R² in regression). You could have identical correlation strengths (r = 0.60) between two studies of crime and poverty, but very different intercepts depending on how the variables are scaled. For example, crime measured per 1,000 vs. per 100,000 residents would give different intercepts but the same correlation."
3) The total error in prediction  
"3" = "❌ Incorrect. Prediction error is captured by residuals — the differences between observed and predicted values. The intercept is part of the prediction equation itself, not a measure of how wrong the predictions are. Total prediction error would be summarized by statistics like the standard error of estimate or mean squared error. In criminology, large residuals might indicate that important predictors are missing from your model (e.g., if you predict crime from demographics but ignore economic factors)."
4) The average value of Y  
"4" = "❌ Incorrect. The intercept equals the mean of Y only in the special case where the mean of X equals zero, which is rare in criminological data. For example, if you're predicting crime rates from years of education, the intercept would equal average crime rate only if average education were 0 years — clearly unrealistic. The relationship is: mean of Y = intercept + slope × mean of X. To avoid confusion, many researchers center their X variables (subtract the mean) so the intercept becomes more interpretable."

---

### Vraag Q19 (Remember)
**Where is the 'center of gravity' in a standardized (z‑score) scatterplot?**

> **Hint:** When you convert crime variables to z-scores (e.g., standardized burglary rates and standardized unemployment rates), where do the means intersect?

1) (0, 0) — intersection of mean lines  
"1" = "✅ Correct! When variables are standardized to z-scores, both means become 0, so the bivariate center is (0,0). This is extremely useful in criminological research for interpreting correlations visually. In a z-score scatterplot of unemployment vs. crime rates, the point (0,0) represents average unemployment and average crime. Points in the upper-right quadrant (both positive) represent above-average unemployment AND above-average crime, while points in the lower-left (both negative) represent below-average unemployment AND below-average crime. The clustering of points around this (0,0) center helps visualize the correlation strength."
2) (1, 1) — one standard deviation point  
"2" = "❌ Incorrect. The point (1,1) represents a location where both variables are one standard deviation above their means — this is not the center of the distribution. In a criminology context, if you're looking at standardized police presence and crime rates, (1,1) would represent a community with both high police presence (z = +1) and high crime (z = +1) — potentially indicating that police are deployed reactively to high-crime areas. This might be an interesting data point, but it's not the center of gravity."
3) The densest part of the cloud  
"3" = "❌ Incorrect. The 'densest part' refers to the mode (most frequent area), which isn't necessarily the mean-center. In criminological data, the mode might be skewed by clustering effects — for example, if many rural counties have similar low crime rates, creating a dense cluster away from the mean. The center of gravity is determined by means, not by where most data points cluster. This distinction matters when interpreting outliers like major cities with extreme crime rates."
4) The most frequent observed point  
"4" = "❌ Incorrect. This describes the mode, not the mean. In criminological research, data rarely clusters at exactly one point due to measurement precision and natural variation. For example, even if many neighborhoods have 'about 5 crimes per 1,000,' the exact values might be 4.8, 5.1, 4.9, etc. The mean-center (0,0) in standardized space represents the balance point of all data, not the most common value."

---

### Vraag Q23 (Remember)
**You switch X from meters to centimeters. What happens to r(X,Y)?**

> **Hint:** If you measure police patrol distance in meters vs. centimeters, or crime rates per 1,000 vs. per 100,000 residents, how does this affect the correlation with other variables?

1) r becomes 100× larger  
"1" = "❌ Incorrect. Units don't affect correlation magnitude. This is a crucial property for criminological research where variables often use different scales. For example, the correlation between 'years of education' and 'arrests per 1,000 residents' would be the same as the correlation between 'years of education' and 'arrests per 100,000 residents.' The scale change doesn't alter the underlying relationship strength. If changing units affected correlation, comparative criminological research across countries with different measurement systems would be impossible."
2) r becomes 100× smaller  
"2" = "❌ Incorrect. Again, correlation is scale-invariant. Whether you measure patrol car response time in seconds, minutes, or hours, the correlation with crime clearance rates remains identical. This property makes correlation particularly valuable for international criminological comparisons — researchers can use data measured in different units without mathematical adjustment. The relationship strength between two variables is independent of how those variables are scaled."
3) r stays exactly the same  
"3" = "✅ Correct! Correlation is unit-free and invariant to linear rescaling. This is because correlation standardizes both variables during calculation — it measures how variables move together relative to their own variability, regardless of units. In criminology, this means you can compare correlations across studies that use different measurement scales. For example, studies measuring crime rates per capita vs. per square kilometer can still have comparable correlation coefficients with demographic factors. This invariance property makes correlation a universal measure of association."
4) r becomes negative  
"4" = "❌ Incorrect. Unit changes cannot flip the direction of a relationship. If increased police presence is associated with decreased crime (negative correlation), this relationship direction remains the same whether you measure presence in officers per block, per square kilometer, or per 1,000 residents. Only the scale changes, not the fundamental pattern. A sign flip would indicate a completely different substantive relationship, which unit conversion cannot cause."

---

## UNDERSTAND LEVEL (16 vragen)

### Vraag Q3 (Understand)
**For which types of variables can you calculate Pearson correlation?**

> **Hint:** Consider whether you can meaningfully calculate correlation between different types of criminological variables — can you correlate gender with crime rate? Prison sentence length with recidivism likelihood?

1) Only categorical variables  
"1" = "❌ Incorrect. Pearson correlation requires numeric variables where mathematical operations (addition, subtraction, averaging) are meaningful. Categorical variables like 'type of crime' (violent, property, drug) or 'court disposition' (guilty, not guilty, plea bargain) don't have inherent numerical values. You can't meaningfully calculate an average of 'violent' and 'property' crimes. For categorical variables, you would use different measures like Cramér's V or Chi-square tests to examine associations."
2) Both variables must be continuous (interval or ratio level)  
"2" = "✅ Correct! Pearson correlation requires both variables to be measured at interval or ratio levels — numeric variables where the distances between values are meaningful and consistent. In criminology, examples include: crime rates (ratio), sentence length in months (ratio), age at first arrest (ratio), number of prior convictions (ratio), and scales measuring attitudes toward police (interval). These variables allow meaningful mathematical operations necessary for calculating means, standard deviations, and covariances that form the basis of Pearson correlation."
3) One categorical and one continuous variable  
"3" = "❌ Incorrect. When you have one categorical and one continuous variable, you use point-biserial correlation (for binary categories) or eta correlation (for multiple categories). For example, if studying the relationship between gender (categorical: male/female) and number of arrests (continuous), you would use point-biserial correlation. If examining the relationship between type of neighborhood (categorical: urban/suburban/rural) and crime rate (continuous), you might use ANOVA or eta correlation rather than Pearson correlation."
4) Any type of variables  
"4" = "❌ Incorrect. Different correlation measures exist for different variable combinations. Pearson correlation is specifically for continuous variables. Other measures include: Spearman's rho for ranked data, phi coefficient for two binary variables, Cramér's V for two categorical variables, and point-biserial for one binary and one continuous variable. Using the wrong correlation type can lead to meaningless results or serious misinterpretation of relationships in criminological research."

---

### Vraag Q4 (Understand)
**Why doesn't correlation prove causation?**

> **Hint:** Consider why a strong correlation between ice cream sales and drowning deaths, or between number of police officers and crime rates, doesn't necessarily mean one causes the other.

1) Correlation is always too weak to prove anything  
"1" = "❌ Incorrect. Even very strong correlations (r = 0.90 or higher) don't establish causation. The issue isn't the strength of the correlation but the logic of causal inference. In criminology, you might find a very strong correlation (r = 0.85) between the number of security cameras in a neighborhood and crime rates, but this doesn't prove cameras cause crime. The high correlation could exist because cameras are installed in response to high crime, not because cameras cause crime. Correlation strength and causal evidence are completely separate issues."
2) Third variables, reverse causation, or coincidence might explain the relationship  
"2" = "✅ Correct! Correlation cannot establish causal direction or rule out alternative explanations. In criminology: (1) Third variables — poverty might cause both low education and high crime, creating a spurious correlation between education and crime; (2) Reverse causation — do more police reduce crime, or does more crime lead to hiring more police? (3) Coincidence — two variables might correlate by chance, especially with small samples. Establishing causation requires controlled experiments, longitudinal designs, natural experiments, or sophisticated statistical techniques that can isolate causal effects from these alternative explanations."
3) Only experiments can show any relationships  
"3" = "❌ Incorrect. Correlation clearly shows that relationships exist — it just can't determine whether they're causal. Many important criminological relationships can't be studied experimentally for ethical reasons (you can't randomly assign people to criminal careers). Correlational studies provide valuable evidence about associations, risk factors, and patterns. While experiments provide the strongest causal evidence, observational studies using techniques like instrumental variables, regression discontinuity, or natural experiments can also provide compelling causal evidence when experiments aren't feasible."
4) Correlation is the same as causation  
"4" = "❌ Incorrect. This represents exactly the misconception that criminologists must avoid. Media reports often claim 'studies show X causes Y' when the research only demonstrated correlation. For example, finding that neighborhoods with more streetlights have less crime doesn't prove streetlights prevent crime — safer neighborhoods might simply be more likely to install streetlights. Understanding this distinction is crucial for evidence-based criminal justice policy, as implementing interventions based on correlational evidence alone can waste resources or even backfire."

---

### Vraag Q6 (Understand)
**How do you interpret a correlation of r = 0.75?**

> **Hint:** Think about what this correlation strength means for the relationship between two crime-related variables — is this a weak, moderate, or strong association?

1) Weak positive relationship  
"1" = "❌ Incorrect. An r = 0.75 represents a strong relationship, not weak. In criminological research, correlations around 0.75 are considered quite substantial. For comparison, the correlation between height and weight in adults is typically around 0.70-0.80. If you found r = 0.75 between neighborhood poverty and crime rates, this would indicate a strong positive association — as poverty increases, crime rates tend to increase substantially. This level of correlation suggests the variables share about 56% of their variance (0.75² = 0.56), which is considerable in social science research."
2) Strong positive relationship  
"2" = "✅ Correct! Values around 0.7-0.8 indicate strong positive associations in social science research. An r = 0.75 means that as one variable increases, the other tends to increase substantially in a predictable pattern. In criminology, this might represent the relationship between unemployment rates and property crime, or between drug arrests and drug overdose deaths in a community. The relationship is strong enough to be practically meaningful for policy and prediction, while still acknowledging that 44% of the variance remains unexplained by this single correlation."
3) Perfect negative relationship  
"3" = "❌ Incorrect. This interpretation has two major errors: (1) r = 0.75 is positive, not negative — the value is above zero, indicating variables move in the same direction; (2) 0.75 is strong but not perfect — a perfect correlation would be r = ±1.00. A perfect negative correlation (r = -1.00) means that as one variable increases, the other decreases in exact proportion, with no exceptions. In criminology, perfect correlations are virtually impossible due to the complexity of human behavior and measurement error."
4) No relationship  
"4" = "❌ Incorrect. An r = 0.75 indicates a strong relationship, not the absence of one. 'No relationship' would be indicated by r ≈ 0.00. To put r = 0.75 in perspective, many important relationships in criminology are weaker than this — for example, the correlation between individual criminal attitudes and actual criminal behavior might be r = 0.30-0.50. Finding r = 0.75 between two crime-related variables would be considered a substantial and practically important association worthy of further investigation and potential policy consideration."

---

### Vraag Q8 (Understand)
**What does the direction of a correlation tell you?**

> **Hint:** Think about whether variables move together in the same direction (both increase together) or in opposite directions (one increases while the other decreases) in criminological research.

1) How strong the relationship is  
"1" = "❌ Incorrect. Direction (positive vs. negative) and strength (how close to ±1.00) are separate aspects of correlation. The direction is indicated by the sign (+ or -), while strength is indicated by the absolute value. For example, r = +0.80 and r = -0.80 have equal strength but opposite directions. In criminology, both the direction and strength matter: r = -0.70 between police patrol frequency and burglary rates (strong negative — more patrols, fewer burglaries) tells a different story than r = +0.70 between unemployment and burglary rates (strong positive — more unemployment, more burglaries)."
2) Whether variables increase together (positive) or one increases as the other decreases (negative)  
"2" = "✅ Correct! Direction indicates the pattern of co-variation between variables. Positive correlations (+) mean variables move in the same direction: as neighborhood income increases, property values increase; as drug availability increases, drug arrests increase. Negative correlations (-) mean variables move in opposite directions: as police visibility increases, street crime decreases; as education levels increase, recidivism rates decrease. Understanding direction is crucial for criminological theory and policy — it tells you whether factors work as risk factors (positive correlation with crime) or protective factors (negative correlation with crime)."
3) Whether the relationship is causal  
"3" = "❌ Incorrect. Direction cannot determine causality — that requires additional evidence beyond correlation. A negative correlation between police presence and crime rates could mean: (1) police reduce crime (causal), (2) high crime areas get more police (reverse causation), or (3) both are influenced by a third factor like neighborhood wealth (spurious correlation). Similarly, a positive correlation between broken windows and crime doesn't prove broken windows cause crime — both might result from neighborhood disinvestment. Causal direction requires experimental evidence, temporal sequencing, or sophisticated statistical controls."
4) How many observations are in the dataset  
"4" = "❌ Incorrect. The correlation direction is independent of sample size (n). You could have r = +0.60 with n = 30 cities or n = 3,000 cities — the positive direction remains the same. Sample size affects the reliability and statistical significance of the correlation, but not its direction. However, larger samples do provide more stable estimates of the correlation's direction and magnitude, which is why criminological studies often try to include many jurisdictions or time periods when possible."

---

### Vraag Q9 (Understand)
**What does a correlation tell us?**

> **Hint:** Focus on what correlation actually measures — how two criminological variables tend to vary together, not what causes what.

1) How much one variable causes the other  
"1" = "❌ Incorrect. Correlation measures association, not causation. This is a critical distinction in criminological research. For example, a correlation between single-parent households and juvenile delinquency doesn't tell us that single-parent families cause delinquency — both might be influenced by poverty, neighborhood factors, or other variables. Correlation tells us these variables tend to occur together, but determining causal relationships requires additional evidence like experimental studies, natural experiments, or longitudinal research with proper controls. Confusing correlation with causation leads to misguided policies and interventions."
2) The direction and strength of a linear relationship between two variables  
"2" = "✅ Correct! Correlation quantifies how consistently and strongly two variables move together in a straight-line pattern. The correlation coefficient (r) captures both direction (positive/negative sign) and strength (absolute value from 0 to 1). In criminology, this might tell us that unemployment rates and property crime rates tend to increase together (positive direction) in a moderately strong pattern (e.g., r = +0.45). This information is valuable for understanding risk factors, developing prevention strategies, and identifying communities that might benefit from interventions, even though it doesn't prove causation."
3) The difference between two group means  
"3" = "❌ Incorrect. Comparing group means uses t-tests or ANOVA, not correlation. For example, comparing average recidivism rates between offenders who received job training vs. those who didn't would use a t-test to examine the difference in means. Correlation examines how two continuous variables co-vary (e.g., how individual recidivism risk scores relate to actual reoffending frequency). The statistical approaches and interpretations are completely different — group comparisons focus on differences between categories, while correlation focuses on linear relationships between continuous measures."
4) The total variance in one variable  
"4" = "❌ Incorrect. Total variance describes the spread of a single variable around its mean, calculated as the standard deviation squared. Correlation examines shared variance between two variables — how much they vary together. The coefficient of determination (R² = r²) tells us the proportion of variance in one variable that's predictable from the other variable. For example, if r = 0.60 between neighborhood poverty and crime rates, then R² = 0.36, meaning 36% of the variance in crime rates is associated with poverty levels, while 64% remains unexplained."

---

### Vraag Q11 (Understand)
**In a simple regression model, what does the slope (b) represent?**

> **Hint:** Think: how much does Y change when X changes by one unit?

1) The predicted value of Y when X = 0  
"1" = "❌ Incorrect. That's the intercept (a)."
2) The amount Y changes for each one-unit increase in X  
"2" = "✅ Correct! The slope shows the expected change in Y for a unit change in X."
3) The variability of Y around its mean  
"3" = "❌ Incorrect. That describes variance, not slope."
4) The strength of correlation  
"4" = "❌ Incorrect. Slope and correlation are related but not identical."

---

### Vraag Q13 (Understand)
**What does R² tell us in regression?**

> **Hint:** Think about explained variance.

1) The proportion of variance in Y explained by X  
"1" = "✅ Correct! R² quantifies how much of Y's variation the model explains."
2) The residual variance left unexplained  
"2" = "❌ Incorrect. That's (1 − R²)."
3) The slope of the regression line  
"3" = "❌ Incorrect. Slope (b) and R² are different statistics."
4) The total correlation between all variables  
"4" = "❌ Incorrect. R² is derived from one correlation (r²) in simple regression."

---

### Vraag Q15 (Understand)
**How are correlation and regression mathematically connected?**

> **Hint:** Think about formulas linking r, b, and R².

1) b = r × (Sx / Sy)  
"1" = "❌ Incorrect. The ratio is reversed."
2) b = r × (Sy / Sx)  
"2" = "✅ Correct! The regression slope equals correlation × ratio of standard deviations."
3) r = b × (Sy / Sx)  
"3" = "❌ Incorrect. That's the inverse relation."
4) R² = b × r  
"4" = "❌ Incorrect. R² = r², not b × r."

---

### Vraag Q18 (Understand)
**Why is standardizing (using z‑scores) useful when comparing two variables?**

> **Hint:** Consider unit effects on covariance and correlation as a unit‑free measure.

1) The relationship fundamentally changes when units change  
"1" = "❌ Incorrect. Units don't change the underlying relationship; only covariance's magnitude."
2) The relationship stays the same, but covariance isn't comparable across units  
"2" = "✅ Correct! Correlation (r) is standardized and unit‑free; covariance isn't."
3) Covariance is always better than correlation  
"3" = "❌ Incorrect. Covariance is scale‑dependent; correlation is scale‑invariant."
4) You should never standardize variables  
"4" = "❌ Incorrect. Standardizing is useful to put variables on the same scale."

---

### Vraag Q20 (Understand)
**What is the main lesson of Anscombe's Quartet?**

> **Hint:** Four datasets can share identical summaries yet have very different shapes.

1) Correlation tells the whole story  
"1" = "❌ Incorrect. Identical r can arise from very different patterns."
2) Always plot your data first  
"2" = "✅ Correct! Visualization avoids being misled by summaries alone."
3) Graphs are less reliable than statistics  
"3" = "❌ Incorrect. Plots complement statistics; both matter."
4) Linear relationships are the most common  
"4" = "❌ Incorrect. The quartet shows diverse structures with the same r."

---

### Vraag Q24 (Understand)
**Why do z‑scores make axes more comparable in a scatterplot?**

> **Hint:** Consider "same scale" and "standard deviations".

1) They put both variables into SD units  
"1" = "✅ Correct! Standardizing places both on the same scale."
2) They always increase the correlation  
"2" = "❌ Incorrect. Standardizing doesn't change r."
3) They remove all outliers  
"3" = "❌ Incorrect. They may help detect outliers, not remove them."
4) They make covariance unit‑free  
"4" = "❌ Incorrect. Correlation is unit‑free; covariance remains scale‑dependent."

---

### Vraag Q26 (Understand)
**Which quadrants dominate under a positive association (in z‑scores)?**

> **Hint:** Consider the signs of z(X) and z(Y).

1) Mostly quadrants I & III  
"1" = "✅ Correct! Positive: both above or both below their means."
2) Mostly quadrants II & IV  
"2" = "❌ Incorrect. That indicates negative association."
3) Evenly spread across all quadrants  
"3" = "❌ Incorrect. Suggests little/no linear relationship."
4) Only quadrant I  
"4" = "❌ Incorrect. Quadrant III also occurs in positive association."

---

### Vraag Q29 (Understand)
**Which statement about covariance and correlation is true?**

> **Hint:** Watch for units and ranges.

1) Covariance is unit‑free and bounded −1 to +1  
"1" = "❌ Incorrect. That's correlation, not covariance."
2) Correlation is unit‑free and always between −1 and +1  
"2" = "✅ Correct! That's why r is comparable across variables."
3) Both are unbounded  
"3" = "❌ Incorrect. Only covariance is unbounded."
4) Both depend on measurement scale  
"4" = "❌ Incorrect. Only covariance is scale‑dependent."

---

### Vraag Q31 (Understand)
**"As X increases, Y tends to …" — choose the best completion for a slightly increasing pattern.**

> **Hint:** Use the standard sentence for a weak upward trend.

1) … decrease, strongly  
"1" = "❌ Incorrect. Wrong direction."
2) … increase, weakly  
"2" = "✅ Correct! Weakly increasing relationship."
3) … increase, very strongly  
"3" = "❌ Incorrect. 'Very strong' doesn't fit a slight increase."
4) … stay the same  
"4" = "❌ Incorrect. That implies no linear relationship."

---

### Vraag Q32 (Remember)
**What does z = +1.2 mean in plain words?**

> **Hint:** Relate to the mean and standard deviation.

1) 1.2 units above the mean  
"1" = "❌ Incorrect. They are SD units, not raw units."
2) 1.2 standard deviations above the mean  
"2" = "✅ Correct! That's the definition of a positive z."
3) 1.2% above the mean  
"3" = "❌ Incorrect. Not a percentage."
4) 0.12 standard deviations above the mean  
"4" = "❌ Incorrect. Wrong magnitude."

---

### Vraag Q34 (Understand)
**Which statement best summarizes when to proceed from correlation concepts to calculations?**

> **Hint:** Consider the foundation needed before computation.

1) Only after mastering all statistical theory  
"1" = "❌ Incorrect. Some practical work can proceed in parallel with theory."
2) After understanding what correlation measures and how to interpret it  
"2" = "✅ Correct! Conceptual understanding should precede mechanical calculation."
3) Calculations should come before understanding concepts  
"3" = "❌ Incorrect. Understanding concepts first helps prevent misinterpretation."
4) Theory and practice are completely unrelated  
"4" = "❌ Incorrect. Theory guides proper application of calculations."

---

## APPLY LEVEL (6 vragen)

### Vraag Q10 (Apply)
**Which statement correctly distinguishes correlation and regression?**

> **Hint:** Think about the difference between saying "police presence and crime are related" versus "we can predict crime levels from police presence data."

1) Correlation is asymmetric, regression is symmetric  
"1" = "❌ Incorrect. This is backwards. Correlation is symmetric — r(X,Y) = r(Y,X). The correlation between police presence and crime rates is the same regardless of which variable you consider first. Regression is asymmetric because it matters which variable you're predicting (Y) from which predictor (X). Regressing crime on police presence gives a different equation than regressing police presence on crime, even though the correlation between them is identical. In criminology, this distinction matters when developing predictive models versus simply documenting associations."
2) Correlation measures mutual association; regression predicts Y from X  
"2" = "✅ Correct! Correlation quantifies how two variables are related without implying direction — it's a symmetric measure of association. Regression creates directional prediction equations that allow you to estimate one variable from another. In criminological research, correlation might tell you that neighborhood poverty and crime rates are strongly related (r = 0.65), while regression tells you that each 1% increase in poverty is associated with 2.3 additional crimes per 1,000 residents. Correlation describes relationships; regression enables prediction and policy modeling."
3) Regression only applies to categorical data  
"3" = "❌ Incorrect. Basic linear regression typically uses continuous variables for both predictors and outcomes. In criminology, we often regress continuous outcomes (crime rates, sentence lengths, recidivism probabilities) on continuous predictors (age, income, education, prior arrests). While specialized regression techniques exist for categorical outcomes (logistic regression for binary outcomes, multinomial regression for multiple categories), the most common regression applications in criminological research use continuous variables measured at interval or ratio levels."
4) Correlation and regression are identical analyses  
"4" = "❌ Incorrect. While mathematically related (the slope in simple regression equals r × sy/sx), they serve different purposes and provide different information. Correlation gives you a standardized measure of association (-1 to +1) that's easy to interpret and compare across studies. Regression gives you prediction equations with specific units that depend on how your variables are measured. In policy research, you might use correlation to identify promising relationships to investigate further, then use regression to develop specific prediction models for resource allocation or risk assessment."

---

### Vraag Q16 (Apply)
**If the correlation between X and Y is zero, what does the regression slope (b) equal?**

> **Hint:** Recall the link between r and b.

1) b = 0  
"1" = "✅ Correct! When r = 0, the regression slope is zero — no linear prediction."
2) b = 1  
"2" = "❌ Incorrect. That would mean a perfect positive relationship."
3) b = −1  
"3" = "❌ Incorrect. That would mean a perfect negative relationship."
4) b cannot be computed  
"4" = "❌ Incorrect. It can be computed, but will be 0."

---

### Vraag Q22 (Apply)
**The relationship is curved but monotonically increasing. Which correlation should you choose?**

> **Hint:** Distinguish "linear" from "monotone".

1) Pearson correlation  
"1" = "❌ Incorrect. Pearson measures linear association and may underestimate strength."
2) Spearman correlation  
"2" = "✅ Correct! Spearman captures monotone relationships via ranks."
3) Both are equally appropriate  
"3" = "❌ Incorrect. Spearman fits better here."
4) Neither  
"4" = "❌ Incorrect. Spearman is suitable for monotone, non‑linear patterns."

---

### Vraag Q27 (Apply)
**A straight trend line slopes upward; points cluster tightly. Which description fits best?**

> **Hint:** Combine direction (sign) with strength (spread).

1) Strong positive  
"1" = "✅ Correct! Upward line + tight cluster → strong positive."
2) Moderate positive  
"2" = "❌ Incorrect. Description suggests stronger than moderate."
3) Weak negative  
"3" = "❌ Incorrect. Direction is positive, not negative."
4) No linear pattern  
"4" = "❌ Incorrect. The pattern is clearly linear."

---

### Vraag Q30 (Apply)
**Which r value best matches 'weak positive'?**

> **Hint:** Use common interpretation guidelines.

1) r = 0.12  
"1" = "✅ Correct! Often interpreted as weak positive."
2) r = 0.56  
"2" = "❌ Incorrect. Closer to moderate."
3) r = −0.72  
"3" = "❌ Incorrect. Strong negative, not weak positive."
4) r = 0.93  
"4" = "❌ Incorrect. Very strong positive."

---

### Vraag Q34 (Apply)
**Which statement best summarizes when to proceed from correlation concepts to calculations?**

> **Hint:** Consider the foundation needed before computation.

1) Only after mastering all statistical theory  
"1" = "❌ Incorrect. Some practical work can proceed in parallel with theory."
2) After understanding what correlation measures and how to interpret it  
"2" = "✅ Correct! Conceptual understanding should precede mechanical calculation."
3) Calculations should come before understanding concepts  
"3" = "❌ Incorrect. Understanding concepts first helps prevent misinterpretation."
4) Theory and practice are completely unrelated  
"4" = "❌ Incorrect. Theory guides proper application of calculations."

---

## ANALYZE LEVEL (5 vragen)

### Vraag Q14 (Analyze)
**Why do we square the residuals when fitting the regression line (OLS method)?**

> **Hint:** Consider the role of positive and negative errors.

1) To make all errors positive and penalize large deviations more heavily  
"1" = "✅ Correct! Squaring ensures positive values and emphasizes larger errors."
2) To simplify the formula for correlation  
"2" = "❌ Incorrect. Squaring is for model fitting, not correlation."
3) To reduce the number of data points  
"3" = "❌ Incorrect. The sample size remains unchanged."
4) Because residuals are always negative  
"4" = "❌ Incorrect. Residuals can be both positive and negative."

---

### Vraag Q21 (Analyze)
**Headline: "Ice cream sales and drownings are strongly correlated." What's a plausible explanation?**

> **Hint:** Think of a third variable (confounder) driving both.

1) Ice cream causes drownings  
"1" = "❌ Incorrect. Correlation ≠ causation."
2) Drownings cause higher ice cream sales  
"2" = "❌ Incorrect. Reverse causality isn't plausible here."
3) Temperature/season increases both  
"3" = "✅ Correct! Warm weather raises ice cream sales and swimming activity."
4) There is no relationship at all  
"4" = "❌ Incorrect. There is an association, just not causal."

---

### Vraag Q25 (Analyze)
**A scatterplot colors points by 'neighborhood type'. How is the overall correlation r typically computed?**

> **Hint:** Compare subgroup calculations versus full sample.

1) Using only the largest subgroup  
"1" = "❌ Incorrect. That ignores many cases."
2) As the average of subgroup correlations  
"2" = "❌ Incorrect. A simple mean of subgroup r's isn't standard."
3) Using all points together, ignoring colors  
"3" = "✅ Correct! By default r is computed on the full dataset."
4) As a weighted average of subgroup r's  
"4" = "❌ Incorrect. Not the default definition of r."

---

### Vraag Q28 (Analyze)
**In a positive trend, which outlier position most reduces r?**

> **Hint:** Think of points that break the linear pattern.

1) Far bottom‑left (low X, very low Y)  
"1" = "❌ Incorrect. That aligns with the positive trend."
2) Far bottom‑right (high X, low Y)  
"2" = "✅ Correct! Pulls the cloud off the line and lowers r."
3) Far top‑right (high X, high Y)  
"3" = "❌ Incorrect. Often increases a positive r."
4) A point exactly on the line  
"4" = "❌ Incorrect. Minimal impact on r."

---

### Vraag Q33 (Analyze)
**Subgroup colors on the plot: what's a risk of looking only at overall r?**

> **Hint:** Think Simpson's paradox and heterogeneity across groups.

1) Subgroup patterns can mask or reverse the overall pattern  
"1" = "✅ Correct! Aggregation can mislead; inspect subgroups."
2) r always changes when you add colors  
"2" = "❌ Incorrect. r's calculation ignores colors."
3) r can never be misleading  
"3" = "❌ Incorrect. r without context can mislead."
4) Subgroups automatically increase r  
"4" = "❌ Incorrect. No such general rule."

---

## EVALUATE LEVEL (5 vragen)

### Vraag Q35 (Evaluate)
**Two criminology studies show conflicting results about the relationship between poverty and crime rates. Study A (N=50) reports r = 0.72, p < 0.001. Study B (N=5000) reports r = 0.18, p < 0.001. Which study provides more trustworthy evidence?**

> **Hint:** Consider sample size, effect size, statistical significance, and practical significance.

1) Study A because it has a stronger correlation  
"1" = "❌ Incorrect. Larger correlation doesn't automatically mean better evidence."
2) Study B because of the much larger sample size providing more reliable estimates  
"2" = "✅ Correct! Large N gives more stable, generalizable estimates despite smaller effect."
3) Both are equally valid since both are statistically significant  
"3" = "❌ Incorrect. Statistical significance doesn't guarantee practical importance or reliability."
4) Neither because correlational studies can't establish causation  
"4" = "❌ Incorrect. While true about causation, the question asks about trustworthy evidence for the relationship strength."

---

### Vraag Q36 (Evaluate)
**A researcher creates a scatterplot showing "Age vs. Criminal Offenses" with the following design choices: logarithmic Y-axis, different colors for gender, and a fitted polynomial curve. Evaluate this visualization approach.**

> **Hint:** Consider appropriateness of scale transformations, grouping variables, and model complexity.

1) Excellent design that enhances all aspects of the analysis  
"1" = "❌ Incorrect. Some design choices may not be optimal."
2) Good use of colors for gender, but log scale and polynomial curve may overcomplicate interpretation  
"2" = "✅ Correct! Color coding is useful, but transformations should be justified and simpler models preferred initially."
3) The logarithmic scale is always inappropriate for criminology data  
"3" = "❌ Incorrect. Log scales can be useful when data spans many orders of magnitude."
4) Only linear relationships should ever be displayed in scatterplots  
"4" = "❌ Incorrect. Non-linear patterns can be meaningful, but should be justified."

---

### Vraag Q37 (Evaluate)
**A news article claims: "Strong correlation (r = 0.65) between neighborhood watch programs and reduced burglary proves these programs are highly effective crime prevention tools." Evaluate this statistical claim.**

> **Hint:** Consider correlation vs. causation, confounding variables, and research design limitations.

1) Valid conclusion - strong correlation provides sufficient evidence of effectiveness  
"1" = "❌ Incorrect. Correlation alone cannot establish causal effectiveness."
2) Invalid - correlation doesn't prove causation; neighborhood characteristics might explain both variables  
"2" = "✅ Correct! Confounders like socioeconomic status could influence both program presence and crime rates."
3) Invalid - r = 0.65 is too weak to support any conclusions  
"3" = "❌ Incorrect. The correlation strength isn't the main issue; causation vs. correlation is."
4) Valid if the sample size was large enough  
"4" = "❌ Incorrect. Sample size doesn't resolve the causation problem."

---

### Vraag Q38 (Evaluate)
**A study uses regression to predict recidivism rates from employment status, with R² = 0.23. The researchers conclude their model is "poor" because it explains less than 25% of variance. Evaluate this interpretation.**

> **Hint:** Consider what constitutes meaningful prediction in social sciences and practical applications.

1) Correct - any model explaining less than 50% of variance is useless  
"1" = "❌ Incorrect. Even modest predictive power can be valuable in social sciences."
2) Incorrect - R² = 0.23 represents meaningful predictive value in criminology research  
"2" = "✅ Correct! In complex social phenomena, even 23% explained variance can provide important insights and practical value."
3) Correct - regression requires R² > 0.80 to be considered valid  
"3" = "❌ Incorrect. No such universal threshold exists for model validity."
4) The interpretation depends entirely on the sample size  
"4" = "❌ Incorrect. While sample size affects significance, it doesn't determine what constitutes meaningful R²."

---

### Vraag Q39 (Evaluate)
**You're reviewing a study that found r = -0.43 between education level and arrest rates. The scatterplot shows clear clustering of points with some extreme outliers. How should you evaluate the reported correlation?**

> **Hint:** Consider robustness of correlation to outliers and alternative measures.

1) Accept r = -0.43 as accurate since it's statistically significant  
"1" = "❌ Incorrect. Outliers can dramatically affect Pearson correlation."
2) Question the correlation's robustness; recommend reporting both Pearson and Spearman correlations  
"2" = "✅ Correct! Outliers can distort Pearson r; Spearman correlation would be more robust to extreme values."
3) Reject the entire analysis because outliers invalidate all correlational studies  
"3" = "❌ Incorrect. Outliers don't invalidate analysis but require appropriate handling."
4) The correlation is definitely too weak to be meaningful regardless of outliers  
"4" = "❌ Incorrect. r = -0.43 represents a moderate relationship that could be practically important."

---

## CREATE LEVEL (4 vragen)

### Vraag Q40 (Create)
**Design a correlational study to investigate the relationship between social media usage and antisocial behavior in adolescents. What key design elements would you include?**

> **Hint:** Consider variables, measurement, sampling, controls, and ethical considerations.

1) Survey 100 teenagers about hours of social media use and self-reported antisocial acts  
"1" = "❌ Incomplete. Missing important design elements like control variables and measurement validity."
2) Longitudinal design measuring social media use (multiple platforms, time), antisocial behavior (multiple measures), controlling for age, SES, and family factors, with proper ethical oversight  
"2" = "✅ Correct! Comprehensive design addresses measurement, temporal aspects, confounders, and ethics."
3) Experimental manipulation where some teens are assigned high social media use  
"3" = "❌ Inappropriate. Ethical issues with manipulating potentially harmful behavior."
4) Simple correlation between total screen time and police contacts  
"4" = "❌ Too simplistic. Screen time isn't specific to social media, and police contacts don't capture full range of antisocial behavior."

---

### Vraag Q41 (Create)
**Formulate a testable research hypothesis about the relationship between economic inequality and violent crime rates at the city level, including predicted direction and strength.**

> **Hint:** Create a specific, directional hypothesis that can be tested with correlation/regression.

1) "Economic inequality affects crime somehow"  
"1" = "❌ Too vague. Lacks direction, specificity, and testability."
2) "Cities with higher income inequality (Gini coefficient) will show moderately strong positive correlations (r = 0.40-0.60) with violent crime rates per capita"  
"2" = "✅ Correct! Specific, directional, measurable hypothesis with predicted effect size."
3) "Poor people commit more violent crimes"  
"3" = "❌ Individual-level claim, not about city-level inequality patterns."
4) "Economic inequality is the sole cause of all violent crime"  
"4" = "❌ Too extreme and untestable; claims causation rather than correlation."

---

### Vraag Q42 (Create)
**Construct a comprehensive interpretation of these results: r = 0.31, R² = 0.10, p < 0.01, N = 847 for the relationship between "Community Social Cohesion" and "Property Crime Rates."**

> **Hint:** Address statistical significance, practical significance, effect size, and limitations.

1) "Significant positive relationship proves social cohesion causes more crime"  
"1" = "❌ Incorrect direction and claims causation inappropriately."
2) "Statistically significant moderate negative association (r = -0.31) indicates that communities with stronger social cohesion tend to have lower property crime rates, explaining 10% of the variance. While effect is modest, it's meaningful in criminology research and suggests social cohesion may be one protective factor among many influencing community crime levels."  
"2" = "✅ Correct! Comprehensive interpretation covering direction, significance, effect size, and appropriate caution about causation."
3) "The correlation is too weak to mean anything important"  
"3" = "❌ Incorrect. r = 0.31 represents a meaningful moderate relationship in social science."
4) "Perfect relationship between social cohesion and crime prevention"  
"4" = "❌ Incorrect. r = 0.31 is moderate, not perfect, and only explains 10% of variance."

---

### Vraag Q43 (Create)
**Design an effective data visualization to simultaneously display the relationship between three variables: neighborhood income, police presence (officers per capita), and burglary rates across 200 neighborhoods.**

> **Hint:** Consider how to represent three continuous variables effectively in one visualization.

1) Three separate scatterplots showing pairwise relationships  
"1" = "❌ Doesn't show relationships simultaneously; loses trivariate patterns."
2) Scatterplot of income vs. burglary rates with point size representing police presence, plus trend line and clear legend  
"2" = "✅ Correct! Efficiently shows all three variables and their relationships in one integrated visualization."
3) Bar chart showing average values for each neighborhood  
"3" = "❌ Loses information about relationships and individual neighborhood patterns."
4) Pie chart divided by income levels  
"4" = "❌ Inappropriate chart type for continuous variables and relationships."

---



### Question Q1 (Remember)
**What is correlation?**

> **Hint:** Think about the relationship between two variables.

1) A measure of how much one variable causes another  
"1" = "❌ Incorrect. Correlation does not establish causation."
2) A statistical measure of the strength and direction of relationship between two variables  
"2" = "✅ Correct! Correlation quantifies linear association between variables."
3) The difference between two variables  
"3" = "❌ Incorrect. That would be a simple difference, not correlation."
4) A method to predict future values  
"4" = "❌ Incorrect. That's prediction; correlation measures association."

---

### Question Q2 (Remember)
**What is regression?**

> **Hint:** Think about predicting one variable from another.

1) The same thing as correlation  
"1" = "❌ Incorrect. Regression and correlation are related but different."
2) A statistical method to predict one variable from another using a linear equation  
"2" = "✅ Correct! Regression creates prediction equations like Y = a + bX."
3) A way to calculate averages  
"3" = "❌ Incorrect. Regression involves prediction, not just averaging."
4) A method only used for categorical variables  
"4" = "❌ Incorrect. Regression typically uses continuous variables."

---

### Question Q3 (Understand)
**For which types of variables can you calculate Pearson correlation?**

> **Hint:** Consider the measurement level requirements.

1) Only categorical variables  
"1" = "❌ Incorrect. Pearson correlation requires numeric variables."
2) Both variables must be continuous (interval or ratio level)  
"2" = "✅ Correct! Pearson correlation requires numeric, continuous variables."
3) One categorical and one continuous variable  
"3" = "❌ Incorrect. This would use point-biserial correlation."
4) Any type of variables  
"4" = "❌ Incorrect. Different correlation types exist for different variable types."

---

### Question Q4 (Understand)
**Why doesn't correlation prove causation?**

> **Hint:** Think about alternative explanations for associations.

1) Correlation is always too weak to prove anything  
"1" = "❌ Incorrect. Even strong correlations don't prove causation."
2) Third variables, reverse causation, or coincidence might explain the relationship  
"2" = "✅ Correct! Many alternative explanations exist for statistical associations."
3) Only experiments can show any relationships  
"3" = "❌ Incorrect. Correlation shows association; causation requires more evidence."
4) Correlation is the same as causation  
"4" = "❌ Incorrect. This is the misconception we want to avoid."

---

### Question Q5 (Remember)
**What is a z-score?**

> **Hint:** Think about standardizing scores relative to the mean and spread.

1) The raw score minus the mean  
"1" = "❌ Incorrect. That's a deviation, not a z-score."
2) A score that shows how many standard deviations a value is from the mean  
"2" = "✅ Correct! z = (X - μ)/σ standardizes scores."
3) The percentage above the mean  
"3" = "❌ Incorrect. Z-scores use standard deviation units, not percentages."
4) The square of the original score  
"4" = "❌ Incorrect. Z-scores involve standardization, not squaring."

---

### Question Q6 (Understand)
**How do you interpret a correlation of r = 0.75?**

> **Hint:** Consider both direction and strength.

1) Weak positive relationship  
"1" = "❌ Incorrect. 0.75 is stronger than weak."
2) Strong positive relationship  
"2" = "✅ Correct! Values around 0.7-0.8 indicate strong positive association."
3) Perfect negative relationship  
"3" = "❌ Incorrect. The value is positive, not negative or perfect."
4) No relationship  
"4" = "❌ Incorrect. 0.75 shows a clear relationship."

---

### Question Q7 (Remember)
**What are the key measures in correlation analysis?**

> **Hint:** Think about the main statistics that describe correlation.

1) Only the correlation coefficient (r)  
"1" = "❌ Incorrect. There are additional important measures."
2) Correlation coefficient (r), coefficient of determination (R²), and sample size (n)  
"2" = "✅ Correct! These provide complete information about the relationship."
3) Only the mean and standard deviation  
"3" = "❌ Incorrect. These don't describe the relationship between variables."
4) The slope and intercept  
"4" = "❌ Incorrect. These are regression parameters, not correlation measures."

---

### Question Q8 (Understand)
**What does the direction of a correlation tell you?**

> **Hint:** Think about positive vs. negative relationships.

1) How strong the relationship is  
"1" = "❌ Incorrect. Direction is about sign, not strength."
2) Whether variables increase together (positive) or one increases as the other decreases (negative)  
"2" = "✅ Correct! Direction shows whether variables move in the same or opposite directions."
3) Whether the relationship is causal  
"3" = "❌ Incorrect. Direction doesn't indicate causation."
4) How many observations are in the dataset  
"4" = "❌ Incorrect. Direction doesn't relate to sample size."

---

### Question Q9 (Understand)
**What does a correlation tell us?**

> **Hint:** Focus on *direction* and *strength* of association.

1) How much one variable causes the other  
"1" = "❌ Incorrect. Correlation shows association, not causation."
2) The direction and strength of a linear relationship between two variables  
"2" = "✅ Correct! Correlation quantifies how strongly and in which direction variables move together."
3) The difference between two group means  
"3" = "❌ Incorrect. That's a t-test, not correlation."
4) The total variance in one variable  
"4" = "❌ Incorrect. Variance describes one variable, not the relationship between two."

---

### Question Q10 (Apply)
**Which statement correctly distinguishes correlation and regression?**

> **Hint:** Think about symmetry vs. prediction.

1) Correlation is asymmetric, regression is symmetric  
"1" = "❌ Incorrect. The opposite is true."
2) Correlation measures mutual association; regression predicts Y from X  
"2" = "✅ Correct! Correlation is symmetric; regression is directional and predictive."
3) Regression only applies to categorical data  
"3" = "❌ Incorrect. Regression requires numeric predictors."
4) Correlation and regression are identical analyses  
"4" = "❌ Incorrect. They are mathematically related but conceptually distinct."

---

### Question Q11 (Understand)
**In a simple regression model, what does the slope (b) represent?**

> **Hint:** Think: how much does Y change when X changes by one unit?

1) The predicted value of Y when X = 0  
"1" = "❌ Incorrect. That's the intercept (a)."
2) The amount Y changes for each one-unit increase in X  
"2" = "✅ Correct! The slope shows the expected change in Y for a unit change in X."
3) The variability of Y around its mean  
"3" = "❌ Incorrect. That describes variance, not slope."
4) The strength of correlation  
"4" = "❌ Incorrect. Slope and correlation are related but not identical."

---

### Question Q12 (Remember)
**What does the intercept (a) represent in regression?**

> **Hint:** It's where the regression line crosses the Y-axis.

> **🔍 Detailed Explanation:** The intercept is the predicted value of Y when X equals zero. However, be cautious about interpretation:
> 
> **When intercept is meaningful:**
> - X = 0 is within the observed range of data
> - X = 0 represents a realistic scenario
> - Example: Predicting crime rate from temperature—intercept is crime rate at 0°C
> 
> **When intercept lacks practical meaning:**
> - X = 0 is far outside the data range (extrapolation)
> - X = 0 is impossible/unrealistic
> - Example: Predicting crime from education years—intercept assumes 0 years education
> 
> **In criminology contexts:**
> - Predicting recidivism from age: intercept = recidivism rate at age 0 (not meaningful)
> - Predicting crime rate from unemployment rate: intercept = crime rate at 0% unemployment (potentially meaningful)

1) The predicted value of Y when X = 0  
"1" = "✅ Correct! That's exactly the definition, but remember to consider whether X = 0 is meaningful in your context."
2) The strength of the correlation  
"2" = "❌ Incorrect. Correlation strength is measured by r, not the intercept."
3) The total error in prediction  
"3" = "❌ Incorrect. Residuals represent prediction error; intercept is a model parameter."
4) The average value of Y  
"4" = "❌ Incorrect. The intercept equals Ȳ only if X̄ = 0, which is rarely the case."

---

### Question Q13 (Understand)
**What does R² tell us in regression?**

> **Hint:** Think about explained variance.

1) The proportion of variance in Y explained by X  
"1" = "✅ Correct! R² quantifies how much of Y's variation the model explains."
2) The residual variance left unexplained  
"2" = "❌ Incorrect. That's (1 − R²)."
3) The slope of the regression line  
"3" = "❌ Incorrect. Slope (b) and R² are different statistics."
4) The total correlation between all variables  
"4" = "❌ Incorrect. R² is derived from one correlation (r²) in simple regression."

---

### Question Q14 (Analyze)
**Why do we square the residuals when fitting the regression line (OLS method)?**

> **Hint:** Consider the role of positive and negative errors.

1) To make all errors positive and penalize large deviations more heavily  
"1" = "✅ Correct! Squaring ensures positive values and emphasizes larger errors."
2) To simplify the formula for correlation  
"2" = "❌ Incorrect. Squaring is for model fitting, not correlation."
3) To reduce the number of data points  
"3" = "❌ Incorrect. The sample size remains unchanged."
4) Because residuals are always negative  
"4" = "❌ Incorrect. Residuals can be both positive and negative."

---

### Question Q15 (Understand)
**How are correlation and regression mathematically connected?**

> **Hint:** Think about formulas linking r, b, and R².

1) b = r × (Sx / Sy)  
"1" = "❌ Incorrect. The ratio is reversed."
2) b = r × (Sy / Sx)  
"2" = "✅ Correct! The regression slope equals correlation × ratio of standard deviations."
3) r = b × (Sy / Sx)  
"3" = "❌ Incorrect. That's the inverse relation."
4) R² = b × r  
"4" = "❌ Incorrect. R² = r², not b × r."

---

### Question Q16 (Apply)
**If the correlation between X and Y is zero, what does the regression slope (b) equal?**

> **Hint:** Recall the link between r and b.

1) b = 0  
"1" = "✅ Correct! When r = 0, the regression slope is zero — no linear prediction."
2) b = 1  
"2" = "❌ Incorrect. That would mean a perfect positive relationship."
3) b = −1  
"3" = "❌ Incorrect. That would mean a perfect negative relationship."
4) b cannot be computed  
"4" = "❌ Incorrect. It can be computed, but will be 0."

---

### Question Q17 (Evaluate)
**Which of the following statements about correlation and causation is correct?**

> **Hint:** One term implies direction and mechanism; the other doesn't.

1) Correlation means one variable causes the other  
"1" = "❌ Incorrect. Association ≠ causation."
2) Correlation can suggest a relationship worth investigating, but doesn't prove cause  
"2" = "✅ Correct! Correlation is a clue, not proof of causality."
3) Correlation is only used in experiments  
"3" = "❌ Incorrect. Correlation is mainly used in observational research."
4) If r = 1, causation is guaranteed  
"4" = "❌ Incorrect. Even a perfect correlation can result from a third variable."

---

### Question Q18 (Understand)
**Why is standardizing (using z‑scores) useful when comparing two variables?**

> **Hint:** Consider unit effects on covariance and correlation as a unit‑free measure.

1) The relationship fundamentally changes when units change  
"1" = "❌ Incorrect. Units don't change the underlying relationship; only covariance's magnitude."
2) The relationship stays the same, but covariance isn't comparable across units  
"2" = "✅ Correct! Correlation (r) is standardized and unit‑free; covariance isn't."
3) Covariance is always better than correlation  
"3" = "❌ Incorrect. Covariance is scale‑dependent; correlation is scale‑invariant."
4) You should never standardize variables  
"4" = "❌ Incorrect. Standardizing is useful to put variables on the same scale."

---

### Question Q19 (Remember)
**Where is the 'center of gravity' in a standardized (z‑score) scatterplot?**

> **Hint:** Z‑scores center variables at their means.

1) (0, 0) — intersection of mean lines  
"1" = "✅ Correct! In z‑scores, the bivariate center is (0,0)."
2) (1, 1) — one standard deviation point  
"2" = "❌ Incorrect. That's one SD above both means, not the center."
3) The densest part of the cloud  
"3" = "❌ Incorrect. The mode isn't necessarily the mean‑center."
4) The most frequent observed point  
"4" = "❌ Incorrect. That's the mode, not the mean‑based center in z‑space."

---

### Question Q20 (Understand)
**What is the main lesson of Anscombe's Quartet?**

> **Hint:** Four datasets can share identical summaries yet have very different shapes.

1) Correlation tells the whole story  
"1" = "❌ Incorrect. Identical r can arise from very different patterns."
2) Always plot your data first  
"2" = "✅ Correct! Visualization avoids being misled by summaries alone."
3) Graphs are less reliable than statistics  
"3" = "❌ Incorrect. Plots complement statistics; both matter."
4) Linear relationships are the most common  
"4" = "❌ Incorrect. The quartet shows diverse structures with the same r."

---

### Question Q21 (Analyze)
**Headline: "Ice cream sales and drownings are strongly correlated." What's a plausible explanation?**

> **Hint:** Think of a third variable (confounder) driving both.

1) Ice cream causes drownings  
"1" = "❌ Incorrect. Correlation ≠ causation."
2) Drownings cause higher ice cream sales  
"2" = "❌ Incorrect. Reverse causality isn't plausible here."
3) Temperature/season increases both  
"3" = "✅ Correct! Warm weather raises ice cream sales and swimming activity."
4) There is no relationship at all  
"4" = "❌ Incorrect. There is an association, just not causal."

---

### Question Q22 (Apply)
**The relationship is curved but monotonically increasing. Which correlation should you choose?**

> **Hint:** Distinguish "linear" from "monotone".

1) Pearson correlation  
"1" = "❌ Incorrect. Pearson measures linear association and may underestimate strength."
2) Spearman correlation  
"2" = "✅ Correct! Spearman captures monotone relationships via ranks."
3) Both are equally appropriate  
"3" = "❌ Incorrect. Spearman fits better here."
4) Neither  
"4" = "❌ Incorrect. Spearman is suitable for monotone, non‑linear patterns."

---

### Question Q23 (Remember)
**You switch X from meters to centimeters. What happens to r(X,Y)?**

> **Hint:** Correlation is scale‑invariant; covariance isn't.

1) r becomes 100× larger  
"1" = "❌ Incorrect. Units don't affect r."
2) r becomes 100× smaller  
"2" = "❌ Incorrect. Units don't affect r."
3) r stays exactly the same  
"3" = "✅ Correct! r is unit‑free and invariant to linear rescaling."
4) r becomes negative  
"4" = "❌ Incorrect. The sign doesn't flip due to units."

---

### Question Q24 (Understand)
**Why do z‑scores make axes more comparable in a scatterplot?**

> **Hint:** Consider "same scale" and "standard deviations".

1) They put both variables into SD units  
"1" = "✅ Correct! Standardizing places both on the same scale."
2) They always increase the correlation  
"2" = "❌ Incorrect. Standardizing doesn't change r."
3) They remove all outliers  
"3" = "❌ Incorrect. They may help detect outliers, not remove them."
4) They make covariance unit‑free  
"4" = "❌ Incorrect. Correlation is unit‑free; covariance remains scale‑dependent."

---

### Question Q25 (Analyze)
**A scatterplot colors points by 'neighborhood type'. How is the overall correlation r typically computed?**

> **Hint:** Compare subgroup calculations versus full sample.

1) Using only the largest subgroup  
"1" = "❌ Incorrect. That ignores many cases."
2) As the average of subgroup correlations  
"2" = "❌ Incorrect. A simple mean of subgroup r's isn't standard."
3) Using all points together, ignoring colors  
"3" = "✅ Correct! By default r is computed on the full dataset."
4) As a weighted average of subgroup r's  
"4" = "❌ Incorrect. Not the default definition of r."

---

### Question Q26 (Understand)
**Which quadrants dominate under a positive association (in z‑scores)?**

> **Hint:** Consider the signs of z(X) and z(Y).

1) Mostly quadrants I & III  
"1" = "✅ Correct! Positive: both above or both below their means."
2) Mostly quadrants II & IV  
"2" = "❌ Incorrect. That indicates negative association."
3) Evenly spread across all quadrants  
"3" = "❌ Incorrect. Suggests little/no linear relationship."
4) Only quadrant I  
"4" = "❌ Incorrect. Quadrant III also occurs in positive association."

---

### Question Q27 (Apply)
**A straight trend line slopes upward; points cluster tightly. Which description fits best?**

> **Hint:** Combine direction (sign) with strength (spread).

1) Strong positive  
"1" = "✅ Correct! Upward line + tight cluster → strong positive."
2) Moderate positive  
"2" = "❌ Incorrect. Description suggests stronger than moderate."
3) Weak negative  
"3" = "❌ Incorrect. Direction is positive, not negative."
4) No linear pattern  
"4" = "❌ Incorrect. The pattern is clearly linear."

---

### Question Q28 (Analyze)
**In a positive trend, which outlier position most reduces r?**

> **Hint:** Think of points that break the linear pattern.

1) Far bottom‑left (low X, very low Y)  
"1" = "❌ Incorrect. That aligns with the positive trend."
2) Far bottom‑right (high X, low Y)  
"2" = "✅ Correct! Pulls the cloud off the line and lowers r."
3) Far top‑right (high X, high Y)  
"3" = "❌ Incorrect. Often increases a positive r."
4) A point exactly on the line  
"4" = "❌ Incorrect. Minimal impact on r."

---

### Question Q29 (Understand)
**Which statement about covariance and correlation is true?**

> **Hint:** Watch for units and ranges.

1) Covariance is unit‑free and bounded −1 to +1  
"1" = "❌ Incorrect. That's correlation, not covariance."
2) Correlation is unit‑free and always between −1 and +1  
"2" = "✅ Correct! That's why r is comparable across variables."
3) Both are unbounded  
"3" = "❌ Incorrect. Only covariance is unbounded."
4) Both depend on measurement scale  
"4" = "❌ Incorrect. Only covariance is scale‑dependent."

---

### Question Q30 (Apply)
**Which r value best matches 'weak positive'?**

> **Hint:** Use common interpretation guidelines.

1) r = 0.12  
"1" = "✅ Correct! Often interpreted as weak positive."
2) r = 0.56  
"2" = "❌ Incorrect. Closer to moderate."
3) r = −0.72  
"3" = "❌ Incorrect. Strong negative, not weak positive."
4) r = 0.93  
"4" = "❌ Incorrect. Very strong positive."

---

### Question Q31 (Understand)
**"As X increases, Y tends to …" — choose the best completion for a slightly increasing pattern.**

> **Hint:** Use the standard sentence for a weak upward trend.

1) … decrease, strongly  
"1" = "❌ Incorrect. Wrong direction."
2) … increase, weakly  
"2" = "✅ Correct! Weakly increasing relationship."
3) … increase, very strongly  
"3" = "❌ Incorrect. 'Very strong' doesn't fit a slight increase."
4) … stay the same  
"4" = "❌ Incorrect. That implies no linear relationship."

---

### Question Q32 (Remember)
**What does z = +1.2 mean in plain words?**

> **Hint:** Relate to the mean and standard deviation.

1) 1.2 units above the mean  
"1" = "❌ Incorrect. They are SD units, not raw units."
2) 1.2 standard deviations above the mean  
"2" = "✅ Correct! That's the definition of a positive z."
3) 1.2% above the mean  
"3" = "❌ Incorrect. Not a percentage."
4) 0.12 standard deviations above the mean  
"4" = "❌ Incorrect. Wrong magnitude."

---

### Question Q33 (Analyze)
**Subgroup colors on the plot: what's a risk of looking only at overall r?**

> **Hint:** Think Simpson's paradox and heterogeneity across groups.

1) Subgroup patterns can mask or reverse the overall pattern  
"1" = "✅ Correct! Aggregation can mislead; inspect subgroups."
2) r always changes when you add colors  
"2" = "❌ Incorrect. r's calculation ignores colors."
3) r can never be misleading  
"3" = "❌ Incorrect. r without context can mislead."
4) Subgroups automatically increase r  
"4" = "❌ Incorrect. No such general rule."

---

### Question Q34 (Apply)
**Which statement best summarizes when to proceed from correlation concepts to calculations?**

> **Hint:** Consider the foundation needed before computation.

1) Only after mastering all statistical theory  
"1" = "❌ Incorrect. Some practical work can proceed in parallel with theory."
2) After understanding what correlation measures and how to interpret it  
"2" = "✅ Correct! Conceptual understanding should precede mechanical calculation."
3) Calculations should come before understanding concepts  
"3" = "❌ Incorrect. Understanding concepts first helps prevent misinterpretation."
4) Theory and practice are completely unrelated  
"4" = "❌ Incorrect. Theory guides proper application of calculations."

---

# Module 2: Correlation Calculations (18 questions)

### Question Q35 (Apply)
**Given X = [4, 6, 8] and Y = [2, 5, 8], calculate the means.**

> **Hint:** Sum divided by n.

1) X̄ = 5, Ȳ = 4  
"1" = "❌ Incorrect. Check your calculations."
2) X̄ = 6, Ȳ = 5  
"2" = "✅ Correct! X̄ = (4+6+8)/3 = 6, Ȳ = (2+5+8)/3 = 5."
3) X̄ = 18, Ȳ = 15  
"3" = "❌ Incorrect. Don't forget to divide by n."
4) X̄ = 7, Ȳ = 6  
"4" = "❌ Incorrect. Recalculate."

---

### Question Q36 (Apply)
**With X̄ = 6 and Ȳ = 5, calculate the deviations for X = [4, 6, 8].**

> **Hint:** Deviation = Xi - X̄

1) [-2, 0, 2]  
"1" = "✅ Correct! (4-6), (6-6), (8-6) = [-2, 0, 2]."
2) [2, 0, -2]  
"2" = "❌ Incorrect. Signs are wrong."
3) [-1, 1, 1]  
"3" = "❌ Incorrect. Wrong calculations."
4) [4, 6, 8]  
"4" = "❌ Incorrect. These are the original values, not deviations."

---

### Question Q37 (Apply)
**Calculate the sum of squared deviations for X with deviations [-2, 0, 2].**

> **Hint:** Sum of (deviation)².

1) 4  
"1" = "❌ Incorrect. That's just one squared deviation."
2) 8  
"2" = "✅ Correct! (-2)² + 0² + 2² = 4 + 0 + 4 = 8."
3) 0  
"3" = "❌ Incorrect. Sum of deviations is 0, but sum of squared deviations isn't."
4) 16  
"4" = "❌ Incorrect. Check your calculation."

---

### Question Q38 (Apply)
**With sum of squared deviations = 8 and n = 3, calculate the sample variance (s²).**

> **Hint:** s² = SS/(n-1)

1) 2.67  
"1" = "❌ Incorrect. You used n instead of n-1."
2) 4  
"2" = "✅ Correct! s² = 8/(3-1) = 8/2 = 4."
3) 8  
"3" = "❌ Incorrect. Don't forget to divide."
4) 1.33  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q39 (Apply)
**Calculate the covariance with deviations X: [-2, 0, 2] and Y: [-3, 0, 3].**

> **Hint:** Cov = Σ(Xi - X̄)(Yi - Ȳ)/(n-1)

1) 6  
"1" = "✅ Correct! [(-2)(-3) + (0)(0) + (2)(3)]/(3-1) = (6+0+6)/2 = 6."
2) 12  
"2" = "❌ Incorrect. Don't forget to divide by n-1."
3) 3  
"3" = "❌ Incorrect. Wrong calculation."
4) 0  
"4" = "❌ Incorrect. The products don't sum to zero."

---

### Question Q40 (Apply)
**With Cov(X,Y) = 6, sX = 2, sY = 1.73, calculate Pearson r.**

> **Hint:** r = Cov(X,Y)/(sX × sY)

1) 1.73  
"1" = "❌ Incorrect. r must be between -1 and +1."
2) 0.87  
"2" = "✅ Correct! r = 6/(2 × 1.73) = 6/3.46 ≈ 0.87."
3) 3.46  
"3" = "❌ Incorrect. That's the denominator."
4) 0.58  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q41 (Understand)
**If all data points fall exactly on a straight line with positive slope, r equals:**

> **Hint:** Perfect linear relationship.

1) The slope of the line  
"1" = "❌ Incorrect. r is scale-free; slope depends on units."
2) +1  
"2" = "✅ Correct! Perfect positive linear relationship gives r = +1."
3) The intercept of the line  
"3" = "❌ Incorrect. Intercept is different from correlation."
4) 0  
"4" = "❌ Incorrect. r = 0 indicates no linear relationship."

---

### Question Q42 (Analyze)
**Which r value indicates the strongest relationship (regardless of direction)?**

> **Hint:** Strength is about absolute value.

1) r = 0.85  
"1" = "❌ Incorrect. Not the strongest absolute value."
2) r = -0.92  
"2" = "✅ Correct! |-0.92| = 0.92 is the highest absolute value."
3) r = 0.78  
"3" = "❌ Incorrect. Lower absolute value."
4) r = -0.15  
"4" = "❌ Incorrect. Weakest relationship."

---

### Question Q43 (Apply)
**If r = 0.87, what is R² (coefficient of determination)?**

> **Hint:** R² = r²

1) 0.87  
"1" = "❌ Incorrect. That's r, not r²."
2) 0.76  
"2" = "✅ Correct! R² = (0.87)² = 0.7569 ≈ 0.76."
3) 1.74  
"3" = "❌ Incorrect. Can't be greater than 1."
4) 0.93  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q44 (Apply)
**Convert to ranks: X = [85, 92, 78, 92]. What are the ranks for X?**

> **Hint:** Assign ranks 1-4, handle ties with averages.

1) [2, 3.5, 1, 3.5]  
"1" = "✅ Correct! 78(1st), 85(2nd), 92s tied for 3rd&4th = 3.5 each."
2) [2, 4, 1, 3]  
"2" = "❌ Incorrect. Need to average tied ranks."
3) [3, 4, 1, 2]  
"3" = "❌ Incorrect. Wrong ranking."
4) [1, 2, 3, 4]  
"4" = "❌ Incorrect. Ignores the tie."

---

### Question Q45 (Understand)
**Why do we average ranks for tied values?**

> **Hint:** Preserve the total sum of ranks.

1) To make calculations easier  
"1" = "❌ Incorrect. Not about convenience."
2) To maintain the sum of ranks = n(n+1)/2  
"2" = "✅ Correct! Averaging preserves the mathematical properties."
3) Ties are not allowed in statistics  
"3" = "❌ Incorrect. Ties are common and handled systematically."
4) To increase the correlation  
"4" = "❌ Incorrect. Not about changing correlation strength."

---

### Question Q46 (Apply)
**For a 2×2 contingency table with χ² = 8.1 and n = 100, calculate Cramér's V.**

> **Hint:** V = √(χ²/(n × min(r-1, c-1)))

1) 0.081  
"1" = "❌ Incorrect. Wrong formula application."
2) 0.285  
"2" = "✅ Correct! V = √(8.1/(100×1)) = √0.081 = 0.285."
3) 0.81  
"3" = "❌ Incorrect. Missing the square root."
4) 0.09  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q47 (Apply)

> **Hint:** Use regular Pearson formula or special point-biserial formula.

1) 0.82  
"1" = "✅ Correct! Strong positive association between binary and continuous variables."
2) 0.00  
"2" = "❌ Incorrect. There is a clear relationship."
3) -0.82  
"3" = "❌ Incorrect. Relationship is positive."
4) 1.00  
"4" = "❌ Incorrect. Not a perfect relationship."

---

### Question Q48 (Analyze)
**Your data has extreme outliers and curved relationships. Which correlation measure is most appropriate?**

> **Hint:** Consider robustness to outliers and non-linearity.

1) Pearson correlation  
"1" = "❌ Incorrect. Sensitive to outliers and assumes linearity."
2) Spearman correlation  
"2" = "✅ Correct! Rank-based, robust to outliers and captures monotonic relationships."
3) Point-biserial  
"3" = "❌ Incorrect. Only for binary-continuous relationships."
4) Cramér's V  
"4" = "❌ Incorrect. For categorical variables."

---

### Question Q49 (Analyze)
**One extreme outlier pulls the correlation from r = 0.85 to r = 0.23. What does this suggest?**

> **Hint:** Consider the impact of influential points.

1) The original correlation was wrong  
"1" = "❌ Incorrect. Both can be 'correct' calculations."
2) Outliers can dramatically affect Pearson r  
"2" = "✅ Correct! Demonstrates sensitivity to extreme values."
3) The relationship is actually negative  
"3" = "❌ Incorrect. Both correlations are positive."
4) Sample size is too small  
"4" = "❌ Incorrect. Issue is about outlier influence, not sample size."

---

### Question Q50 (Evaluate)
**When should you prefer Spearman over Pearson correlation?**

> **Hint:** Consider data type and relationship characteristics.

1) When you want the strongest correlation  
"1" = "❌ Incorrect. Choice should be based on data characteristics, not strength."
2) When data is ordinal or relationship is monotonic but non-linear  
"2" = "✅ Correct! Spearman is appropriate for ranks and monotonic relationships."
3) When sample size is large  
"3" = "❌ Incorrect. Sample size alone doesn't determine the choice."
4) When you have missing data  
"4" = "❌ Incorrect. Both require complete data for standard calculation."

---

### Question Q51 (Understand)

> **Hint:** Think about standardization.

1) They're the same thing  
"1" = "❌ Incorrect. Related but different."
2) Correlation is standardized covariance  
"2" = "✅ Correct! r = Cov(X,Y)/(sX × sY)."
3) Covariance is always larger  
"3" = "❌ Incorrect. Depends on the scale."
4) They have opposite signs  
"4" = "❌ Incorrect. They have the same sign."

---

### Question Q52 (Apply)
**Interpret r = -0.65 between study hours and error rate.**

> **Hint:** Consider direction, strength, and practical meaning.

1) Moderate positive: more study, more errors  
"1" = "❌ Incorrect. r is negative."
2) Moderate negative: more study, fewer errors  
"2" = "✅ Correct! Makes practical sense - studying reduces errors."
3) Weak relationship with no practical meaning  
"3" = "❌ Incorrect. -0.65 is moderate to strong."
4) Perfect negative relationship  
"4" = "❌ Incorrect. Perfect would be r = -1.00."

---

# Module 3: From Correlation to Regression (7 questions)

### Question Q53 (Understand)
**Looking at a scatterplot, which pattern suggests the strongest positive correlation?**

> **Hint:** Consider both direction and scatter around the trend.

1) Points scattered randomly with no clear pattern  
"1" = "❌ Incorrect. Random scatter indicates no correlation."
2) Points tightly clustered around an upward-sloping line  
"2" = "✅ Correct! Tight clustering around positive trend = strong positive correlation."
3) Points forming a perfect horizontal line  
"3" = "❌ Incorrect. Horizontal indicates no relationship between variables."
4) Points loosely scattered around a downward trend  
"4" = "❌ Incorrect. This suggests weak negative correlation."

---

### Question Q54 (Apply)
**If r = 0.9 between study hours and exam scores, what can we predict?**

> **Hint:** Strong correlation enables better prediction.

1) Students who study more will definitely get higher scores  
"1" = "❌ Incorrect. Correlation allows prediction but not certainty."
2) Study hours have a strong positive association with exam scores, enabling good predictions  
"2" = "✅ Correct! High correlation means we can make reliable (but not perfect) predictions."
3) Study hours cause exam scores to increase  
"3" = "❌ Incorrect. Correlation doesn't establish causation."
4) There is no relationship between study hours and scores  
"4" = "❌ Incorrect. r = 0.9 indicates a very strong relationship."

---

### Question Q55 (Apply)
**From correlation to regression line: If r = 0.8, what does this tell us about the regression slope?**

> **Hint:** Think about the formula connecting r and b.

1) The slope will be positive and moderately steep  
"1" = "✅ Correct! Positive r leads to positive slope; 0.8 is strong correlation."
2) The slope will be exactly 0.8  
"2" = "❌ Incorrect. Slope depends on both r and the ratio of standard deviations."
3) The slope will be negative  
"3" = "❌ Incorrect. Positive correlation means positive slope."
4) The slope cannot be determined from r alone  
"4" = "❌ Incorrect. r's sign always determines slope's sign."

---

### Question Q56 (Analyze)
**If R² = 0.64, how much prediction error remains unexplained?**

> **Hint:** R² is the explained proportion; what's left?

1) 64% remains unexplained  
"1" = "❌ Incorrect. R² represents explained variance."
2) 36% remains unexplained  
"2" = "✅ Correct! If 64% is explained, then 100% - 64% = 36% is unexplained."
3) 0.64 units remain unexplained  
"3" = "❌ Incorrect. R² is a proportion, not a raw amount."
4) No error remains — perfect prediction  
"4" = "❌ Incorrect. R² = 1.0 would indicate perfect prediction."

---

### Question Q57 (Apply)
**A regression gives Ŷ = 50 + 3X. If X increases by 2 units, Y increases by:**

> **Hint:** Use the slope to calculate the change.

1) 2 units  
"1" = "❌ Incorrect. The slope is 3, not 1."
2) 3 units  
"2" = "❌ Incorrect. That's for a 1-unit change in X."
3) 6 units  
"3" = "✅ Correct! Slope × change in X = 3 × 2 = 6 units."
4) 50 units  
"4" = "❌ Incorrect. That's the intercept, not the change."

---

### Question Q58 (Understand)
**What do residuals in a "good" regression model look like?**

> **Hint:** Think about patterns that would violate regression assumptions.

1) Large positive residuals at high X values  
"1" = "❌ Incorrect. This suggests systematic bias."
2) Randomly scattered around zero with no clear pattern  
"2" = "✅ Correct! Random residuals indicate the model captures the systematic relationship well."
3) Residuals that increase steadily as X increases  
"3" = "❌ Incorrect. This indicates heteroscedasticity (assumption violation)."
4) All residuals exactly equal to zero  
"4" = "❌ Incorrect. This would require perfect prediction (unlikely with real data)."

---

### Question Q59 (Evaluate)
**When is it appropriate to use regression for prediction?**

> **Hint:** Consider the conditions that make regression reliable.

1) Always, regardless of the correlation strength  
"1" = "❌ Incorrect. Weak correlations lead to poor predictions."
2) When there's a strong linear relationship and you're predicting within the data range  
"2" = "✅ Correct! Strong relationships and avoiding extrapolation are key conditions."
3) Only when you can prove causation  
"3" = "❌ Incorrect. Prediction doesn't require proving causation."
4) Only with experimental data  
"4" = "❌ Incorrect. Regression works with observational data too."

---

# Module 4: Regression Basics (10 questions)

### Question Q60 (Understand)
**What does the "least squares" principle minimize in regression?**

> **Hint:** Think about what OLS stands for.

1) The sum of errors (residuals)  
"1" = "❌ Incorrect. Sum of residuals is always zero."
2) The sum of absolute errors  
"2" = "❌ Incorrect. That's least absolute deviations."
3) The sum of squared errors  
"3" = "✅ Correct! OLS minimizes Σ(yi - ŷi)²."
4) The correlation coefficient  
"4" = "❌ Incorrect. OLS doesn't minimize correlation."

---

### Question Q44 (Remember)
**Where does the regression line always pass through?**

> **Hint:** A fundamental property of OLS regression.

1) The origin (0,0)  
"1" = "❌ Incorrect. Only if both means are zero."
2) The point of means (X̄, Ȳ)  
"2" = "✅ Correct! The line always goes through (X̄, Ȳ)."
3) The highest data point  
"3" = "❌ Incorrect. Not a property of regression lines."
4) The lowest data point  
"4" = "❌ Incorrect. Not a property of regression lines."

---

### Question Q45 (Understand)
**If the regression equation is Ŷ = 5 + 2X, how do you interpret the slope?**

> **Hint:** Slope indicates the change in Y per unit change in X.

1) Y increases by 5 units for each unit increase in X  
"1" = "❌ Incorrect. That's the intercept, not slope."
2) Y increases by 2 units for each unit increase in X  
"2" = "✅ Correct! Slope = 2 means ΔY = 2 when ΔX = 1."
3) Y increases by 7 units for each unit increase in X  
"3" = "❌ Incorrect. That's adding intercept and slope."
4) X increases by 2 units for each unit increase in Y  
"4" = "❌ Incorrect. Backwards interpretation."

---

### Question Q46 (Understand)
**In Ŷ = 5 + 2X, what does the intercept (5) represent?**

> **Hint:** Value of Y when X = 0.

1) The slope of the line  
"1" = "❌ Incorrect. Slope is 2."
2) The predicted Y when X = 0  
"2" = "✅ Correct! Intercept is the Y-value when X = 0."
3) The correlation between X and Y  
"3" = "❌ Incorrect. Correlation is different from intercept."
4) The average value of Y  
"4" = "❌ Incorrect. That's Ȳ, not the intercept."

---

### Question Q47 (Understand)
**What is a residual in regression analysis?**

> **Hint:** Think about prediction error.

1) The slope of the regression line  
"1" = "❌ Incorrect. That's a regression coefficient."
2) The difference between observed and predicted Y  
"2" = "✅ Correct! Residual = yi - ŷi."
3) The correlation coefficient  
"3" = "❌ Incorrect. That measures linear association."
4) The intercept of the regression line  
"4" = "❌ Incorrect. That's a regression coefficient."

---

### Question Q48 (Understand)
**Why does OLS use squared errors rather than absolute errors?**

> **Hint:** Think about mathematical properties and outlier sensitivity.

1) Squared errors are easier to interpret  
"1" = "❌ Incorrect. Actually less intuitive than absolute errors."
2) It gives more weight to larger errors and has nice calculus properties  
"2" = "✅ Correct! Penalizes large errors more and allows analytical solutions."
3) Absolute errors don't exist  
"3" = "❌ Incorrect. They exist but have different properties."
4) Squared errors are always smaller  
"4" = "❌ Incorrect. Only when |error| < 1."

---

### Question Q49 (Understand)
**What does R² = 0.64 mean in regression?**

> **Hint:** Proportion of variance explained.

1) 64% of Y's variance is explained by X  
"1" = "✅ Correct! R² represents explained variance."
2) The correlation is 0.64  
"2" = "❌ Incorrect. r = √0.64 = 0.80."
3) 64% of predictions are correct  
"3" = "❌ Incorrect. R² isn't about prediction accuracy percentage."
4) The slope is 0.64  
"4" = "❌ Incorrect. R² and slope are different concepts."

---

### Question Q50 (Analyze)
**What's the main risk of extrapolation in regression?**

> **Hint:** Using the model outside the data range.

1) Calculations become more difficult  
"1" = "❌ Incorrect. Calculations are equally easy."
2) The relationship may not hold outside the observed range  
"2" = "✅ Correct! Linear relationship might break down beyond data boundaries."
3) R² always decreases  
"3" = "❌ Incorrect. R² is calculated on existing data."
4) The slope changes  
"4" = "❌ Incorrect. The equation stays the same; validity is questioned."

---

### Question Q51 (Understand)
**How do correlation and regression differ?**

> **Hint:** Think about symmetry and prediction.

1) They're identical concepts  
"1" = "❌ Incorrect. Related but different."
2) Correlation is symmetric; regression has directional prediction  
"2" = "✅ Correct! r(X,Y) = r(Y,X), but regression of Y on X ≠ X on Y."
3) Correlation is more accurate  
"3" = "❌ Incorrect. They serve different purposes."
4) Regression doesn't use correlation  
"4" = "❌ Incorrect. They're closely related."

---

### Question Q52 (Analyze)
**You find a strong regression relationship (R² = 0.81). Can you conclude causation?**

> **Hint:** Think about confounding and experimental design.

1) Yes, high R² proves causation  
"1" = "❌ Incorrect. Association ≠ causation, regardless of strength."
2) No, need experimental or quasi-experimental design  
"2" = "✅ Correct! Correlation/regression alone cannot establish causation."
3) Only if the slope is positive  
"3" = "❌ Incorrect. Direction doesn't determine causation."
4) Yes, but only for R² > 0.80  
"4" = "❌ Incorrect. No threshold makes correlation become causation."

---

# Module 5: Regression Calculations (12 questions)

### Question Q53 (Apply)
**Calculate the slope using b = r(sy/sx) where r = 0.6, sy = 8, sx = 4.**

> **Hint:** Direct substitution into the formula.

1) 0.3  
"1" = "❌ Incorrect. Wrong calculation."
2) 1.2  
"2" = "✅ Correct! b = 0.6 × (8/4) = 0.6 × 2 = 1.2."
3) 2.4  
"3" = "❌ Incorrect. Check your arithmetic."
4) 0.6  
"4" = "❌ Incorrect. That's just r."

---

### Question Q54 (Apply)
**Calculate the intercept using a = Ȳ - bX̄ where Ȳ = 12, b = 1.2, X̄ = 5.**

> **Hint:** Direct substitution into the formula.

1) 6.0  
"1" = "✅ Correct! a = 12 - 1.2(5) = 12 - 6 = 6."
2) 18.0  
"2" = "❌ Incorrect. Check your signs."
3) 1.2  
"3" = "❌ Incorrect. That's the slope."
4) 12.0  
"4" = "❌ Incorrect. That's just Ȳ."

---

### Question Q55 (Apply)
**Using Ŷ = 6 + 1.2X, predict Y when X = 8.**

> **Hint:** Substitute X = 8 into the equation.

1) 15.6  
"1" = "✅ Correct! Ŷ = 6 + 1.2(8) = 6 + 9.6 = 15.6."
2) 9.6  
"2" = "❌ Incorrect. Don't forget the intercept."
3) 20.4  
"3" = "❌ Incorrect. Check your calculation."
4) 6.0  
"4" = "❌ Incorrect. That's just the intercept."

---

### Question Q56 (Apply)
**If observed Y = 14 and predicted Ŷ = 15.6, what's the residual?**

> **Hint:** Residual = observed - predicted.

1) 1.6  
"1" = "❌ Incorrect. Wrong sign."
2) -1.6  
"2" = "✅ Correct! Residual = 14 - 15.6 = -1.6."
3) 29.6  
"3" = "❌ Incorrect. Don't add them."
4) 15.6  
"4" = "❌ Incorrect. That's the predicted value."

---

### Question Q57 (Apply)
**If r = 0.8, what is R²?**

> **Hint:** R² = r²

1) 0.8  
"1" = "❌ Incorrect. That's r, not r²."
2) 0.64  
"2" = "✅ Correct! R² = (0.8)² = 0.64."
3) 1.6  
"3" = "❌ Incorrect. Can't exceed 1."
4) 0.89  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q58 (Apply)
**What's the standardized slope (beta) when r = 0.75?**

> **Hint:** In simple regression, β = r.

1) 0.56  
"1" = "❌ Incorrect. That would be r²."
2) 0.75  
"2" = "✅ Correct! In simple regression, the standardized slope equals r."
3) 1.33  
"3" = "❌ Incorrect. Not possible given r = 0.75."
4) 0.87  
"4" = "❌ Incorrect. Wrong value."

---

### Question Q59 (Understand)
**If you change X from meters to centimeters, what happens to the slope?**

> **Hint:** Consider unit effects on regression coefficients.

1) Slope stays the same  
"1" = "❌ Incorrect. Slope is not scale-invariant."
2) Slope becomes 100 times smaller  
"2" = "✅ Correct! When X units get 100× smaller, slope gets 100× smaller."
3) Slope becomes 100 times larger  
"3" = "❌ Incorrect. Wrong direction."
4) Slope becomes negative  
"4" = "❌ Incorrect. Sign doesn't change due to scale."

---

### Question Q60 (Apply)
**From regression output: Coefficient = 2.5, SE = 0.8, t = 3.125. What's the interpretation?**

> **Hint:** Focus on the coefficient and its meaning.

1) Y increases by 0.8 units per unit increase in X  
"1" = "❌ Incorrect. That's the standard error."
2) Y increases by 2.5 units per unit increase in X  
"2" = "✅ Correct! The coefficient is the slope."
3) Y increases by 3.125 units per unit increase in X  
"3" = "❌ Incorrect. That's the t-statistic."
4) The relationship is not significant  
"4" = "❌ Incorrect. t = 3.125 suggests significance."

---

### Question Q61 (Analyze)
**An outlier pulls the slope from 2.1 to 3.8. What should you do?**

> **Hint:** Consider data investigation and robustness.

1) Always remove the outlier  
"1" = "❌ Incorrect. Need to investigate first."
2) Investigate the outlier and consider robust methods  
"2" = "✅ Correct! Check if it's an error and consider robustness."
3) Always keep the outlier  
"3" = "❌ Incorrect. Depends on the situation."
4) Use the average of both slopes  
"4" = "❌ Incorrect. Not a standard practice."

---

### Question Q62 (Analyze)
**The intercept is -50 in a model predicting salary from years of experience. Is this meaningful?**

> **Hint:** Think about extrapolation and practical interpretation.

1) Yes, people with no experience owe money  
"1" = "❌ Incorrect. Practically nonsensical."
2) No, it's extrapolation beyond meaningful data range  
"2" = "✅ Correct! Intercept may not be meaningful outside data range."
3) Yes, it's always meaningful  
"3" = "❌ Incorrect. Context matters."
4) No, intercepts are never meaningful  
"4" = "❌ Incorrect. Sometimes they are meaningful."

---

### Question Q63 (Understand)
**Which assumption is most important for least squares regression?**

> **Hint:** Think about core OLS assumptions.

1) X must be normally distributed  
"1" = "❌ Incorrect. X distribution isn't required to be normal."
2) Y must have constant variance across X values  
"2" = "✅ Correct! Homoscedasticity is a key assumption."
3) Sample size must exceed 30  
"3" = "❌ Incorrect. No specific sample size requirement."
4) Variables must be measured without error  
"4" = "❌ Incorrect. While ideal, some measurement error is usually tolerated."

---

### Question Q64 (Understand)
**What's the difference between prediction and explanation in regression?**

> **Hint:** Think about goals and interpretation.

1) They're the same thing  
"1" = "❌ Incorrect. Different goals."
2) Prediction focuses on accuracy; explanation on understanding relationships  
"2" = "✅ Correct! Different emphases and evaluation criteria."
3) Prediction is always better  
"3" = "❌ Incorrect. Depends on the research goal."
4) Explanation doesn't use regression  
"4" = "❌ Incorrect. Regression serves both purposes."

---

# Module 6: Partial Correlation (8 questions)

### Question Q65 (Understand)
**When is partial correlation most useful?**

> **Hint:** Think about confounding variables.

1) When you want the strongest correlation  
"1" = "❌ Incorrect. Strength isn't the goal."
2) When you want to control for a third variable  
"2" = "✅ Correct! Partial correlation removes the effect of confounders."
3) When sample size is small  
"3" = "❌ Incorrect. Not specifically about sample size."
4) When variables are categorical  
"4" = "❌ Incorrect. Partial correlation is for continuous variables."

---

### Question Q66 (Remember)
**What's the formula for partial correlation rXY.Z?**

> **Hint:** Uses pairwise correlations and algebraic manipulation.

1) rXY × rXZ × rYZ  
"1" = "❌ Incorrect. Not a product."
2) (rXY - rXZ × rYZ) / √[(1-rXZ²)(1-rYZ²)]  
"2" = "✅ Correct! Standard partial correlation formula."
3) rXY - rXZ - rYZ  
"3" = "❌ Incorrect. Simple subtraction doesn't work."
4) (rXY + rXZ + rYZ) / 3  
"4" = "❌ Incorrect. Not an average."

---

### Question Q67 (Apply)
**Calculate rXY.Z with rXY = 0.7, rXZ = 0.5, rYZ = 0.6.**

> **Hint:** Use the partial correlation formula.

1) 0.45  
"1" = "✅ Correct! rXY.Z = (0.7 - 0.5×0.6)/√[(1-0.5²)(1-0.6²)] = 0.4/√[0.75×0.64] ≈ 0.45."
2) 0.70  
"2" = "❌ Incorrect. That's just rXY."
3) 0.60  
"3" = "❌ Incorrect. Wrong calculation."
4) 0.30  
"4" = "❌ Incorrect. Check your arithmetic."

---

### Question Q68 (Analyze)
**rXY = 0.8, but rXY.Z = 0.2. What does this suggest?**

> **Hint:** Think about spurious correlation.

1) Z has no effect  
"1" = "❌ Incorrect. Z clearly has a major effect."
2) Much of the X-Y relationship was due to Z  
"2" = "✅ Correct! Z was confounding the X-Y relationship."
3) There was a calculation error  
"3" = "❌ Incorrect. This pattern is possible and meaningful."
4) X and Y are not related  
"4" = "❌ Incorrect. They still have some relationship (0.2)."

---

### Question Q69 (Understand)
**What's the difference between controlling for Z and interacting with Z?**

> **Hint:** Think about constant vs. variable effects.

1) They're the same concept  
"1" = "❌ Incorrect. Different concepts."
2) Controlling assumes Z's effect is constant; interaction allows it to vary  
"2" = "✅ Correct! Control removes Z's effect; interaction examines how Z modifies relationships."
3) Interaction is always better  
"3" = "❌ Incorrect. Depends on the research question."
4) Controlling is only for categorical variables  
"4" = "❌ Incorrect. Can control for any type of variable."

---

### Question Q70 (Analyze)
**Interpret rXY.Z = -0.3 when rXY = 0.1 originally.**

> **Hint:** Think about suppression effects.

1) Controlling for Z revealed a hidden negative relationship  
"1" = "✅ Correct! Z was suppressing the true negative X-Y relationship."
2) Z caused the relationship to become negative  
"2" = "❌ Incorrect. Z revealed what was already there."
3) There's no relationship between X and Y  
"3" = "❌ Incorrect. There is a negative relationship."
4) The calculation must be wrong  
"4" = "❌ Incorrect. Suppression effects are real phenomena."

---

### Question Q71 (Apply)
**How should you report partial correlation results?**

> **Hint:** Think about what readers need to know.

1) Only report the partial correlation value  
"1" = "❌ Incorrect. Need more context."
2) Report both zero-order and partial correlations with controlled variables  
"2" = "✅ Correct! Provides full picture of relationships."
3) Only report if the partial correlation is significant  
"3" = "❌ Incorrect. Non-significant results can be meaningful."
4) Report only the variables that were controlled  
"4" = "❌ Incorrect. Need the actual correlation values."

---

### Question Q72 (Understand)
**Does changing the scale of X affect the partial correlation rXY.Z?**

> **Hint:** Think about correlation's scale-invariance property.

1) Yes, partial correlations are scale-dependent  
"1" = "❌ Incorrect. Correlations are scale-invariant."
2) No, all correlations (including partial) are scale-invariant  
"2" = "✅ Correct! Scale changes don't affect any correlation measures."
3) Only if Z is also rescaled  
"3" = "❌ Incorrect. Scale-invariance holds regardless."
4) Yes, but only for the controlled variable  
"4" = "❌ Incorrect. All correlations are scale-invariant."

---

### Question Q82 (Understand)
**When should you use partial correlation instead of simple correlation?**

> **Hint:** Think about when you need to control for the influence of other variables.

1) When you have more than two variables and want to isolate the relationship between two specific variables  
"1" = "✅ Correct! Partial correlation controls for third variables."
2) When your correlation coefficient is too small  
"2" = "❌ Incorrect. Partial correlation is about controlling variables, not size."
3) When you have missing data  
"3" = "❌ Incorrect. This relates to data handling, not correlation type."
4) When variables are not normally distributed  
"4" = "❌ Incorrect. This relates to correlation assumptions, not when to use partial correlation."

---

### Question Q83 (Remember)
**What is the formula for partial correlation rXY.Z?**

> **Hint:** Think about how you remove the influence of Z from both X and Y.

1) rXY.Z = rXY - rXZ × rYZ  
"1" = "❌ Incorrect. Missing the denominator."
2) rXY.Z = (rXY - rXZ × rYZ) / √((1-r²XZ)(1-r²YZ))  
"2" = "✅ Correct! This removes Z's influence from both X and Y."
3) rXY.Z = rXY / (rXZ × rYZ)  
"3" = "❌ Incorrect. This is not the correct formula."
4) rXY.Z = rXY + rXZ - rYZ  
"4" = "❌ Incorrect. This doesn't control for Z properly."

---

### Question Q84 (Apply)
**Calculate the partial correlation rXY.Z given: rXY = 0.60, rXZ = 0.40, rYZ = 0.30**

> **Hint:** Use the partial correlation formula step by step.

1) 0.47  
"1" = "✅ Correct! rXY.Z = (0.60 - 0.40×0.30) / √((1-0.16)(1-0.09)) = 0.48/√(0.84×0.91) ≈ 0.47"
2) 0.60  
"2" = "❌ Incorrect. This ignores the control for Z."
3) 0.30  
"3" = "❌ Incorrect. Check your calculation."
4) 0.72  
"4" = "❌ Incorrect. This is larger than the original correlation."

---

### Question Q85 (Analyze)
**What's the difference between spurious correlation and suppression?**

> **Hint:** Think about whether the third variable inflates or deflates the relationship.

1) Spurious correlation is when a third variable creates a false relationship; suppression is when it hides a true relationship  
"1" = "✅ Correct! Both involve third variables but in opposite ways."
2) They're the same thing  
"2" = "❌ Incorrect. They're opposite phenomena."
3) Spurious correlation involves measurement error; suppression involves sampling error  
"3" = "❌ Incorrect. Both relate to third variable effects."
4) Spurious correlation is stronger; suppression is weaker  
"4" = "❌ Incorrect. This describes magnitude, not the underlying mechanism."

---

### Question Q86 (Understand)
**When controlling for variable Z, what does it mean if rXY.Z > rXY?**

> **Hint:** Think about what happens when Z was suppressing the true relationship.

1) Z was creating a spurious correlation  
"1" = "❌ Incorrect. Spurious correlation would make the partial correlation smaller."
2) Z was suppressing the true relationship between X and Y  
"2" = "✅ Correct! Removing Z's influence reveals a stronger relationship."
3) There's an error in calculation  
"3" = "❌ Incorrect. This is a valid statistical phenomenon."
4) X and Y are now confounded  
"4" = "❌ Incorrect. Controlling for Z reduces confounding."

---

### Question Q87 (Analyze)
**How should you interpret a partial correlation of rXY.Z = 0.45 when rXY = 0.60?**

> **Hint:** Compare the magnitudes and think about Z's role.

1) Z was irrelevant to the X-Y relationship  
"1" = "❌ Incorrect. If Z were irrelevant, the correlations would be similar."
2) Z partially explains the X-Y relationship  
"2" = "✅ Correct! The relationship is weaker after controlling for Z."
3) Z completely explains the X-Y relationship  
"3" = "❌ Incorrect. There's still a substantial relationship (0.45)."
4) The analysis is invalid  
"4" = "❌ Incorrect. This is a normal result."

---

### Question Q88 (Apply)
**When reporting partial correlations in criminology research, you should:**

> **Hint:** Think about complete and transparent reporting practices.

1) Only report the partial correlation value  
"1" = "❌ Incorrect. Readers need the full context."
2) Report both simple and partial correlations, plus what was controlled  
"2" = "✅ Correct! Provides full picture of relationships."
3) Only report if the partial correlation is significant  
"3" = "❌ Incorrect. Non-significant results can be meaningful."
4) Report only the variables that were controlled  
"4" = "❌ Incorrect. Need the actual correlation values."

---

### Question Q89 (Understand)
**Does changing the scale of X affect the partial correlation rXY.Z?**

> **Hint:** Think about correlation's scale-invariance property.

1) Yes, partial correlations are scale-dependent  
"1" = "❌ Incorrect. Correlations are scale-invariant."
2) No, all correlations (including partial) are scale-invariant  
"2" = "✅ Correct! Scale changes don't affect any correlation measures."
3) Only if Z is also rescaled  
"3" = "❌ Incorrect. Scale-invariance holds regardless."
4) Yes, but only for the controlled variable  
"4" = "❌ Incorrect. All correlations are scale-invariant."

---

## Summary

This expanded version provides comprehensive coverage of correlation and regression concepts across 80 carefully structured questions spanning five modules:

1. **Module 1 (34 questions)**: Fundamental concepts including what correlation and regression are, variable types, basic interpretation, and foundation concepts before moving to standardization and scatterplot interpretation
2. **Module 2 (18 questions)**: Detailed calculation procedures for various correlation measures  
3. **Module 3 (7 questions)**: Bridge module connecting correlation concepts to regression
4. **Module 3 (10 questions)**: Core regression concepts and interpretation
5. **Module 4 (12 questions)**: Regression calculations and practical applications
6. **Module 5 (8 questions)**: Advanced topics in partial correlation and control variables

The first 8 questions now cover the fundamental concepts you requested:
- **Q1-Q2**: Basic definitions of correlation and regression
- **Q3**: Variable types suitable for correlation analysis
- **Q4**: Why correlation doesn't prove causation
- **Q5**: What z-scores are and their purpose
- **Q6**: How to interpret correlation values
- **Q7**: Key measures in correlation analysis
- **Q8**: Understanding relationship direction

Each question includes hints and detailed feedback to support learning across Bloom's taxonomy levels.