---
title: "Correlation & Regression — Microcourse (MCQ format)"
output: word_document
---

# Correlation and Regression — Basics to Interpretation

Note: This file reformats questions from `Complete_Course_Questions.Rmd` to match the MCQ style used in `All quesion/basisbegrippen_statistiek.Rmd`. For items that normally require visuals, the phrasing is conceptual.

## OVERVIEW (Expanded course — 64 questions)

### Module 1: Correlation Basics (16 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q1 | Why standardize? | Understand |
| Q2 | Center in z‑scores | Remember |
| Q3 | Anscombe's Quartet | Understand |
| Q4 | Correlation ≠ Causation | Analyze |
| Q5 | Monotone vs. linear | Apply |
| Q6 | Units don't change r | Remember |
| Q7 | Z‑scores compare axes | Understand |
| Q8 | Subgroups vs. overall r | Analyze |
| Q9 | Quadrants and sign | Understand |
| Q10 | Direction and strength | Apply |
| Q11 | Outlier impact | Analyze |
| Q12 | Covariance vs correlation | Understand |
| Q13 | Weak positive | Apply |
| Q14 | Describe the pattern | Understand |
| Q15 | Meaning of z = +1.2 | Remember |
| Q16 | Aggregation pitfall | Analyze |

### Module 2: Correlation Calculations (18 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q17 | Compute means | Apply |
| Q18 | Calculate deviations | Apply |
| Q19 | Sum of squares | Apply |
| Q20 | Sample variances | Apply |
| Q21 | Covariance calculation | Apply |
| Q22 | Pearson r (standardized cov) | Apply |
| Q23 | Pearson r (z‑scores) | Understand |
| Q24 | Interpret r magnitude | Analyze |
| Q25 | Compute R² | Apply |
| Q26 | Spearman from ranks | Apply |
| Q27 | Handling ties in ranks | Understand |
| Q28 | Cramér's V calculation | Apply |
| Q29 | Point‑biserial correlation | Apply |
| Q30 | Choose correlation measure | Analyze |
| Q31 | Outlier sensitivity | Analyze |
| Q32 | When to use Spearman | Evaluate |
| Q33 | Correlation vs covariance | Understand |
| Q34 | Interpretation practice | Apply |

### Module 3: Regression Basics (10 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q35 | OLS principle | Understand |
| Q36 | Line passes through means | Remember |
| Q37 | Slope interpretation | Understand |
| Q38 | Intercept meaning | Understand |
| Q39 | Residuals concept | Understand |
| Q40 | Why squared errors | Understand |
| Q41 | R² interpretation | Understand |
| Q42 | Extrapolation risks | Analyze |
| Q43 | Correlation vs regression | Understand |
| Q44 | Causality caution | Analyze |

### Module 4: Regression Calculations (12 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q45 | Calculate slope | Apply |
| Q46 | Calculate intercept | Apply |
| Q47 | Make predictions | Apply |
| Q48 | Calculate residuals | Apply |
| Q49 | R² from correlation | Apply |
| Q50 | Standardized slope | Apply |
| Q51 | Unit effects on regression | Understand |
| Q52 | Read statistical output | Apply |
| Q53 | Outlier effects | Analyze |
| Q54 | Intercept interpretation | Analyze |
| Q55 | Model assumptions | Understand |
| Q56 | Prediction vs explanation | Understand |

### Module 5: Partial Correlation (8 questions)
| Question | Title | Level |
|----------|-------|-------|
| Q57 | When to use partial correlation | Understand |
| Q58 | Partial correlation formula | Remember |
| Q59 | Calculate partial correlation | Apply |
| Q60 | Spurious vs suppression | Analyze |
| Q61 | Control vs interaction | Understand |
| Q62 | Interpret partial correlation | Analyze |
| Q63 | Statistical reporting | Apply |
| Q64 | Scale invariance | Understand |

---

# Module 1: Correlation Basics (16 questions)

### Question Q1 (Understand)
**Why is standardizing (using z‑scores) useful when comparing two variables?**

> **Hint:** Consider unit effects on covariance and correlation as a unit‑free measure.

1) The relationship fundamentally changes when units change  
"1" = "❌ Incorrect. Units don't change the underlying relationship; only covariance's magnitude."
2) The relationship stays the same, but covariance isn't comparable across units  
"2" = "✅ Correct! Correlation (r) is standardized and unit‑free; covariance isn't."
3) Covariance is always better than correlation  
"3" = "❌ Incorrect. Covariance is scale‑dependent; correlation is scale‑invariant."
4) You should never standardize variables  
"4" = "❌ Incorrect. Standardizing is useful to put variables on the same scale."

---

### Question Q2 (Remember)
**Where is the 'center of gravity' in a standardized (z‑score) scatterplot?**

> **Hint:** Z‑scores center variables at their means.

1) (0, 0) — intersection of mean lines  
"1" = "✅ Correct! In z‑scores, the bivariate center is (0,0)."
2) (1, 1) — one standard deviation point  
"2" = "❌ Incorrect. That's one SD above both means, not the center."
3) The densest part of the cloud  
"3" = "❌ Incorrect. The mode isn't necessarily the mean‑center."
4) The most frequent observed point  
"4" = "❌ Incorrect. That's the mode, not the mean‑based center in z‑space."

---

### Question Q3 (Understand)
**What is the main lesson of Anscombe's Quartet?**

> **Hint:** Four datasets can share identical summaries yet have very different shapes.

1) Correlation tells the whole story  
"1" = "❌ Incorrect. Identical r can arise from very different patterns."
2) Always plot your data first  
"2" = "✅ Correct! Visualization avoids being misled by summaries alone."
3) Graphs are less reliable than statistics  
"3" = "❌ Incorrect. Plots complement statistics; both matter."
4) Linear relationships are the most common  
"4" = "❌ Incorrect. The quartet shows diverse structures with the same r."

---

### Question Q4 (Analyze)
**Headline: "Ice cream sales and drownings are strongly correlated." What's a plausible explanation?**

> **Hint:** Think of a third variable (confounder) driving both.

1) Ice cream causes drownings  
"1" = "❌ Incorrect. Correlation ≠ causation."
2) Drownings cause higher ice cream sales  
"2" = "❌ Incorrect. Reverse causality isn't plausible here."
3) Temperature/season increases both  
"3" = "✅ Correct! Warm weather raises ice cream sales and swimming activity."
4) There is no relationship at all  
"4" = "❌ Incorrect. There is an association, just not causal."

---

### Question Q5 (Apply)
**The relationship is curved but monotonically increasing. Which correlation should you choose?**

> **Hint:** Distinguish "linear" from "monotone".

1) Pearson correlation  
"1" = "❌ Incorrect. Pearson measures linear association and may underestimate strength."
2) Spearman correlation  
"2" = "✅ Correct! Spearman captures monotone relationships via ranks."
3) Both are equally appropriate  
"3" = "❌ Incorrect. Spearman fits better here."
4) Neither  
"4" = "❌ Incorrect. Spearman is suitable for monotone, non‑linear patterns."

---

### Question Q6 (Remember)
**You switch X from meters to centimeters. What happens to r(X,Y)?**

> **Hint:** Correlation is scale‑invariant; covariance isn't.

1) r becomes 100× larger  
"1" = "❌ Incorrect. Units don't affect r."
2) r becomes 100× smaller  
"2" = "❌ Incorrect. Units don't affect r."
3) r stays exactly the same  
"3" = "✅ Correct! r is unit‑free and invariant to linear rescaling."
4) r becomes negative  
"4" = "❌ Incorrect. The sign doesn't flip due to units."

---

### Question Q7 (Understand)
**Why do z‑scores make axes more comparable in a scatterplot?**

> **Hint:** Consider "same scale" and "standard deviations".

1) They put both variables into SD units  
"1" = "✅ Correct! Standardizing places both on the same scale."
2) They always increase the correlation  
"2" = "❌ Incorrect. Standardizing doesn't change r."
3) They remove all outliers  
"3" = "❌ Incorrect. They may help detect outliers, not remove them."
4) They make covariance unit‑free  
"4" = "❌ Incorrect. Correlation is unit‑free; covariance remains scale‑dependent."

---

### Question Q8 (Analyze)
**A scatterplot colors points by 'neighborhood type'. How is the overall correlation r typically computed?**

> **Hint:** Compare subgroup calculations versus full sample.

1) Using only the largest subgroup  
"1" = "❌ Incorrect. That ignores many cases."
2) As the average of subgroup correlations  
"2" = "❌ Incorrect. A simple mean of subgroup r's isn't standard."
3) Using all points together, ignoring colors  
"3" = "✅ Correct! By default r is computed on the full dataset."
4) As a weighted average of subgroup r's  
"4" = "❌ Incorrect. Not the default definition of r."

---

### Question Q9 (Understand)
**Which quadrants dominate under a positive association (in z‑scores)?**

> **Hint:** Consider the signs of z(X) and z(Y).

1) Mostly quadrants I & III  
"1" = "✅ Correct! Positive: both above or both below their means."
2) Mostly quadrants II & IV  
"2" = "❌ Incorrect. That indicates negative association."
3) Evenly spread across all quadrants  
"3" = "❌ Incorrect. Suggests little/no linear relationship."
4) Only quadrant I  
"4" = "❌ Incorrect. Quadrant III also occurs in positive association."

---

### Question Q10 (Apply)
**A straight trend line slopes upward; points cluster tightly. Which description fits best?**

> **Hint:** Combine direction (sign) with strength (spread).

1) Strong positive  
"1" = "✅ Correct! Upward line + tight cluster → strong positive."
2) Moderate positive  
"2" = "❌ Incorrect. Description suggests stronger than moderate."
3) Weak negative  
"3" = "❌ Incorrect. Direction is positive, not negative."
4) No linear pattern  
"4" = "❌ Incorrect. The pattern is clearly linear."

---

### Question Q11 (Analyze)
**In a positive trend, which outlier position most reduces r?**

> **Hint:** Think of points that break the linear pattern.

1) Far bottom‑left (low X, very low Y)  
"1" = "❌ Incorrect. That aligns with the positive trend."
2) Far bottom‑right (high X, low Y)  
"2" = "✅ Correct! Pulls the cloud off the line and lowers r."
3) Far top‑right (high X, high Y)  
"3" = "❌ Incorrect. Often increases a positive r."
4) A point exactly on the line  
"4" = "❌ Incorrect. Minimal impact on r."

---

### Question Q12 (Understand)
**Which statement about covariance and correlation is true?**

> **Hint:** Watch for units and ranges.

1) Covariance is unit‑free and bounded −1 to +1  
"1" = "❌ Incorrect. That's correlation, not covariance."
2) Correlation is unit‑free and always between −1 and +1  
"2" = "✅ Correct! That's why r is comparable across variables."
3) Both are unbounded  
"3" = "❌ Incorrect. Only covariance is unbounded."
4) Both depend on measurement scale  
"4" = "❌ Incorrect. Only covariance is scale‑dependent."

---

### Question Q13 (Apply)
**Which r value best matches 'weak positive'?**

> **Hint:** Use common interpretation guidelines.

1) r = 0.12  
"1" = "✅ Correct! Often interpreted as weak positive."
2) r = 0.56  
"2" = "❌ Incorrect. Closer to moderate."
3) r = −0.72  
"3" = "❌ Incorrect. Strong negative, not weak positive."
4) r = 0.93  
"4" = "❌ Incorrect. Very strong positive."

---

### Question Q14 (Understand)
**"As X increases, Y tends to …" — choose the best completion for a slightly increasing pattern.**

> **Hint:** Use the standard sentence for a weak upward trend.

1) … decrease, strongly  
"1" = "❌ Incorrect. Wrong direction."
2) … increase, weakly  
"2" = "✅ Correct! Weakly increasing relationship."
3) … increase, very strongly  
"3" = "❌ Incorrect. 'Very strong' doesn't fit a slight increase."
4) … stay the same  
"4" = "❌ Incorrect. That implies no linear relationship."

---

### Question Q15 (Remember)
**What does z = +1.2 mean in plain words?**

> **Hint:** Relate to the mean and standard deviation.

1) 1.2 units above the mean  
"1" = "❌ Incorrect. They are SD units, not raw units."
2) 1.2 standard deviations above the mean  
"2" = "✅ Correct! That's the definition of a positive z."
3) 1.2% above the mean  
"3" = "❌ Incorrect. Not a percentage."
4) 0.12 standard deviations above the mean  
"4" = "❌ Incorrect. Wrong magnitude."

---

### Question Q16 (Analyze)
**Subgroup colors on the plot: what's a risk of looking only at overall r?**

> **Hint:** Think Simpson's paradox and heterogeneity across groups.

1) Subgroup patterns can mask or reverse the overall pattern  
"1" = "✅ Correct! Aggregation can mislead; inspect subgroups."
2) r always changes when you add colors  
"2" = "❌ Incorrect. r's calculation ignores colors."
3) r can never be misleading  
"3" = "❌ Incorrect. r without context can mislead."
4) Subgroups automatically increase r  
"4" = "❌ Incorrect. No such general rule."

---

# Module 2: Correlation Calculations (18 questions)

### Question Q17 (Apply)
**Given X = [4, 6, 8] and Y = [2, 5, 8], calculate the means.**

> **Hint:** Sum divided by n.

1) X̄ = 5, Ȳ = 4  
"1" = "❌ Incorrect. Check your calculations."
2) X̄ = 6, Ȳ = 5  
"2" = "✅ Correct! X̄ = (4+6+8)/3 = 6, Ȳ = (2+5+8)/3 = 5."
3) X̄ = 18, Ȳ = 15  
"3" = "❌ Incorrect. Don't forget to divide by n."
4) X̄ = 7, Ȳ = 6  
"4" = "❌ Incorrect. Recalculate."

---

### Question Q18 (Apply)
**With X̄ = 6 and Ȳ = 5, calculate the deviations for X = [4, 6, 8].**

> **Hint:** Deviation = Xi - X̄

1) [-2, 0, 2]  
"1" = "✅ Correct! (4-6), (6-6), (8-6) = [-2, 0, 2]."
2) [2, 0, -2]  
"2" = "❌ Incorrect. Signs are wrong."
3) [-1, 1, 1]  
"3" = "❌ Incorrect. Wrong calculations."
4) [4, 6, 8]  
"4" = "❌ Incorrect. These are the original values, not deviations."

---

### Question Q19 (Apply)
**Calculate the sum of squared deviations for X with deviations [-2, 0, 2].**

> **Hint:** Sum of (deviation)².

1) 4  
"1" = "❌ Incorrect. That's just one squared deviation."
2) 8  
"2" = "✅ Correct! (-2)² + 0² + 2² = 4 + 0 + 4 = 8."
3) 0  
"3" = "❌ Incorrect. Sum of deviations is 0, but sum of squared deviations isn't."
4) 16  
"4" = "❌ Incorrect. Check your calculation."

---

### Question Q20 (Apply)
**With sum of squared deviations = 8 and n = 3, calculate the sample variance (s²).**

> **Hint:** s² = SS/(n-1)

1) 2.67  
"1" = "❌ Incorrect. You used n instead of n-1."
2) 4  
"2" = "✅ Correct! s² = 8/(3-1) = 8/2 = 4."
3) 8  
"3" = "❌ Incorrect. Don't forget to divide."
4) 1.33  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q21 (Apply)
**Calculate the covariance with deviations X: [-2, 0, 2] and Y: [-3, 0, 3].**

> **Hint:** Cov = Σ(Xi - X̄)(Yi - Ȳ)/(n-1)

1) 6  
"1" = "✅ Correct! [(-2)(-3) + (0)(0) + (2)(3)]/(3-1) = (6+0+6)/2 = 6."
2) 12  
"2" = "❌ Incorrect. Don't forget to divide by n-1."
3) 3  
"3" = "❌ Incorrect. Wrong calculation."
4) 0  
"4" = "❌ Incorrect. The products don't sum to zero."

---

### Question Q22 (Apply)
**With Cov(X,Y) = 6, sX = 2, sY = 1.73, calculate Pearson r.**

> **Hint:** r = Cov(X,Y)/(sX × sY)

1) 1.73  
"1" = "❌ Incorrect. r must be between -1 and +1."
2) 0.87  
"2" = "✅ Correct! r = 6/(2 × 1.73) = 6/3.46 ≈ 0.87."
3) 3.46  
"3" = "❌ Incorrect. That's the denominator."
4) 0.58  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q23 (Understand)
**If all data points fall exactly on a straight line with positive slope, r equals:**

> **Hint:** Perfect linear relationship.

1) The slope of the line  
"1" = "❌ Incorrect. r is scale-free; slope depends on units."
2) +1  
"2" = "✅ Correct! Perfect positive linear relationship gives r = +1."
3) The intercept of the line  
"3" = "❌ Incorrect. Intercept is different from correlation."
4) 0  
"4" = "❌ Incorrect. r = 0 indicates no linear relationship."

---

### Question Q24 (Analyze)
**Which r value indicates the strongest relationship (regardless of direction)?**

> **Hint:** Strength is about absolute value.

1) r = 0.85  
"1" = "❌ Incorrect. Not the strongest absolute value."
2) r = -0.92  
"2" = "✅ Correct! |-0.92| = 0.92 is the highest absolute value."
3) r = 0.78  
"3" = "❌ Incorrect. Lower absolute value."
4) r = -0.15  
"4" = "❌ Incorrect. Weakest relationship."

---

### Question Q25 (Apply)
**If r = 0.87, what is R² (coefficient of determination)?**

> **Hint:** R² = r²

1) 0.87  
"1" = "❌ Incorrect. That's r, not r²."
2) 0.76  
"2" = "✅ Correct! R² = (0.87)² = 0.7569 ≈ 0.76."
3) 1.74  
"3" = "❌ Incorrect. Can't be greater than 1."
4) 0.93  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q26 (Apply)
**Convert to ranks: X = [85, 92, 78, 92]. What are the ranks for X?**

> **Hint:** Assign ranks 1-4, handle ties with averages.

1) [2, 3.5, 1, 3.5]  
"1" = "✅ Correct! 78(1st), 85(2nd), 92s tied for 3rd&4th = 3.5 each."
2) [2, 4, 1, 3]  
"2" = "❌ Incorrect. Need to average tied ranks."
3) [3, 4, 1, 2]  
"3" = "❌ Incorrect. Wrong ranking."
4) [1, 2, 3, 4]  
"4" = "❌ Incorrect. Ignores the tie."

---

### Question Q27 (Understand)
**Why do we average ranks for tied values?**

> **Hint:** Preserve the total sum of ranks.

1) To make calculations easier  
"1" = "❌ Incorrect. Not about convenience."
2) To maintain the sum of ranks = n(n+1)/2  
"2" = "✅ Correct! Averaging preserves the mathematical properties."
3) Ties are not allowed in statistics  
"3" = "❌ Incorrect. Ties are common and handled systematically."
4) To increase the correlation  
"4" = "❌ Incorrect. Not about changing correlation strength."

---

### Question Q28 (Apply)
**For a 2×2 contingency table with χ² = 8.1 and n = 100, calculate Cramér's V.**

> **Hint:** V = √(χ²/(n × min(r-1, c-1)))

1) 0.081  
"1" = "❌ Incorrect. Wrong formula application."
2) 0.285  
"2" = "✅ Correct! V = √(8.1/(100×1)) = √0.081 = 0.285."
3) 0.81  
"3" = "❌ Incorrect. Missing the square root."
4) 0.09  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q29 (Apply)
**Calculate point-biserial correlation between binary X (0,1,1,0) and continuous Y (2,5,6,3).**

> **Hint:** Use regular Pearson formula or special point-biserial formula.

1) 0.82  
"1" = "✅ Correct! Strong positive association between binary and continuous variables."
2) 0.00  
"2" = "❌ Incorrect. There is a clear relationship."
3) -0.82  
"3" = "❌ Incorrect. Relationship is positive."
4) 1.00  
"4" = "❌ Incorrect. Not a perfect relationship."

---

### Question Q30 (Analyze)
**Your data has extreme outliers and curved relationships. Which correlation measure is most appropriate?**

> **Hint:** Consider robustness to outliers and non-linearity.

1) Pearson correlation  
"1" = "❌ Incorrect. Sensitive to outliers and assumes linearity."
2) Spearman correlation  
"2" = "✅ Correct! Rank-based, robust to outliers and captures monotonic relationships."
3) Point-biserial  
"3" = "❌ Incorrect. Only for binary-continuous relationships."
4) Cramér's V  
"4" = "❌ Incorrect. For categorical variables."

---

### Question Q31 (Analyze)
**One extreme outlier pulls the correlation from r = 0.85 to r = 0.23. What does this suggest?**

> **Hint:** Consider the impact of influential points.

1) The original correlation was wrong  
"1" = "❌ Incorrect. Both can be 'correct' calculations."
2) Outliers can dramatically affect Pearson r  
"2" = "✅ Correct! Demonstrates sensitivity to extreme values."
3) The relationship is actually negative  
"3" = "❌ Incorrect. Both correlations are positive."
4) Sample size is too small  
"4" = "❌ Incorrect. Issue is about outlier influence, not sample size."

---

### Question Q32 (Evaluate)
**When should you prefer Spearman over Pearson correlation?**

> **Hint:** Consider data type and relationship characteristics.

1) When you want the strongest correlation  
"1" = "❌ Incorrect. Choice should be based on data characteristics, not strength."
2) When data is ordinal or relationship is monotonic but non-linear  
"2" = "✅ Correct! Spearman is appropriate for ranks and monotonic relationships."
3) When sample size is large  
"3" = "❌ Incorrect. Sample size alone doesn't determine the choice."
4) When you have missing data  
"4" = "❌ Incorrect. Both require complete data for standard calculation."

---

### Question Q33 (Understand)
**How does covariance relate to correlation?**

> **Hint:** Think about standardization.

1) They're the same thing  
"1" = "❌ Incorrect. Related but different."
2) Correlation is standardized covariance  
"2" = "✅ Correct! r = Cov(X,Y)/(sX × sY)."
3) Covariance is always larger  
"3" = "❌ Incorrect. Depends on the scale."
4) They have opposite signs  
"4" = "❌ Incorrect. They have the same sign."

---

### Question Q34 (Apply)
**Interpret r = -0.65 between study hours and error rate.**

> **Hint:** Consider direction, strength, and practical meaning.

1) Moderate positive: more study, more errors  
"1" = "❌ Incorrect. r is negative."
2) Moderate negative: more study, fewer errors  
"2" = "✅ Correct! Makes practical sense - studying reduces errors."
3) Weak relationship with no practical meaning  
"3" = "❌ Incorrect. -0.65 is moderate to strong."
4) Perfect negative relationship  
"4" = "❌ Incorrect. Perfect would be r = -1.00."

---

# Module 3: Regression Basics (10 questions)

### Question Q35 (Understand)
**What does the "least squares" principle minimize in regression?**

> **Hint:** Think about what OLS stands for.

1) The sum of errors (residuals)  
"1" = "❌ Incorrect. Sum of residuals is always zero."
2) The sum of absolute errors  
"2" = "❌ Incorrect. That's least absolute deviations."
3) The sum of squared errors  
"3" = "✅ Correct! OLS minimizes Σ(yi - ŷi)²."
4) The correlation coefficient  
"4" = "❌ Incorrect. OLS doesn't minimize correlation."

---

### Question Q36 (Remember)
**Where does the regression line always pass through?**

> **Hint:** A fundamental property of OLS regression.

1) The origin (0,0)  
"1" = "❌ Incorrect. Only if both means are zero."
2) The point of means (X̄, Ȳ)  
"2" = "✅ Correct! The line always goes through (X̄, Ȳ)."
3) The highest data point  
"3" = "❌ Incorrect. Not a property of regression lines."
4) The lowest data point  
"4" = "❌ Incorrect. Not a property of regression lines."

---

### Question Q37 (Understand)
**If the regression equation is Ŷ = 5 + 2X, how do you interpret the slope?**

> **Hint:** Slope indicates the change in Y per unit change in X.

1) Y increases by 5 units for each unit increase in X  
"1" = "❌ Incorrect. That's the intercept, not slope."
2) Y increases by 2 units for each unit increase in X  
"2" = "✅ Correct! Slope = 2 means ΔY = 2 when ΔX = 1."
3) Y increases by 7 units for each unit increase in X  
"3" = "❌ Incorrect. That's adding intercept and slope."
4) X increases by 2 units for each unit increase in Y  
"4" = "❌ Incorrect. Backwards interpretation."

---

### Question Q38 (Understand)
**In Ŷ = 5 + 2X, what does the intercept (5) represent?**

> **Hint:** Value of Y when X = 0.

1) The slope of the line  
"1" = "❌ Incorrect. Slope is 2."
2) The predicted Y when X = 0  
"2" = "✅ Correct! Intercept is the Y-value when X = 0."
3) The correlation between X and Y  
"3" = "❌ Incorrect. Correlation is different from intercept."
4) The average value of Y  
"4" = "❌ Incorrect. That's Ȳ, not the intercept."

---

### Question Q39 (Understand)
**What is a residual in regression analysis?**

> **Hint:** Think about prediction error.

1) The slope of the regression line  
"1" = "❌ Incorrect. That's a regression coefficient."
2) The difference between observed and predicted Y  
"2" = "✅ Correct! Residual = yi - ŷi."
3) The correlation coefficient  
"3" = "❌ Incorrect. That measures linear association."
4) The intercept of the regression line  
"4" = "❌ Incorrect. That's a regression coefficient."

---

### Question Q40 (Understand)
**Why does OLS use squared errors rather than absolute errors?**

> **Hint:** Think about mathematical properties and outlier sensitivity.

1) Squared errors are easier to interpret  
"1" = "❌ Incorrect. Actually less intuitive than absolute errors."
2) It gives more weight to larger errors and has nice calculus properties  
"2" = "✅ Correct! Penalizes large errors more and allows analytical solutions."
3) Absolute errors don't exist  
"3" = "❌ Incorrect. They exist but have different properties."
4) Squared errors are always smaller  
"4" = "❌ Incorrect. Only when |error| < 1."

---

### Question Q41 (Understand)
**What does R² = 0.64 mean in regression?**

> **Hint:** Proportion of variance explained.

1) 64% of Y's variance is explained by X  
"1" = "✅ Correct! R² represents explained variance."
2) The correlation is 0.64  
"2" = "❌ Incorrect. r = √0.64 = 0.80."
3) 64% of predictions are correct  
"3" = "❌ Incorrect. R² isn't about prediction accuracy percentage."
4) The slope is 0.64  
"4" = "❌ Incorrect. R² and slope are different concepts."

---

### Question Q42 (Analyze)
**What's the main risk of extrapolation in regression?**

> **Hint:** Using the model outside the data range.

1) Calculations become more difficult  
"1" = "❌ Incorrect. Calculations are equally easy."
2) The relationship may not hold outside the observed range  
"2" = "✅ Correct! Linear relationship might break down beyond data boundaries."
3) R² always decreases  
"3" = "❌ Incorrect. R² is calculated on existing data."
4) The slope changes  
"4" = "❌ Incorrect. The equation stays the same; validity is questioned."

---

### Question Q43 (Understand)
**How do correlation and regression differ?**

> **Hint:** Think about symmetry and prediction.

1) They're identical concepts  
"1" = "❌ Incorrect. Related but different."
2) Correlation is symmetric; regression has directional prediction  
"2" = "✅ Correct! r(X,Y) = r(Y,X), but regression of Y on X ≠ X on Y."
3) Correlation is more accurate  
"3" = "❌ Incorrect. They serve different purposes."
4) Regression doesn't use correlation  
"4" = "❌ Incorrect. They're closely related."

---

### Question Q44 (Analyze)
**You find a strong regression relationship (R² = 0.81). Can you conclude causation?**

> **Hint:** Think about confounding and experimental design.

1) Yes, high R² proves causation  
"1" = "❌ Incorrect. Association ≠ causation, regardless of strength."
2) No, need experimental or quasi-experimental design  
"2" = "✅ Correct! Correlation/regression alone cannot establish causation."
3) Only if the slope is positive  
"3" = "❌ Incorrect. Direction doesn't determine causation."
4) Yes, but only for R² > 0.80  
"4" = "❌ Incorrect. No threshold makes correlation become causation."

---

# Module 4: Regression Calculations (12 questions)

### Question Q45 (Apply)
**Calculate the slope using b = r(sy/sx) where r = 0.6, sy = 8, sx = 4.**

> **Hint:** Direct substitution into the formula.

1) 0.3  
"1" = "❌ Incorrect. Wrong calculation."
2) 1.2  
"2" = "✅ Correct! b = 0.6 × (8/4) = 0.6 × 2 = 1.2."
3) 2.4  
"3" = "❌ Incorrect. Check your arithmetic."
4) 0.6  
"4" = "❌ Incorrect. That's just r."

---

### Question Q46 (Apply)
**Calculate the intercept using a = Ȳ - bX̄ where Ȳ = 12, b = 1.2, X̄ = 5.**

> **Hint:** Direct substitution into the formula.

1) 6.0  
"1" = "✅ Correct! a = 12 - 1.2(5) = 12 - 6 = 6."
2) 18.0  
"2" = "❌ Incorrect. Check your signs."
3) 1.2  
"3" = "❌ Incorrect. That's the slope."
4) 12.0  
"4" = "❌ Incorrect. That's just Ȳ."

---

### Question Q47 (Apply)
**Using Ŷ = 6 + 1.2X, predict Y when X = 8.**

> **Hint:** Substitute X = 8 into the equation.

1) 15.6  
"1" = "✅ Correct! Ŷ = 6 + 1.2(8) = 6 + 9.6 = 15.6."
2) 9.6  
"2" = "❌ Incorrect. Don't forget the intercept."
3) 20.4  
"3" = "❌ Incorrect. Check your calculation."
4) 6.0  
"4" = "❌ Incorrect. That's just the intercept."

---

### Question Q48 (Apply)
**If observed Y = 14 and predicted Ŷ = 15.6, what's the residual?**

> **Hint:** Residual = observed - predicted.

1) 1.6  
"1" = "❌ Incorrect. Wrong sign."
2) -1.6  
"2" = "✅ Correct! Residual = 14 - 15.6 = -1.6."
3) 29.6  
"3" = "❌ Incorrect. Don't add them."
4) 15.6  
"4" = "❌ Incorrect. That's the predicted value."

---

### Question Q49 (Apply)
**If r = 0.8, what is R²?**

> **Hint:** R² = r²

1) 0.8  
"1" = "❌ Incorrect. That's r, not r²."
2) 0.64  
"2" = "✅ Correct! R² = (0.8)² = 0.64."
3) 1.6  
"3" = "❌ Incorrect. Can't exceed 1."
4) 0.89  
"4" = "❌ Incorrect. Wrong calculation."

---

### Question Q50 (Apply)
**What's the standardized slope (beta) when r = 0.75?**

> **Hint:** In simple regression, β = r.

1) 0.56  
"1" = "❌ Incorrect. That would be r²."
2) 0.75  
"2" = "✅ Correct! In simple regression, the standardized slope equals r."
3) 1.33  
"3" = "❌ Incorrect. Not possible given r = 0.75."
4) 0.87  
"4" = "❌ Incorrect. Wrong value."

---

### Question Q51 (Understand)
**If you change X from meters to centimeters, what happens to the slope?**

> **Hint:** Consider unit effects on regression coefficients.

1) Slope stays the same  
"1" = "❌ Incorrect. Slope is not scale-invariant."
2) Slope becomes 100 times smaller  
"2" = "✅ Correct! When X units get 100× smaller, slope gets 100× smaller."
3) Slope becomes 100 times larger  
"3" = "❌ Incorrect. Wrong direction."
4) Slope becomes negative  
"4" = "❌ Incorrect. Sign doesn't change due to scale."

---

### Question Q52 (Apply)
**From regression output: Coefficient = 2.5, SE = 0.8, t = 3.125. What's the interpretation?**

> **Hint:** Focus on the coefficient and its meaning.

1) Y increases by 0.8 units per unit increase in X  
"1" = "❌ Incorrect. That's the standard error."
2) Y increases by 2.5 units per unit increase in X  
"2" = "✅ Correct! The coefficient is the slope."
3) Y increases by 3.125 units per unit increase in X  
"3" = "❌ Incorrect. That's the t-statistic."
4) The relationship is not significant  
"4" = "❌ Incorrect. t = 3.125 suggests significance."

---

### Question Q53 (Analyze)
**An outlier pulls the slope from 2.1 to 3.8. What should you do?**

> **Hint:** Consider data investigation and robustness.

1) Always remove the outlier  
"1" = "❌ Incorrect. Need to investigate first."
2) Investigate the outlier and consider robust methods  
"2" = "✅ Correct! Check if it's an error and consider robustness."
3) Always keep the outlier  
"3" = "❌ Incorrect. Depends on the situation."
4) Use the average of both slopes  
"4" = "❌ Incorrect. Not a standard practice."

---

### Question Q54 (Analyze)
**The intercept is -50 in a model predicting salary from years of experience. Is this meaningful?**

> **Hint:** Think about extrapolation and practical interpretation.

1) Yes, people with no experience owe money  
"1" = "❌ Incorrect. Practically nonsensical."
2) No, it's extrapolation beyond meaningful data range  
"2" = "✅ Correct! Intercept may not be meaningful outside data range."
3) Yes, it's always meaningful  
"3" = "❌ Incorrect. Context matters."
4) No, intercepts are never meaningful  
"4" = "❌ Incorrect. Sometimes they are meaningful."

---

### Question Q55 (Understand)
**Which assumption is most important for least squares regression?**

> **Hint:** Think about core OLS assumptions.

1) X must be normally distributed  
"1" = "❌ Incorrect. X distribution isn't required to be normal."
2) Y must have constant variance across X values  
"2" = "✅ Correct! Homoscedasticity is a key assumption."
3) Sample size must exceed 30  
"3" = "❌ Incorrect. No specific sample size requirement."
4) Variables must be measured without error  
"4" = "❌ Incorrect. While ideal, some measurement error is usually tolerated."

---

### Question Q56 (Understand)
**What's the difference between prediction and explanation in regression?**

> **Hint:** Think about goals and interpretation.

1) They're the same thing  
"1" = "❌ Incorrect. Different goals."
2) Prediction focuses on accuracy; explanation on understanding relationships  
"2" = "✅ Correct! Different emphases and evaluation criteria."
3) Prediction is always better  
"3" = "❌ Incorrect. Depends on the research goal."
4) Explanation doesn't use regression  
"4" = "❌ Incorrect. Regression serves both purposes."

---

# Module 5: Partial Correlation (8 questions)

### Question Q57 (Understand)
**When is partial correlation most useful?**

> **Hint:** Think about confounding variables.

1) When you want the strongest correlation  
"1" = "❌ Incorrect. Strength isn't the goal."
2) When you want to control for a third variable  
"2" = "✅ Correct! Partial correlation removes the effect of confounders."
3) When sample size is small  
"3" = "❌ Incorrect. Not specifically about sample size."
4) When variables are categorical  
"4" = "❌ Incorrect. Partial correlation is for continuous variables."

---

### Question Q58 (Remember)
**What's the formula for partial correlation rXY.Z?**

> **Hint:** Uses pairwise correlations and algebraic manipulation.

1) rXY × rXZ × rYZ  
"1" = "❌ Incorrect. Not a product."
2) (rXY - rXZ × rYZ) / √[(1-rXZ²)(1-rYZ²)]  
"2" = "✅ Correct! Standard partial correlation formula."
3) rXY - rXZ - rYZ  
"3" = "❌ Incorrect. Simple subtraction doesn't work."
4) (rXY + rXZ + rYZ) / 3  
"4" = "❌ Incorrect. Not an average."

---

### Question Q59 (Apply)
**Calculate rXY.Z with rXY = 0.7, rXZ = 0.5, rYZ = 0.6.**

> **Hint:** Use the partial correlation formula.

1) 0.45  
"1" = "✅ Correct! rXY.Z = (0.7 - 0.5×0.6)/√[(1-0.5²)(1-0.6²)] = 0.4/√[0.75×0.64] ≈ 0.45."
2) 0.70  
"2" = "❌ Incorrect. That's just rXY."
3) 0.60  
"3" = "❌ Incorrect. Wrong calculation."
4) 0.30  
"4" = "❌ Incorrect. Check your arithmetic."

---

### Question Q60 (Analyze)
**rXY = 0.8, but rXY.Z = 0.2. What does this suggest?**

> **Hint:** Think about spurious correlation.

1) Z has no effect  
"1" = "❌ Incorrect. Z clearly has a major effect."
2) Much of the X-Y relationship was due to Z  
"2" = "✅ Correct! Z was confounding the X-Y relationship."
3) There was a calculation error  
"3" = "❌ Incorrect. This pattern is possible and meaningful."
4) X and Y are not related  
"4" = "❌ Incorrect. They still have some relationship (0.2)."

---

### Question Q61 (Understand)
**What's the difference between controlling for Z and interacting with Z?**

> **Hint:** Think about constant vs. variable effects.

1) They're the same concept  
"1" = "❌ Incorrect. Different concepts."
2) Controlling assumes Z's effect is constant; interaction allows it to vary  
"2" = "✅ Correct! Control removes Z's effect; interaction examines how Z modifies relationships."
3) Interaction is always better  
"3" = "❌ Incorrect. Depends on the research question."
4) Controlling is only for categorical variables  
"4" = "❌ Incorrect. Can control for any type of variable."

---

### Question Q62 (Analyze)
**Interpret rXY.Z = -0.3 when rXY = 0.1 originally.**

> **Hint:** Think about suppression effects.

1) Controlling for Z revealed a hidden negative relationship  
"1" = "✅ Correct! Z was suppressing the true negative X-Y relationship."
2) Z caused the relationship to become negative  
"2" = "❌ Incorrect. Z revealed what was already there."
3) There's no relationship between X and Y  
"3" = "❌ Incorrect. There is a negative relationship."
4) The calculation must be wrong  
"4" = "❌ Incorrect. Suppression effects are real phenomena."

---

### Question Q63 (Apply)
**How should you report partial correlation results?**

> **Hint:** Think about what readers need to know.

1) Only report the partial correlation value  
"1" = "❌ Incorrect. Need more context."
2) Report both zero-order and partial correlations with controlled variables  
"2" = "✅ Correct! Provides full picture of relationships."
3) Only report if the partial correlation is significant  
"3" = "❌ Incorrect. Non-significant results can be meaningful."
4) Report only the variables that were controlled  
"4" = "❌ Incorrect. Need the actual correlation values."

---

### Question Q64 (Understand)
**Does changing the scale of X affect the partial correlation rXY.Z?**

> **Hint:** Think about correlation's scale-invariance property.

1) Yes, partial correlations are scale-dependent  
"1" = "❌ Incorrect. Correlations are scale-invariant."
2) No, all correlations (including partial) are scale-invariant  
"2" = "✅ Correct! Scale changes don't affect any correlation measures."
3) Only if Z is also rescaled  
"3" = "❌ Incorrect. Scale-invariance holds regardless."
4) Yes, but only for the controlled variable  
"4" = "❌ Incorrect. All correlations are scale-invariant."

---

## Summary

This expanded version provides comprehensive coverage of correlation and regression concepts across 64 carefully structured questions spanning five modules:

1. **Module 1 (16 questions)**: Foundation concepts including standardization, scatterplot interpretation, and basic correlation understanding
2. **Module 2 (18 questions)**: Detailed calculation procedures for various correlation measures  
3. **Module 3 (10 questions)**: Core regression concepts and interpretation
4. **Module 4 (12 questions)**: Regression calculations and practical applications
5. **Module 5 (8 questions)**: Advanced topics in partial correlation and control variables

Each question includes hints and detailed feedback to support learning across Bloom's taxonomy levels.